import tvm
from tvm import relay
from tvm.ir.transform import Sequential
from tvm.contrib import graph_runtime
import numpy as np
def vmobj_to_list(o, dtype="float32"):
    if isinstance(o, tvm.nd.NDArray):
        return [o]
    elif isinstance(o, tvm.runtime.container.ADT):
        result = []
        for f in o:
            result.extend(vmobj_to_list(f, dtype))
        return result
    else:
        return o


mod = tvm.IRModule()
mutated_mod = tvm.IRModule()
var_0 = relay.var("var_0", dtype = "float64", shape = (14, 12))#candidate|0|(14, 12)|var|float64
uop_1 = relay.sinh(var_0.astype('float64')) # shape=(14, 12)
bop_3 = relay.subtract(uop_1.astype('int16'), relay.reshape(var_0.astype('int16'), relay.shape_of(uop_1))) # shape=(14, 12)
output = relay.Tuple([bop_3,])
output2 = relay.Tuple([bop_3,])
func_6 = relay.Function([var_0,], output)
mod['func_6'] = func_6
mod = relay.transform.InferType()(mod)
mutated_mod['func_6'] = func_6
mutated_mod = relay.transform.InferType()(mutated_mod)
var_7 = relay.var("var_7", dtype = "float64", shape = (14, 12))#candidate|7|(14, 12)|var|float64
func_6_call = mutated_mod.get_global_var('func_6')
call_8 = func_6_call(var_7)
output = call_8
func_9 = relay.Function([var_7], output)
mutated_mod['func_9'] = func_9
mutated_mod = relay.transform.InferType()(mutated_mod)
var_11 = relay.var("var_11", dtype = "float32", shape = (6,))#candidate|11|(6,)|var|float32
var_12 = relay.var("var_12", dtype = "float32", shape = (6,))#candidate|12|(6,)|var|float32
bop_13 = relay.greater_equal(var_11.astype('bool'), relay.reshape(var_12.astype('bool'), relay.shape_of(var_11))) # shape=(6,)
bop_16 = relay.logical_or(bop_13.astype('bool'), relay.reshape(var_11.astype('bool'), relay.shape_of(bop_13))) # shape=(6,)
bop_19 = relay.left_shift(bop_16.astype('uint16'), relay.reshape(bop_13.astype('uint16'), relay.shape_of(bop_16))) # shape=(6,)
bop_22 = relay.bitwise_and(bop_13.astype('uint8'), relay.reshape(var_11.astype('uint8'), relay.shape_of(bop_13))) # shape=(6,)
bop_25 = relay.floor_mod(var_12.astype('float64'), relay.reshape(bop_16.astype('float64'), relay.shape_of(var_12))) # shape=(6,)
uop_28 = relay.acos(bop_16.astype('float32')) # shape=(6,)
func_6_call = mod.get_global_var('func_6')
func_9_call = mutated_mod.get_global_var('func_9')
const_31 = relay.const([3.215811,-6.233436,-5.786821,8.791536,-2.465942,5.373033,-0.122590,-6.615859,-1.341553,-2.177434,9.884612,7.574138,-9.825809,4.158201,1.019726,3.836343,3.267626,-9.816286,3.780512,-2.020106,7.714733,-6.311223,-3.334787,8.411318,4.636055,6.229947,-4.569555,8.668415,-4.971194,-6.050397,6.665529,6.222662,8.739927,-0.146943,7.219959,2.007423,6.662180,5.749068,-9.156860,-4.388460,-4.152476,-0.604980,-6.563621,-2.254061,-9.537480,-4.385210,-2.437859,-9.893560,7.688876,-6.530906,8.195916,-6.566977,0.707403,-1.641047,-9.379148,2.367702,-2.150461,5.761048,3.954793,-4.716774,-4.901008,-2.157254,-1.380628,5.275389,5.139608,-7.596277,5.110953,1.392369,-6.269357,-9.248332,-5.774604,-8.316282,4.112645,9.698566,6.910055,-3.392816,7.609968,-6.364328,0.741479,1.256112,3.477880,5.360289,-1.538687,9.299150,-4.470752,8.662238,-6.114236,8.153125,7.844973,-7.052492,-4.392809,8.748476,2.024557,5.003234,7.110751,-2.827892,6.239361,8.248231,-3.018853,-8.265922,-4.815218,-6.502108,1.804159,-5.110884,-6.080891,6.647931,0.993582,-3.370792,-4.942188,3.546398,4.894190,-2.338871,0.714575,-8.241505,8.406315,-3.376415,8.808443,-1.284622,-2.716687,5.035574,1.231416,-5.672110,3.569776,-5.257282,-2.700912,9.113437,0.220760,-8.034048,5.598394,-7.589851,-3.464704,-9.266168,4.411080,-9.871541,0.070366,5.011011,6.343821,8.947730,-4.198078,-0.080150,0.769973,-1.764560,-7.652136,6.440366,-4.194831,-0.036923,-7.641452,-6.156687,6.012725,-1.638989,-2.035187,3.357768,8.946080,1.481735,-9.803097,-5.577942,6.750328,-8.290313,-5.884770,-0.907116,-4.383506,0.751433,1.109396,-7.484081,-0.117086,-6.516317,-4.775768,-2.460084], dtype = "float64")#candidate|31|(168,)|const|float64
call_30 = relay.TupleGetItem(func_6_call(relay.reshape(const_31.astype('float64'), [14, 12])), 0)
call_32 = relay.TupleGetItem(func_9_call(relay.reshape(const_31.astype('float64'), [14, 12])), 0)
uop_33 = relay.sin(bop_22.astype('float32')) # shape=(6,)
uop_35 = relay.log2(var_12.astype('float64')) # shape=(6,)
var_37 = relay.var("var_37", dtype = "float64", shape = (6,))#candidate|37|(6,)|var|float64
bop_38 = relay.floor_divide(uop_35.astype('float64'), relay.reshape(var_37.astype('float64'), relay.shape_of(uop_35))) # shape=(6,)
bop_41 = relay.add(bop_22.astype('uint64'), relay.reshape(bop_38.astype('uint64'), relay.shape_of(bop_22))) # shape=(6,)
uop_44 = relay.tan(var_37.astype('float32')) # shape=(6,)
func_6_call = mod.get_global_var('func_6')
func_9_call = mutated_mod.get_global_var('func_9')
call_46 = relay.TupleGetItem(func_6_call(relay.reshape(call_30.astype('float64'), [14, 12])), 0)
call_47 = relay.TupleGetItem(func_9_call(relay.reshape(call_30.astype('float64'), [14, 12])), 0)
bop_48 = relay.logical_xor(uop_35.astype('int16'), relay.reshape(uop_28.astype('int16'), relay.shape_of(uop_35))) # shape=(6,)
const_51 = relay.const([-3.225354,2.475023,-1.658126,5.950272,1.270863,-4.621581], dtype = "float32")#candidate|51|(6,)|const|float32
bop_52 = relay.bitwise_or(uop_44.astype('int64'), relay.reshape(const_51.astype('int64'), relay.shape_of(uop_44))) # shape=(6,)
bop_55 = relay.equal(bop_22.astype('bool'), relay.reshape(uop_35.astype('bool'), relay.shape_of(bop_22))) # shape=(6,)
uop_58 = relay.log(uop_35.astype('float64')) # shape=(6,)
uop_60 = relay.tan(bop_52.astype('float32')) # shape=(6,)
const_62 = relay.const([True,True,True,False,True,False], dtype = "bool")#candidate|62|(6,)|const|bool
bop_63 = relay.subtract(bop_55.astype('int64'), relay.reshape(const_62.astype('int64'), relay.shape_of(bop_55))) # shape=(6,)
uop_66 = relay.sin(uop_58.astype('float32')) # shape=(6,)
uop_68 = relay.asin(uop_66.astype('float32')) # shape=(6,)
bop_70 = relay.bitwise_or(uop_66.astype('uint32'), relay.reshape(bop_19.astype('uint32'), relay.shape_of(uop_66))) # shape=(6,)
bop_73 = relay.right_shift(uop_60.astype('uint16'), relay.reshape(uop_28.astype('uint16'), relay.shape_of(uop_60))) # shape=(6,)
uop_76 = relay.cos(uop_68.astype('float32')) # shape=(6,)
uop_78 = relay.log10(uop_76.astype('float32')) # shape=(6,)
uop_80 = relay.atanh(uop_68.astype('float32')) # shape=(6,)
func_6_call = mod.get_global_var('func_6')
func_9_call = mutated_mod.get_global_var('func_9')
call_82 = relay.TupleGetItem(func_6_call(relay.reshape(call_30.astype('float64'), [14, 12])), 0)
call_83 = relay.TupleGetItem(func_9_call(relay.reshape(call_30.astype('float64'), [14, 12])), 0)
uop_84 = relay.rsqrt(uop_68.astype('float32')) # shape=(6,)
var_86 = relay.var("var_86", dtype = "float32", shape = (6,))#candidate|86|(6,)|var|float32
bop_87 = relay.greater_equal(uop_78.astype('bool'), relay.reshape(var_86.astype('bool'), relay.shape_of(uop_78))) # shape=(6,)
output = relay.Tuple([bop_25,call_30,const_31,uop_33,bop_41,call_46,bop_48,bop_63,bop_70,bop_73,uop_80,call_82,uop_84,bop_87,])
output2 = relay.Tuple([bop_25,call_32,const_31,uop_33,bop_41,call_47,bop_48,bop_63,bop_70,bop_73,uop_80,call_83,uop_84,bop_87,])
func_90 = relay.Function([var_11,var_12,var_37,var_86,], output)
mod['func_90'] = func_90
mod = relay.transform.InferType()(mod)
var_91 = relay.var("var_91", dtype = "float32", shape = (6,))#candidate|91|(6,)|var|float32
var_92 = relay.var("var_92", dtype = "float32", shape = (6,))#candidate|92|(6,)|var|float32
var_93 = relay.var("var_93", dtype = "float64", shape = (6,))#candidate|93|(6,)|var|float64
var_94 = relay.var("var_94", dtype = "float32", shape = (6,))#candidate|94|(6,)|var|float32
output = func_90(var_91,var_92,var_93,var_94,)
func_95 = relay.Function([var_91,var_92,var_93,var_94,], output)
mutated_mod['func_95'] = func_95
mutated_mod = relay.transform.InferType()(mutated_mod)
const_97 = relay.const([[-2,-4,2,6,-1,-9,3,7,9,-6,-4,-4],[7,2,9,7,-6,-8,4,6,-7,6,-10,-7],[4,4,2,-2,9,8,-7,1,5,-2,5,6],[4,-1,-2,3,-2,3,-4,-2,10,3,4,-1],[-3,-9,4,10,5,2,2,5,-4,-7,-5,3],[10,3,10,-4,-8,3,8,7,9,-3,5,-4],[-6,7,-1,-7,8,4,3,-5,10,-2,-3,4],[-10,-2,4,-6,-8,-4,-3,9,-2,-1,2,-7],[-4,-1,-9,9,-1,-4,7,-7,-3,4,-1,-9],[-8,7,6,2,-2,9,7,1,-6,-3,7,8],[1,7,-4,5,9,-4,6,7,7,1,3,-2],[-1,4,4,-7,3,-5,10,-1,-1,-6,-10,-9],[10,-1,-4,-3,-9,-10,-8,-6,-10,-10,-2,-1]], dtype = "int16")#candidate|97|(13, 12)|const|int16
const_98 = relay.const([[-8,6,-2,-10,6,5,-6,9,-7,-3,-7,-6],[5,-1,9,4,-8,9,5,-10,5,-10,-2,7],[9,-6,4,5,-9,-8,-2,8,-5,9,-10,10],[4,-6,-10,-10,2,-5,-8,-8,7,-9,-8,-8],[-6,2,7,9,3,-10,8,-4,-5,-9,-1,2],[-10,-8,8,1,4,7,-5,-5,-4,3,-6,-4],[-8,-6,9,9,-10,10,-5,-1,-4,2,-5,-10],[-3,-2,-10,2,1,-6,-7,-10,2,-5,2,-5],[4,-8,4,9,2,8,10,-9,9,1,-2,5],[10,-8,5,9,-3,-10,6,6,-3,-2,-6,3],[-8,-3,5,2,-7,-8,-8,-4,5,-7,5,10],[10,10,3,-3,-8,-9,6,8,6,8,2,-2],[-5,-9,2,8,-1,8,-2,5,9,2,-7,-9]], dtype = "int16")#candidate|98|(13, 12)|const|int16
bop_99 = relay.greater_equal(const_97.astype('bool'), relay.reshape(const_98.astype('bool'), relay.shape_of(const_97))) # shape=(13, 12)
uop_102 = relay.exp(bop_99.astype('float32')) # shape=(13, 12)
var_104 = relay.var("var_104", dtype = "float32", shape = (13, 12))#candidate|104|(13, 12)|var|float32
bop_105 = relay.multiply(uop_102.astype('int16'), relay.reshape(var_104.astype('int16'), relay.shape_of(uop_102))) # shape=(13, 12)
bop_108 = relay.minimum(uop_102.astype('uint16'), relay.reshape(bop_105.astype('uint16'), relay.shape_of(uop_102))) # shape=(13, 12)
uop_111 = relay.sin(const_97.astype('float32')) # shape=(13, 12)
uop_113 = relay.log10(uop_111.astype('float64')) # shape=(13, 12)
var_115 = relay.var("var_115", dtype = "float64", shape = (13, 12))#candidate|115|(13, 12)|var|float64
bop_116 = relay.divide(uop_113.astype('float32'), relay.reshape(var_115.astype('float32'), relay.shape_of(uop_113))) # shape=(13, 12)
uop_119 = relay.sin(uop_113.astype('float64')) # shape=(13, 12)
uop_121 = relay.asin(uop_119.astype('float32')) # shape=(13, 12)
uop_123 = relay.acos(uop_121.astype('float64')) # shape=(13, 12)
bop_125 = relay.floor_mod(uop_123.astype('float32'), relay.reshape(var_104.astype('float32'), relay.shape_of(uop_123))) # shape=(13, 12)
output = relay.Tuple([bop_108,bop_116,bop_125,])
output2 = relay.Tuple([bop_108,bop_116,bop_125,])
func_128 = relay.Function([var_104,var_115,], output)
mod['func_128'] = func_128
mod = relay.transform.InferType()(mod)
var_129 = relay.var("var_129", dtype = "float32", shape = (13, 12))#candidate|129|(13, 12)|var|float32
var_130 = relay.var("var_130", dtype = "float64", shape = (13, 12))#candidate|130|(13, 12)|var|float64
output = func_128(var_129,var_130,)
func_131 = relay.Function([var_129,var_130,], output)
mutated_mod['func_131'] = func_131
mutated_mod = relay.transform.InferType()(mutated_mod)
var_133 = relay.var("var_133", dtype = "float32", shape = (15,))#candidate|133|(15,)|var|float32
var_134 = relay.var("var_134", dtype = "float32", shape = (15,))#candidate|134|(15,)|var|float32
bop_135 = relay.floor_divide(var_133.astype('float32'), relay.reshape(var_134.astype('float32'), relay.shape_of(var_133))) # shape=(15,)
uop_138 = relay.acos(var_134.astype('float32')) # shape=(15,)
uop_140 = relay.rsqrt(uop_138.astype('float32')) # shape=(15,)
uop_142 = relay.log(uop_140.astype('float32')) # shape=(15,)
uop_144 = relay.rsqrt(uop_142.astype('float64')) # shape=(15,)
bop_146 = relay.right_shift(uop_142.astype('int32'), relay.reshape(var_134.astype('int32'), relay.shape_of(uop_142))) # shape=(15,)
var_149 = relay.var("var_149", dtype = "float32", shape = (15,))#candidate|149|(15,)|var|float32
bop_150 = relay.less(uop_142.astype('bool'), relay.reshape(var_149.astype('bool'), relay.shape_of(uop_142))) # shape=(15,)
bop_153 = relay.greater_equal(uop_140.astype('bool'), relay.reshape(var_134.astype('bool'), relay.shape_of(uop_140))) # shape=(15,)
bop_156 = relay.divide(uop_144.astype('float32'), relay.reshape(var_134.astype('float32'), relay.shape_of(uop_144))) # shape=(15,)
bop_159 = relay.multiply(bop_153.astype('uint64'), relay.reshape(var_149.astype('uint64'), relay.shape_of(bop_153))) # shape=(15,)
uop_162 = relay.log10(uop_144.astype('float64')) # shape=(15,)
uop_164 = relay.asinh(uop_162.astype('float32')) # shape=(15,)
uop_166 = relay.sinh(uop_164.astype('float64')) # shape=(15,)
uop_168 = relay.tan(uop_166.astype('float64')) # shape=(15,)
uop_170 = relay.erf(uop_168.astype('float64')) # shape=(15,)
uop_172 = relay.asin(uop_170.astype('float32')) # shape=(15,)
const_174 = relay.const([8.453197,5.663151,2.971422,-3.356524,1.995486,8.843791,1.620488,2.640998,5.444708,3.693928,-3.360712,9.035095,-1.648111,-8.356637,2.498925], dtype = "float32")#candidate|174|(15,)|const|float32
bop_175 = relay.subtract(uop_172.astype('uint64'), relay.reshape(const_174.astype('uint64'), relay.shape_of(uop_172))) # shape=(15,)
uop_178 = relay.acosh(uop_162.astype('float64')) # shape=(15,)
output = relay.Tuple([bop_135,bop_146,bop_150,bop_156,bop_159,bop_175,uop_178,])
output2 = relay.Tuple([bop_135,bop_146,bop_150,bop_156,bop_159,bop_175,uop_178,])
func_180 = relay.Function([var_133,var_134,var_149,], output)
mod['func_180'] = func_180
mod = relay.transform.InferType()(mod)
var_181 = relay.var("var_181", dtype = "float32", shape = (15,))#candidate|181|(15,)|var|float32
var_182 = relay.var("var_182", dtype = "float32", shape = (15,))#candidate|182|(15,)|var|float32
var_183 = relay.var("var_183", dtype = "float32", shape = (15,))#candidate|183|(15,)|var|float32
output = func_180(var_181,var_182,var_183,)
func_184 = relay.Function([var_181,var_182,var_183,], output)
mutated_mod['func_184'] = func_184
mutated_mod = relay.transform.InferType()(mutated_mod)
var_186 = relay.var("var_186", dtype = "float32", shape = (9, 15, 13))#candidate|186|(9, 15, 13)|var|float32
uop_187 = relay.atanh(var_186.astype('float32')) # shape=(9, 15, 13)
bop_189 = relay.subtract(uop_187.astype('uint32'), relay.reshape(var_186.astype('uint32'), relay.shape_of(uop_187))) # shape=(9, 15, 13)
uop_192 = relay.log(bop_189.astype('float64')) # shape=(9, 15, 13)
bop_194 = relay.multiply(uop_192.astype('float64'), relay.reshape(var_186.astype('float64'), relay.shape_of(uop_192))) # shape=(9, 15, 13)
uop_197 = relay.acosh(bop_194.astype('float64')) # shape=(9, 15, 13)
bop_199 = relay.logical_or(uop_192.astype('bool'), relay.reshape(var_186.astype('bool'), relay.shape_of(uop_192))) # shape=(9, 15, 13)
bop_202 = relay.greater(uop_197.astype('bool'), relay.reshape(bop_194.astype('bool'), relay.shape_of(uop_197))) # shape=(9, 15, 13)
bop_205 = relay.bitwise_or(uop_187.astype('uint64'), relay.reshape(bop_194.astype('uint64'), relay.shape_of(uop_187))) # shape=(9, 15, 13)
uop_208 = relay.sin(bop_205.astype('float64')) # shape=(9, 15, 13)
bop_210 = relay.maximum(bop_199.astype('uint16'), relay.reshape(bop_205.astype('uint16'), relay.shape_of(bop_199))) # shape=(9, 15, 13)
bop_213 = relay.floor_divide(uop_197.astype('float32'), relay.reshape(bop_205.astype('float32'), relay.shape_of(uop_197))) # shape=(9, 15, 13)
var_216 = relay.var("var_216", dtype = "bool", shape = (9, 15, 13))#candidate|216|(9, 15, 13)|var|bool
bop_217 = relay.left_shift(bop_202.astype('int8'), relay.reshape(var_216.astype('int8'), relay.shape_of(bop_202))) # shape=(9, 15, 13)
uop_220 = relay.sqrt(bop_217.astype('float32')) # shape=(9, 15, 13)
uop_222 = relay.tan(uop_220.astype('float32')) # shape=(9, 15, 13)
func_128_call = mod.get_global_var('func_128')
func_131_call = mutated_mod.get_global_var('func_131')
const_225 = relay.const([-4.477609,-8.305841,-9.027699,-9.399900,1.297050,4.567720,9.437313,3.063873,-0.103263,5.207278,7.856177,-2.631722,5.481806,-5.728185,8.020681,6.556567,1.344432,-3.237896,1.903930,0.159548,-7.369089,-5.503927,-3.391830,0.774085,-8.513431,6.317235,-0.468119,-1.930554,-3.491859,3.778986,-9.691670,-2.031864,-0.806241,9.151150,3.955831,-6.978426,4.445723,8.032645,-1.867418,4.432511,-8.017764,-0.987941,-1.121130,-1.072145,4.456812,-0.037896,-1.737641,-9.902348,-6.941073,5.400719,-0.897009,6.959007,-1.131987,-8.913027,8.407279,5.124911,-6.581073,9.545983,-9.325854,4.782902,6.281613,2.311302,-5.747647,-4.875672,-3.203557,-6.521104,-5.195356,-3.690365,2.781034,6.536097,-7.616867,-2.359901,6.711416,-1.009682,5.498780,3.050063,3.506244,-0.847874,-4.341234,-0.593408,-3.453856,-2.262176,2.228243,-0.906984,4.287553,6.981798,-5.156238,-4.209720,1.657132,-0.524650,-8.820805,3.360928,-3.350668,-2.487704,2.797800,2.894644,6.931382,-1.760854,9.471660,0.321591,-4.109776,-4.937955,-1.868238,-4.026356,3.946970,-4.569818,0.979395,-3.078635,-0.373951,-9.009194,2.981369,5.887968,2.356722,0.136474,-5.990121,0.131117,-4.635040,-0.631274,-4.056995,-0.612518,8.773872,-3.447592,1.744670,-2.779875,2.134153,8.297792,4.863795,9.949066,-5.260852,0.516487,-3.177598,4.773980,-6.586015,5.745383,9.334627,0.902715,7.124785,2.007258,-9.125172,-8.642772,-2.247230,-5.188557,-9.730544,7.047112,8.015021,-8.296348,3.816310,-2.655620,6.052401,4.206238,4.291005,5.037278,-2.007751,6.045323,-3.474979,-2.845744], dtype = "float32")#candidate|225|(156,)|const|float32
call_224 = relay.TupleGetItem(func_128_call(relay.reshape(const_225.astype('float32'), [13, 12]), relay.reshape(const_225.astype('float64'), [13, 12]), ), 0)
call_226 = relay.TupleGetItem(func_131_call(relay.reshape(const_225.astype('float32'), [13, 12]), relay.reshape(const_225.astype('float64'), [13, 12]), ), 0)
uop_227 = relay.log10(uop_222.astype('float32')) # shape=(9, 15, 13)
uop_229 = relay.log10(uop_227.astype('float32')) # shape=(9, 15, 13)
bop_231 = relay.less(uop_229.astype('bool'), relay.reshape(uop_192.astype('bool'), relay.shape_of(uop_229))) # shape=(9, 15, 13)
bop_234 = relay.multiply(uop_227.astype('float64'), relay.reshape(bop_205.astype('float64'), relay.shape_of(uop_227))) # shape=(9, 15, 13)
bop_237 = relay.multiply(uop_229.astype('int32'), relay.reshape(bop_231.astype('int32'), relay.shape_of(uop_229))) # shape=(9, 15, 13)
uop_240 = relay.exp(uop_227.astype('float64')) # shape=(9, 15, 13)
bop_242 = relay.mod(bop_231.astype('float32'), relay.reshape(uop_222.astype('float32'), relay.shape_of(bop_231))) # shape=(9, 15, 13)
uop_245 = relay.rsqrt(uop_222.astype('float64')) # shape=(9, 15, 13)
uop_247 = relay.sigmoid(uop_222.astype('float64')) # shape=(9, 15, 13)
uop_249 = relay.asinh(uop_222.astype('float32')) # shape=(9, 15, 13)
bop_251 = relay.subtract(bop_217.astype('uint64'), relay.reshape(bop_189.astype('uint64'), relay.shape_of(bop_217))) # shape=(9, 15, 13)
bop_254 = relay.divide(uop_247.astype('float64'), relay.reshape(bop_194.astype('float64'), relay.shape_of(uop_247))) # shape=(9, 15, 13)
func_128_call = mod.get_global_var('func_128')
func_131_call = mutated_mod.get_global_var('func_131')
call_257 = relay.TupleGetItem(func_128_call(relay.reshape(call_224.astype('float32'), [13, 12]), relay.reshape(call_224.astype('float64'), [13, 12]), ), 0)
call_258 = relay.TupleGetItem(func_131_call(relay.reshape(call_224.astype('float32'), [13, 12]), relay.reshape(call_224.astype('float64'), [13, 12]), ), 0)
uop_259 = relay.erf(bop_237.astype('float64')) # shape=(9, 15, 13)
const_261 = relay.const([[[9.250689,-1.098813,4.140970,9.654021,4.682750,1.047433,-0.293008,9.067191,9.166018,2.801167,7.824414,-0.139657,-6.889095],[1.592014,-9.990603,-5.008187,1.599675,-4.558112,-5.139479,-4.061928,4.707879,4.961609,-4.682983,4.697501,6.328114,7.273201],[-8.322042,-3.548243,9.238948,-1.539129,-0.005096,-8.459820,-6.659300,-7.164628,-7.600898,-5.320850,8.495842,5.627556,8.532716],[4.905905,7.419201,6.798003,-4.277252,5.124851,-8.090625,3.269298,-1.744985,-5.448625,-3.573087,-5.141407,8.111748,0.878730],[-5.956670,7.448738,2.118534,-2.107264,9.393134,-5.616271,0.064998,-3.407867,1.476460,-1.846504,5.602375,-4.164891,0.341209],[-1.757667,-9.998734,5.077406,-3.352312,-9.271107,1.646046,8.914732,-2.989306,-7.007338,9.317431,0.024609,-2.927987,-4.946459],[-1.518725,-0.103058,3.100547,4.189706,-9.275208,-6.516575,6.018808,-5.139211,2.862741,0.683330,4.991913,5.331151,-5.588034],[2.000144,-6.527159,-7.083049,3.774335,8.201566,6.571124,-4.384646,0.662376,2.171495,4.088855,-5.956105,8.952185,-2.057781],[7.389876,7.991119,3.405550,4.613002,-9.028333,-3.127962,-8.709716,3.335631,-6.397964,7.446231,-9.443568,-4.947693,-4.666399],[1.106067,8.663147,-0.719338,5.083576,-2.700380,-9.456716,8.817861,-5.701145,-2.390974,1.277571,-1.237407,4.050824,2.878039],[-3.561615,0.425504,-0.732317,-3.411414,4.155308,1.561081,-3.321738,5.001018,5.509068,-7.597499,-8.716099,-6.116608,-4.786085],[-1.053853,-0.434426,6.558972,2.746074,2.606509,7.056671,1.943437,-3.850159,-9.992531,6.406758,6.986759,-8.709381,-7.172253],[0.909514,-8.754555,7.384905,4.177478,-3.777461,2.762723,-6.325248,-1.212508,-4.243921,-5.797539,-3.684255,-9.292419,-6.806112],[-1.266314,1.695914,5.896117,9.592558,-3.519499,-1.689990,-2.950689,-7.960858,2.074789,-2.892878,5.117562,3.587725,3.795542],[-8.933676,0.613654,4.363837,1.524590,-7.842701,3.092195,-4.594944,6.366140,-6.244941,4.314691,1.461762,1.092621,-4.543363]],[[-6.889937,-6.476160,0.059043,9.484666,8.516243,-0.709252,0.265530,0.648285,-1.724030,-1.331948,2.581199,6.497841,-8.292629],[3.427816,-4.226378,-0.543031,5.967485,-2.308528,0.394332,-1.509542,6.098887,5.003681,2.721737,9.814489,-4.207853,8.843794],[-7.289694,-8.012750,0.289052,-1.676894,-7.143430,4.115649,9.365482,-7.826299,4.211654,7.904534,-3.508549,-3.129488,-5.936697],[5.575886,4.437764,-8.286255,-0.716615,-4.329797,-5.067259,4.109490,1.958205,-2.857909,7.131858,6.616055,9.089603,5.940128],[7.424122,-5.685613,1.361704,-2.863557,-0.501514,4.406146,-8.722536,1.603036,-7.798024,1.299562,8.091332,1.752080,-7.091012],[9.498721,3.295730,1.757962,-8.534408,-4.861337,-0.115188,2.958217,0.424555,6.148776,-9.911658,-4.701058,4.766380,8.379721],[-4.005577,8.299307,9.289792,-8.533225,1.271759,-7.242770,0.210087,-3.953747,0.687401,4.175089,-2.513416,-8.871224,1.435011],[3.142334,-9.728605,2.332170,0.920797,-6.454114,0.280574,-8.239729,-4.346301,5.390385,6.122053,7.667805,9.860668,-3.673406],[7.213195,-8.445160,1.438981,-2.907529,-9.328994,-5.622167,-7.738245,4.841764,-4.342529,7.262020,-4.200172,-8.927906,-3.857571],[-9.733909,-9.015195,9.360102,-2.760688,-2.335695,4.426689,9.114034,-4.625167,-3.672801,-9.840055,5.557601,7.436710,-2.974902],[5.452657,7.291203,-6.893061,8.326564,-1.221622,7.881367,-8.907831,4.511847,-1.946234,-2.486387,-2.702515,2.359151,-9.183315],[5.831329,7.149102,5.587761,4.880957,-0.505994,-8.981653,-3.715212,-4.101503,2.170403,-1.657824,3.779166,-1.120503,9.910712],[-9.593472,9.605433,1.142256,-4.083532,-5.289032,5.959845,-5.483376,-3.906994,5.924296,-3.811133,-1.986326,1.094789,-7.413879],[4.779594,-9.635810,0.262132,7.965702,8.087686,-5.371263,-7.273574,0.289292,-0.633480,2.268886,-3.857817,1.106721,1.558270],[7.168911,-9.750644,8.325764,-9.871447,3.186051,-2.852630,-8.479416,7.290814,3.245914,-8.065412,-1.722752,-8.589437,7.626375]],[[-0.873919,2.045239,-7.154771,-3.790689,-5.089928,-3.857067,7.664351,0.460566,-7.580824,4.862402,-0.497409,8.361911,0.416309],[5.186073,-8.924498,1.489299,9.998234,-2.709508,9.218395,8.313546,-3.331691,-3.026991,0.559831,5.338471,7.699775,2.825001],[7.975999,-0.192251,-9.790332,-1.773209,-3.330601,-3.162884,8.651049,5.625733,0.385810,-9.259733,-0.314193,-1.456297,-7.409603],[-0.449910,-9.149496,2.812612,-7.945349,3.719153,5.100446,6.758435,0.811182,-3.554919,-0.278026,5.249226,-4.043111,7.662191],[-8.758198,-0.661226,5.605545,-5.910522,-2.265353,8.160071,-4.481114,-6.598586,2.181537,7.369066,8.923484,2.789581,-8.862083],[1.614849,-5.050522,2.301231,-2.760232,-2.001837,-8.089713,-9.172891,-5.993438,-7.726839,-3.904198,4.133472,-4.330207,-5.367114],[-1.959265,-8.738887,-6.767562,4.964697,-1.998140,4.190328,-2.885679,8.768802,-8.147742,2.412278,9.638664,0.387642,-2.765756],[6.771007,-0.056873,-3.214630,4.447492,0.723984,0.756003,4.761666,4.650964,-9.871314,-1.282022,3.576080,0.295577,4.351168],[-6.201944,-2.242162,3.082461,8.676585,4.880951,-5.048061,-4.932435,-0.053567,-6.544154,-5.157808,-7.139101,7.381885,-9.114793],[-2.914361,-1.278121,-8.903691,-2.591184,6.555118,8.869033,1.838187,1.483326,5.085279,7.964275,2.770827,2.608917,-8.103227],[-9.878918,-2.307948,-9.316277,1.101846,6.255155,2.464506,-6.738757,7.617052,6.192634,1.893776,3.326738,6.884165,-7.622524],[-0.862592,-0.112352,-1.376586,0.250057,4.911434,9.308612,-7.003253,-0.185771,-9.173424,-6.301326,-9.064302,6.543839,-7.534662],[6.639945,7.755165,-0.658004,1.026475,-7.849453,-4.971076,6.914733,2.470444,-3.251725,4.078581,1.670264,2.028739,8.740260],[-5.971966,7.462815,5.959386,-5.970550,0.412012,2.116655,5.356788,-8.572258,9.390222,4.674950,-1.007474,-2.123550,-3.749771],[6.965866,4.061850,-3.189237,6.265261,8.260108,-2.837212,-8.560851,-9.479803,-0.052013,6.777804,8.505451,-9.111622,-9.247779]],[[-0.495934,-8.251072,-9.918951,3.023112,2.208336,0.388147,1.796363,9.424293,-1.526219,1.492940,4.510336,-3.225503,-3.257274],[1.752918,-0.235541,6.924975,-4.717708,-1.730569,-6.757822,1.258116,7.888150,-8.085968,1.829421,-9.439552,1.755194,-5.565023],[5.326563,-5.392453,4.559667,6.634751,3.798618,-8.689451,-8.067926,-0.908674,-6.453960,-2.797219,1.659844,8.962501,5.703545],[-8.031479,5.771485,1.963279,-4.617716,9.518104,-2.139069,3.181981,8.276547,1.903564,-6.283593,-3.364685,7.897713,-8.956685],[-6.391288,7.392141,9.699900,-6.383761,1.811555,-5.264166,1.559095,8.697060,-8.703303,2.862295,-2.214561,6.607535,7.015017],[-2.932252,5.934831,4.071201,-1.546496,1.475941,-0.460811,-8.797191,7.489228,8.679261,-4.409151,-6.131342,-2.852256,1.125381],[1.510836,1.649351,-5.405126,0.113640,5.653686,4.482358,-5.868215,4.334790,0.567995,-7.807471,-7.328618,2.124391,-0.416112],[3.597074,-8.023086,2.081080,-4.139164,-5.677969,-1.083176,-4.274968,-7.857290,6.794774,-6.541574,0.992446,7.756991,-5.191424],[-8.786133,-1.134399,-0.548804,6.346227,-4.089466,-4.770656,0.289450,-5.733716,-5.093930,8.505699,-3.663949,8.161147,-8.506367],[-3.407182,-9.515005,2.608642,8.974826,2.536125,-9.049353,-0.346406,-3.970392,8.687117,5.493886,3.096067,-4.422081,-5.072058],[-2.296721,4.006163,-5.693771,-5.461320,-0.648229,8.173776,5.922029,9.994028,4.136709,5.070737,-9.310939,-5.240157,-6.608867],[-5.913867,-7.026738,4.524647,-5.378990,3.583788,9.209126,-1.504688,-5.564347,1.458426,-6.910546,2.382635,-2.832276,8.289463],[2.779342,-4.183808,-9.717143,-2.258146,1.716483,1.140809,-5.876304,-6.442272,-3.373028,9.384803,5.322753,-4.982334,-0.615521],[6.757755,-7.962442,5.918262,-8.200267,1.218644,-0.179733,-3.314990,-5.363338,-4.048945,-3.957361,-6.403778,4.104729,5.865588],[-2.027690,-9.904767,1.835092,2.756522,9.321381,4.589354,-0.474341,-2.238103,-1.318667,-9.733935,-7.238790,6.291830,5.562370]],[[9.195943,-3.246084,9.910594,-5.597561,9.182614,-6.687760,-1.390669,8.143349,8.546828,-3.686783,2.718146,-6.868546,8.319379],[-6.402435,-3.637602,-3.815408,-6.338853,-9.970553,9.674277,5.092044,5.890018,3.584339,0.335946,0.714855,-7.962378,-5.800197],[8.320247,4.090716,2.020154,2.920249,-0.471586,7.754975,-2.254403,-9.977640,9.472006,-4.255171,2.029117,-2.774783,9.153709],[-3.381471,0.736180,0.284981,0.296003,-4.298985,-9.110528,-0.857599,1.882808,5.290924,-0.438099,-8.988739,9.051727,-8.888669],[-1.425179,-4.859607,-0.780854,-1.999903,5.779734,-6.888947,-4.648561,-2.026523,4.128432,3.170901,-1.307980,-5.667707,5.258120],[-1.788072,-9.032857,9.174319,1.753907,-2.390002,-0.076346,-4.470003,-0.484372,6.443430,5.271444,3.546895,-5.371421,0.902480],[7.819647,4.747811,-3.783942,5.724563,-2.861285,-5.687246,-5.392851,-4.666438,5.967402,7.147839,4.907774,-3.038124,-2.937225],[7.919765,0.714165,9.550520,0.224392,0.153444,7.445448,-8.232383,1.804772,2.445158,9.876167,3.058202,-7.865776,-6.142948],[5.418712,-4.378379,-8.439554,-3.510495,5.367135,-4.063652,1.739885,-8.664077,-2.710499,-5.635884,9.163247,-2.798631,2.797906],[6.800638,-2.062325,-8.569661,2.630701,4.330871,-2.143054,5.160266,8.204417,-2.355888,0.147656,8.077755,4.823103,9.116790],[-1.630160,5.591139,2.934170,4.314951,-4.239063,2.273831,5.197177,0.620880,4.575856,2.046065,-1.812001,8.632936,-4.483777],[-9.304854,-4.111001,6.469919,9.047712,1.774850,6.711704,-2.204362,-5.339321,9.204874,-1.461431,9.422978,5.916842,-0.574124],[0.225641,4.226345,8.649746,3.190626,-5.124839,-5.255198,-6.077425,-6.967271,-0.251850,5.212701,6.617299,-8.094840,-7.603720],[5.152703,-0.353884,3.742517,9.644540,-7.217755,-4.369209,-2.301082,-3.409953,-1.227780,-4.215642,-8.235027,6.208630,4.190314],[2.605502,-4.918324,-4.828410,9.024680,-7.481195,-6.550025,-4.907134,-2.614437,-4.995039,3.560232,9.298851,3.583576,-5.808429]],[[-3.806138,-3.531181,-3.415014,-6.572645,1.893344,-6.403593,1.177722,4.994955,-2.973968,-2.336986,0.410065,-0.835694,5.072450],[-6.055063,6.812459,0.367762,2.117319,-6.605851,1.051028,-1.677975,4.249504,6.052364,8.348539,-1.155322,-5.077476,-5.551943],[4.629926,-9.068687,-7.639478,-0.239490,-8.837272,-2.883988,5.400592,0.825333,1.096445,2.320680,9.255121,0.020805,8.816606],[-2.408180,4.512177,1.854564,5.463771,6.796543,5.531314,-0.632486,2.003859,1.572515,7.981562,5.847107,-8.700650,6.823782],[-7.239613,5.980054,-2.745113,1.471082,-6.414014,-6.136480,0.084111,-4.519035,9.145316,-1.111427,0.375105,8.814252,-5.378820],[9.672436,3.007304,-5.193134,8.950839,-6.195107,-3.275389,4.495343,-8.789329,-1.748839,-7.007046,-8.968612,9.182128,-0.898922],[-3.716095,0.610160,2.326026,-8.886310,3.417946,-7.086781,-8.609292,-3.468043,-6.198129,5.663697,-2.601450,-5.435714,-4.098148],[-7.988773,2.885210,-9.302818,2.293093,5.323358,-2.911461,4.956807,-6.147066,8.947018,-7.938858,0.332307,7.784342,-9.662250],[9.740933,-3.649779,5.321043,4.120250,-4.954381,9.122333,-9.831640,-6.129968,-5.606327,-6.684556,3.394091,0.645643,-9.104108],[-8.069539,5.966452,8.053553,-5.965678,3.303721,-5.800882,-4.029367,-1.914946,-0.061773,-0.330737,-5.354233,2.991703,-3.242538],[-0.193789,-2.623003,-9.531149,-4.806178,2.545284,-6.471403,-5.759248,-0.723553,6.220629,1.338358,-1.500966,-0.762004,-9.246094],[6.667151,7.136059,-3.675122,7.924826,-7.876224,2.419219,7.143672,-4.367597,-2.249283,1.255782,-9.655971,-9.395845,6.837980],[5.263806,6.275656,-9.452643,2.788844,-2.812752,3.701620,5.961271,-0.082891,-2.957476,8.785462,6.034378,7.984832,-1.904760],[1.778996,7.247862,0.342435,-3.108426,-3.569331,4.964362,4.096892,1.324471,7.750528,-5.780154,-6.681953,-9.701419,-0.357810],[6.483372,-1.934293,2.994508,-7.093078,-4.613984,9.490011,9.871532,5.273478,-2.084379,-7.329502,5.441105,-3.768554,7.724791]],[[6.148130,-0.996164,-3.620370,9.519687,-1.370593,-7.461912,-1.720418,-3.598877,-1.118053,4.705215,9.591166,-5.215544,-7.419675],[5.500455,3.119727,7.602361,-6.284308,-7.847276,4.129242,-7.299206,-6.083128,5.246398,4.047814,0.618332,9.918892,-6.492785],[-2.698230,-4.353511,-2.798741,8.604789,5.580974,-1.544925,-0.404781,-2.000919,1.617877,6.636775,0.414061,-2.749770,8.043902],[-5.436064,-9.208671,5.386693,2.963451,0.644790,5.130277,-0.548854,9.351679,8.560447,1.739422,-8.678308,-3.976315,7.194498],[-2.479907,-6.903705,3.498516,-1.442470,1.520856,-0.479246,9.631884,1.821993,-8.497818,0.778601,-8.885758,7.678123,-4.488795],[-2.133480,-4.340245,6.767075,1.103617,-5.757701,-6.369722,1.502973,-5.484918,8.892264,1.567163,-7.147477,-2.120641,-3.066939],[-8.104616,-0.726162,6.995510,4.602232,-8.221247,-0.865793,5.757808,-1.796818,0.903230,8.022165,8.029835,1.973884,1.835779],[-7.357671,-5.723328,3.052810,5.807609,9.089017,-5.873148,-1.943152,3.884594,0.730585,1.370403,6.277321,5.528490,-5.694836],[7.630247,8.397135,1.251840,-1.148479,-8.164242,5.077556,6.568447,-6.043490,6.649543,3.208916,5.820932,4.080827,-0.793953],[1.541102,-0.992143,7.192003,-4.693270,-4.801463,-2.847934,5.027117,-0.325341,-1.890893,4.545162,-5.467577,6.032102,-1.735333],[-3.547554,7.984749,-3.541815,-6.160387,-7.653930,-2.881354,-7.218342,1.291750,2.065617,-7.119797,9.513887,8.696121,5.492771],[2.359918,8.052051,-1.325746,-6.956542,4.656319,-3.444468,1.904842,3.883920,6.633945,-1.362219,-7.948324,4.939497,-5.562583],[-6.954543,-9.321278,8.383058,-7.263702,8.143124,-3.347709,8.452151,-6.540175,6.088712,-0.266053,6.337769,-0.989803,-9.168153],[2.553387,2.951727,-3.227827,1.718577,-7.374659,1.984329,-7.525599,0.894635,-5.346908,-4.101574,-8.128971,-7.590510,-7.525140],[6.161525,8.457868,3.736403,5.177479,-0.432719,-6.995014,-0.276009,-3.459811,-4.189249,-7.178647,8.108344,-1.795096,7.626147]],[[9.425547,8.642222,8.364175,0.688202,7.489536,6.631278,0.907153,-9.044554,-8.889861,-3.100871,-5.276097,5.961370,-3.889557],[4.767426,-5.196157,-8.368779,-9.833269,5.881241,-8.024384,7.995737,6.587376,-8.885338,-5.758722,8.164536,-7.758428,-1.197451],[-6.149956,0.267461,-0.510724,8.235576,-6.061707,4.500506,6.763061,-6.184515,5.656718,6.209819,3.487561,3.609402,9.832581],[-2.289180,5.779805,-7.143349,-6.254065,-4.156083,9.258106,5.602233,4.895137,-4.885942,5.277260,-2.839953,-3.171518,9.644116],[-7.026970,-3.321120,6.937269,8.771915,7.763157,-2.674643,7.971453,-7.402646,-3.471674,-6.868618,-4.848087,3.700187,-2.124847],[-6.199403,8.681116,-2.385737,5.676040,6.816408,6.924106,8.999144,1.648080,-1.924726,-8.228782,9.932702,-6.846690,3.583732],[-0.520106,-8.757024,-8.610029,-3.101806,-1.883623,8.406737,6.258470,5.568208,8.096646,3.466269,-7.506055,-6.467704,-1.472039],[-9.377049,5.133606,-0.060830,-7.706320,-5.804281,0.708520,-5.724193,0.749018,7.337101,3.273527,7.815862,6.970138,1.885263],[-4.103521,7.493019,8.752143,5.359217,7.357891,-0.962815,-2.659214,-9.492778,7.689863,-3.116089,8.039526,1.056619,-4.898559],[9.032444,9.037455,0.360758,-1.740926,0.938784,-0.145379,4.482573,-1.715591,3.649588,-9.594985,-7.258200,4.550689,6.160859],[2.628676,0.394525,5.847794,7.176312,6.185089,9.885774,1.071966,5.772350,5.730391,5.659318,-6.195637,0.248445,5.935019],[3.001885,-4.679272,0.635395,6.921843,6.594706,7.010443,-5.461955,2.033543,3.163559,-1.784731,3.173134,3.965806,4.042394],[1.881651,-9.877503,-6.348135,3.947198,-9.292349,-6.090457,9.212773,7.435189,4.935742,1.383780,1.137968,1.470249,5.323956],[7.284827,-3.051892,7.492416,8.734277,-3.641781,2.218689,-8.974674,-6.813918,6.939430,-1.464339,-6.070541,-1.451985,2.349364],[-3.062561,2.306976,5.560717,-7.038691,2.652566,0.708627,-0.467611,1.528595,-0.332650,5.052199,-7.600641,-6.755110,4.896765]],[[-1.322977,0.057861,9.156679,3.025475,1.763974,-9.115950,-1.983429,9.762846,-5.874409,5.442164,6.117034,-5.199211,-7.783231],[-5.560562,9.588369,8.887198,7.456495,1.224815,0.343259,-4.682550,5.909736,-2.506225,-3.058655,-1.824018,9.849914,-2.492210],[0.697129,-4.610560,-9.541679,-3.838275,-5.160384,4.575664,-2.249369,6.316946,5.996674,1.286758,-3.632730,-8.624111,4.120415],[8.606764,-8.484079,-1.422567,-6.894418,8.226803,3.931087,1.528510,-5.136339,6.191790,8.390268,-7.810645,-2.606719,-4.579320],[0.019137,-0.683095,0.145647,-8.959325,6.839034,0.397204,5.946722,-4.971516,-1.828019,-7.747062,5.351296,-7.343447,-8.623069],[1.854846,-2.302784,5.043844,9.203627,-8.734411,-0.709119,-6.454001,9.760061,0.842108,3.186696,7.055234,1.988636,-8.029774],[-8.069835,-2.905659,0.824847,2.047406,0.668203,8.597117,-4.674133,5.474132,-6.604676,2.379069,7.011938,-8.961269,-7.112337],[-5.454127,-8.199471,-3.359039,3.045691,3.146821,1.869892,-2.517624,-6.677965,0.659960,-8.926430,5.994666,-8.633690,-9.564675],[0.025463,-7.301833,0.217371,-4.787832,2.956840,-6.962617,1.001509,0.340020,-2.786694,8.468465,-7.718430,-3.086923,1.791837],[0.554640,-7.799750,5.385542,2.954460,5.810403,-0.642670,-6.710607,0.099762,6.937769,-5.626053,0.531893,-2.276971,7.374630],[7.248702,8.879681,9.259822,-0.052770,2.632826,-2.688028,-1.314211,1.880289,8.164796,-6.192634,-5.392990,4.659881,3.965419],[8.112357,0.487087,-1.074779,-4.311459,7.164078,-2.243600,1.081153,7.274328,-9.514957,-3.343034,-6.950844,7.634754,-6.336697],[-6.924917,6.378497,-0.710064,-4.665991,6.324295,-6.611492,-9.429122,-3.699355,8.954680,-3.454854,3.256154,-5.375648,-1.171458],[6.925381,-0.005924,7.936613,4.834772,-6.630086,-1.117902,7.014119,2.196033,5.883596,6.288327,-6.292147,-6.852785,1.601966],[-1.895610,6.416924,-5.752534,-8.327037,-4.248297,-8.280041,-3.219254,2.954504,8.842276,8.899459,-7.359508,-9.025054,-4.607375]]], dtype = "float64")#candidate|261|(9, 15, 13)|const|float64
bop_262 = relay.logical_or(uop_259.astype('bool'), relay.reshape(const_261.astype('bool'), relay.shape_of(uop_259))) # shape=(9, 15, 13)
func_180_call = mod.get_global_var('func_180')
func_184_call = mutated_mod.get_global_var('func_184')
const_266 = relay.const([6.930141,-5.033948,-6.773332,-0.093529,5.882803,-4.603672,-9.613187,7.748747,-4.316858,7.751334,-9.597162,-4.535183,-7.388107,-6.978478,9.582233], dtype = "float32")#candidate|266|(15,)|const|float32
call_265 = relay.TupleGetItem(func_180_call(relay.reshape(const_266.astype('float32'), [15,]), relay.reshape(const_266.astype('float32'), [15,]), relay.reshape(const_266.astype('float32'), [15,]), ), 4)
call_267 = relay.TupleGetItem(func_184_call(relay.reshape(const_266.astype('float32'), [15,]), relay.reshape(const_266.astype('float32'), [15,]), relay.reshape(const_266.astype('float32'), [15,]), ), 4)
var_268 = relay.var("var_268", dtype = "bool", shape = (9, 15, 13))#candidate|268|(9, 15, 13)|var|bool
bop_269 = relay.divide(bop_262.astype('float64'), relay.reshape(var_268.astype('float64'), relay.shape_of(bop_262))) # shape=(9, 15, 13)
const_272 = relay.const([[[True,False,True,False,True,True,True,False,False,False,False,True,True],[False,True,False,True,True,True,True,False,True,False,True,False,True],[False,False,False,False,False,True,False,False,False,True,True,True,True],[True,False,False,True,True,False,False,True,True,True,True,False,True],[False,False,True,False,False,True,False,False,False,False,True,False,False],[True,False,False,True,True,True,True,True,False,False,True,False,False],[False,False,True,True,True,True,True,False,True,True,False,True,True],[False,True,True,False,False,False,False,False,True,False,True,False,True],[False,True,True,False,True,True,False,False,False,False,True,False,False],[False,True,False,True,True,False,False,False,True,False,False,True,False],[False,True,False,False,True,False,True,False,False,False,True,True,False],[False,True,True,False,True,True,True,False,False,False,False,True,False],[True,True,True,True,False,True,False,False,True,True,False,True,True],[False,True,True,True,False,True,False,True,True,False,True,False,False],[True,True,False,False,True,False,False,False,True,False,True,True,False]],[[True,True,False,False,False,False,True,True,False,True,False,False,True],[True,False,False,False,False,True,True,True,False,False,True,False,True],[False,False,False,True,False,True,False,False,True,True,False,True,False],[False,False,True,True,True,False,True,True,False,False,True,True,True],[True,False,False,True,True,False,True,True,True,True,True,False,True],[False,True,True,True,True,False,False,False,True,True,True,False,True],[True,False,False,True,True,True,True,True,False,False,True,True,True],[True,False,False,True,True,True,False,False,False,True,False,False,False],[True,False,True,False,True,False,False,True,True,False,False,False,True],[False,False,True,True,False,False,True,False,True,False,True,True,False],[False,False,True,False,False,False,False,True,False,True,False,True,False],[True,True,False,False,False,False,False,True,True,False,True,False,True],[False,False,False,True,True,False,False,False,True,False,False,True,False],[True,True,False,False,True,True,True,False,True,True,False,False,True],[False,False,False,False,True,True,True,False,False,False,False,False,False]],[[True,True,False,True,True,True,False,True,True,True,False,False,True],[False,False,False,False,True,False,False,True,False,False,False,True,False],[True,True,False,True,True,False,False,False,True,True,True,True,False],[True,False,True,True,False,True,True,False,True,False,False,True,False],[False,True,False,False,True,True,True,False,True,True,False,True,True],[True,True,False,False,True,True,False,False,True,False,True,False,False],[False,True,False,False,True,True,True,True,True,True,True,False,True],[False,True,True,True,False,False,False,True,False,False,False,False,False],[True,True,False,False,True,False,True,False,False,False,True,False,True],[False,True,False,False,False,False,False,True,False,False,True,False,True],[True,False,False,True,True,True,False,True,True,False,True,False,False],[False,False,True,False,False,True,True,False,True,True,True,True,False],[True,False,True,True,True,False,False,True,True,True,True,False,False],[False,False,True,True,False,True,True,True,True,True,False,False,False],[True,True,True,True,True,False,True,False,True,False,False,True,False]],[[False,False,True,False,False,True,False,False,False,False,True,False,True],[True,True,True,True,True,False,True,False,True,False,False,False,True],[False,True,True,True,True,True,False,False,True,False,True,True,False],[False,True,False,False,False,True,True,True,False,True,False,True,True],[True,False,False,False,True,False,True,False,True,False,False,True,False],[True,False,True,True,False,True,False,False,True,True,True,True,False],[False,False,False,True,True,False,True,True,False,False,True,True,True],[True,True,True,False,True,False,False,False,True,True,False,False,True],[True,True,True,False,True,True,False,False,False,False,False,False,True],[False,False,True,True,True,False,False,False,False,True,True,True,True],[False,False,True,False,True,True,True,False,True,True,True,False,True],[False,False,True,False,True,True,False,False,False,False,False,False,False],[True,True,True,False,False,False,False,False,False,True,True,False,False],[False,True,True,False,False,True,False,True,True,False,False,False,False],[False,False,True,False,False,False,True,False,False,True,False,False,True]],[[False,True,False,False,True,True,True,True,True,True,False,False,False],[False,False,False,False,False,False,False,True,False,False,True,True,False],[True,True,False,True,False,True,True,True,True,False,False,True,True],[True,False,False,True,True,False,True,True,False,False,False,False,True],[False,False,True,False,True,False,True,True,False,True,False,True,False],[False,True,False,True,True,False,True,True,True,False,True,True,False],[True,True,False,True,False,False,True,True,False,False,False,True,False],[False,True,False,True,True,False,False,False,True,True,False,True,False],[True,True,True,False,True,False,True,True,True,False,False,True,True],[False,True,True,False,True,True,True,False,False,False,False,True,False],[False,False,False,True,True,False,False,False,False,False,True,False,True],[False,False,True,True,True,False,True,True,False,False,False,True,False],[True,True,True,False,False,True,False,False,False,True,False,False,False],[True,False,True,True,False,True,True,True,True,False,True,False,True],[True,False,False,False,True,True,False,False,True,False,True,True,False]],[[True,True,True,True,True,False,False,False,True,False,True,False,True],[False,False,True,False,False,False,True,False,True,False,True,True,False],[False,True,True,True,True,False,False,False,True,True,False,True,True],[True,True,True,True,True,True,False,False,False,False,False,True,False],[True,True,True,False,True,True,True,False,False,True,False,True,True],[True,False,False,True,False,True,False,True,True,True,False,True,True],[False,True,False,True,True,True,False,False,False,True,True,True,True],[True,False,True,False,False,True,True,False,False,True,True,False,False],[False,False,False,True,True,True,False,True,False,True,True,True,True],[True,False,False,False,False,False,True,True,False,True,False,True,True],[False,False,False,True,False,True,True,True,False,False,False,True,False],[False,False,True,True,False,False,False,False,False,False,False,True,True],[True,False,False,False,True,False,True,False,True,True,True,False,False],[True,True,False,False,True,True,True,False,False,True,False,False,True],[False,False,False,False,False,True,False,False,True,False,False,False,False]],[[False,False,True,False,False,False,True,True,True,False,False,False,False],[False,True,False,True,False,True,True,False,True,True,True,True,True],[True,True,False,True,True,False,True,False,False,False,True,False,True],[False,False,True,False,True,True,True,True,False,True,False,False,False],[True,True,True,True,True,False,False,True,False,False,True,True,False],[True,True,True,True,False,True,False,True,True,True,True,False,False],[True,False,True,True,False,False,True,True,True,False,False,False,True],[False,False,False,True,False,True,True,False,True,True,True,True,True],[True,False,False,True,False,True,True,True,True,True,False,False,True],[True,False,True,True,True,True,True,True,False,False,False,True,False],[True,True,True,False,False,False,False,False,False,True,True,True,False],[False,True,False,False,False,False,False,True,True,True,False,True,False],[False,True,True,False,True,False,True,False,True,True,True,True,True],[True,False,False,False,True,True,True,True,True,True,True,False,False],[True,True,False,False,False,True,True,True,True,False,True,False,False]],[[False,True,True,False,False,False,False,False,True,True,True,False,True],[True,False,False,True,False,True,False,True,True,False,False,False,True],[True,False,True,True,True,True,False,False,True,False,True,False,False],[False,True,False,False,False,True,False,True,False,True,False,False,False],[False,True,False,False,False,True,True,True,False,False,True,False,False],[False,False,True,False,False,True,False,False,False,False,True,False,True],[True,True,False,False,True,False,True,True,False,True,False,True,True],[False,True,False,False,False,False,False,True,True,True,True,True,True],[True,True,True,True,True,False,True,True,False,False,True,True,False],[True,True,False,True,False,True,False,False,True,False,False,False,False],[True,True,True,False,False,False,False,True,True,True,False,False,False],[False,True,True,False,True,False,True,True,True,True,False,False,True],[False,False,True,False,False,True,True,True,True,True,True,True,True],[True,False,True,True,False,True,False,True,True,True,False,False,True],[True,True,True,True,False,True,False,False,True,False,True,False,False]],[[False,False,True,False,True,False,False,False,False,True,True,False,False],[True,False,False,True,True,False,True,False,True,True,False,True,True],[True,False,False,False,False,True,False,True,True,True,False,True,True],[False,False,False,False,True,True,False,True,True,True,True,False,False],[True,True,False,False,True,True,False,True,True,False,False,True,False],[True,False,False,True,True,False,True,False,False,False,True,True,False],[False,False,True,False,False,False,False,False,True,True,False,True,False],[True,False,True,True,False,False,True,False,True,True,False,True,True],[False,True,False,True,True,True,False,True,True,False,True,True,True],[False,False,True,False,True,False,False,False,True,False,False,True,False],[False,False,False,True,True,False,False,True,False,False,False,False,True],[False,False,False,True,True,True,False,False,True,True,True,True,True],[False,True,True,True,True,True,True,True,False,False,True,True,False],[True,True,False,True,False,False,False,False,False,True,True,False,False],[False,True,True,True,False,True,False,True,True,True,True,False,False]]], dtype = "bool")#candidate|272|(9, 15, 13)|const|bool
bop_273 = relay.right_shift(bop_231.astype('uint32'), relay.reshape(const_272.astype('uint32'), relay.shape_of(bop_231))) # shape=(9, 15, 13)
var_276 = relay.var("var_276", dtype = "bool", shape = (9, 15, 13))#candidate|276|(9, 15, 13)|var|bool
bop_277 = relay.less_equal(bop_262.astype('bool'), relay.reshape(var_276.astype('bool'), relay.shape_of(bop_262))) # shape=(9, 15, 13)
const_280 = relay.const([[[False,True,False,False,False,True,True,True,True,True,False,False,False],[True,True,False,False,True,True,False,True,False,True,True,False,False],[False,False,True,False,False,False,False,False,False,False,True,False,True],[False,True,True,False,True,True,False,True,True,True,True,True,False],[True,False,True,True,True,False,True,False,False,True,False,False,True],[True,False,False,True,False,False,False,True,True,True,False,True,False],[True,False,True,False,False,True,True,False,False,False,False,False,False],[False,True,True,True,True,False,True,True,True,True,False,True,True],[True,False,True,False,False,True,False,False,True,False,True,False,False],[True,False,False,True,True,True,True,False,False,False,False,True,True],[True,True,True,False,False,False,False,True,False,False,False,False,False],[False,True,True,False,True,True,True,False,False,False,True,True,False],[True,True,False,False,True,True,True,False,True,True,True,True,True],[True,True,True,False,False,True,True,True,False,False,False,True,False],[True,True,True,False,True,False,False,True,True,True,False,False,True]],[[True,False,False,False,True,False,True,False,False,True,False,True,True],[False,True,True,True,False,False,False,True,True,True,False,True,False],[True,False,False,True,True,True,True,False,True,False,False,False,True],[False,False,True,True,True,True,False,False,False,False,True,False,False],[False,True,False,True,True,True,True,True,False,False,False,False,False],[True,False,False,True,True,False,True,False,True,False,True,False,True],[True,False,False,True,False,False,False,False,True,True,True,False,False],[False,False,False,False,True,True,False,True,True,False,False,False,False],[True,True,False,True,False,True,False,False,True,False,False,True,True],[True,True,False,True,True,False,True,False,False,False,True,True,False],[False,True,False,True,True,True,False,True,True,False,True,True,False],[False,True,False,True,False,True,False,True,False,False,True,True,False],[False,False,True,True,False,False,False,False,True,True,True,True,True],[False,True,False,True,True,False,True,True,True,True,False,False,False],[False,False,False,True,False,False,True,True,True,True,True,True,True]],[[False,False,True,True,True,True,False,True,True,True,True,False,False],[True,True,False,True,False,False,True,False,False,True,False,True,False],[True,True,False,False,False,False,False,True,False,False,True,False,True],[False,False,True,False,False,False,True,True,True,True,True,False,True],[True,True,True,True,True,False,False,True,False,False,False,True,False],[False,True,True,False,False,True,False,True,True,True,True,False,False],[False,False,True,False,True,True,True,True,False,True,True,False,False],[False,False,False,True,False,False,False,True,True,False,False,True,False],[True,False,True,False,False,False,False,False,False,True,True,False,False],[True,True,False,True,True,False,True,False,True,False,False,True,True],[True,True,False,True,True,True,True,True,True,False,True,True,False],[True,True,True,True,True,False,False,True,True,False,True,False,False],[False,False,False,True,False,False,True,False,True,False,True,False,True],[True,False,False,False,False,False,True,True,True,True,True,False,False],[False,False,False,True,False,False,True,False,False,True,False,True,True]],[[True,True,True,False,True,False,False,True,False,True,True,False,False],[True,True,False,True,True,False,True,True,True,True,False,True,True],[False,False,False,True,False,True,False,True,True,True,True,False,True],[True,True,False,True,True,True,False,True,False,False,False,True,True],[True,False,True,False,False,True,True,False,False,True,True,True,False],[True,False,True,True,True,False,False,False,False,True,True,False,True],[False,False,True,True,False,False,False,True,True,False,True,False,False],[True,True,True,False,True,False,True,False,True,False,False,True,False],[False,True,False,True,False,False,True,True,True,True,True,True,True],[False,True,False,False,True,True,True,True,False,False,True,True,False],[True,True,True,False,False,True,True,False,False,True,False,False,False],[True,True,False,True,False,False,False,False,True,False,False,False,True],[False,True,False,True,True,True,False,False,False,False,False,True,False],[False,True,False,False,True,False,False,True,True,False,False,True,True],[True,True,True,True,False,True,False,True,False,False,False,False,False]],[[False,True,False,False,True,True,True,False,True,False,False,True,False],[True,False,False,False,True,True,False,False,False,False,True,True,True],[True,True,False,True,True,False,False,False,False,False,True,True,False],[False,False,False,False,False,True,False,False,True,True,True,True,True],[True,False,False,False,True,True,True,True,False,True,False,True,True],[False,True,False,False,True,False,False,True,False,False,False,False,False],[True,True,True,True,False,False,True,False,True,False,True,False,False],[False,True,False,True,False,False,False,False,False,True,True,False,False],[True,False,False,False,False,True,True,True,False,False,False,True,False],[True,False,False,True,False,False,True,False,True,True,False,True,False],[True,False,True,True,False,False,False,False,False,False,True,False,False],[False,False,False,True,False,True,True,False,False,True,False,True,True],[True,True,False,False,True,True,False,False,False,False,False,False,False],[True,True,False,True,True,False,True,True,True,True,False,True,False],[False,False,False,False,False,False,True,False,False,False,True,True,False]],[[True,True,False,False,False,True,True,False,False,False,False,True,True],[True,True,True,False,True,True,True,True,True,True,True,False,True],[False,False,False,True,False,True,False,True,True,False,False,False,False],[True,False,False,False,True,False,True,False,False,False,False,True,False],[True,False,True,False,True,True,False,True,False,True,True,True,False],[False,True,False,True,False,True,True,False,False,True,False,True,True],[True,False,True,False,False,True,True,True,True,False,True,True,False],[True,False,True,False,False,True,False,True,False,False,False,False,False],[False,True,True,False,False,False,False,False,False,False,True,True,True],[False,False,False,True,False,False,False,True,False,False,False,False,True],[True,False,False,True,True,False,False,False,False,False,False,False,False],[False,False,True,False,False,True,False,False,True,False,False,True,True],[True,True,True,True,True,False,False,True,True,True,True,True,True],[False,False,True,False,False,True,True,False,True,True,True,True,True],[False,True,False,True,False,True,True,False,False,False,False,False,True]],[[False,True,False,True,False,False,True,True,True,False,True,False,False],[False,True,True,False,False,False,True,False,True,False,True,False,False],[False,False,False,False,True,False,False,False,False,False,False,True,False],[True,True,True,True,True,True,False,True,True,True,True,True,True],[False,True,True,True,True,True,True,True,True,True,False,True,True],[False,False,True,True,False,True,True,True,False,False,False,True,True],[False,False,False,True,True,True,False,False,False,True,True,True,False],[True,False,False,False,True,False,False,True,False,False,False,True,True],[False,True,False,True,True,False,True,True,True,True,False,True,True],[False,False,True,False,False,False,False,True,False,False,True,True,True],[True,True,True,False,True,True,False,True,True,True,True,False,False],[False,True,True,True,True,True,True,False,True,True,False,False,False],[False,False,False,True,True,True,True,False,False,False,True,False,True],[False,True,False,True,True,False,False,False,True,True,False,False,True],[True,True,True,True,False,False,True,False,True,False,True,False,False]],[[True,False,False,True,True,False,False,True,True,False,True,False,False],[False,True,False,False,True,False,False,False,True,False,False,True,False],[False,True,True,False,False,True,True,False,False,False,False,True,False],[False,True,True,False,True,False,True,False,False,False,False,False,True],[True,False,True,False,False,True,False,False,False,False,True,True,False],[True,True,False,False,True,False,True,True,False,True,True,False,True],[True,False,True,False,True,False,False,True,True,True,False,True,True],[False,True,False,True,True,True,True,True,False,False,False,True,True],[False,False,False,False,True,False,True,False,False,False,True,False,True],[False,True,False,True,False,False,False,False,False,True,False,True,False],[False,True,False,True,True,True,False,True,True,True,True,False,False],[True,True,True,False,False,True,True,False,False,False,True,False,False],[True,True,False,False,True,False,True,False,False,False,True,False,False],[False,True,True,True,True,True,False,False,True,False,True,False,True],[True,False,False,True,True,True,False,True,True,False,False,False,False]],[[False,True,True,False,True,True,True,False,False,True,True,False,True],[False,True,True,True,False,False,True,False,False,False,True,False,False],[False,False,False,False,False,False,True,True,False,False,True,True,True],[True,False,False,False,False,True,True,True,False,True,True,True,True],[True,False,False,False,False,False,False,False,False,True,False,False,False],[False,False,True,True,True,True,False,False,True,False,True,False,True],[True,True,False,False,False,False,False,False,False,False,False,False,False],[False,True,False,False,False,False,True,True,False,False,False,False,False],[True,False,True,True,True,False,False,True,True,False,True,True,False],[True,False,False,False,False,True,True,True,True,True,True,False,True],[True,True,True,True,True,True,True,True,False,False,True,True,False],[False,True,True,False,False,True,False,False,True,False,True,False,True],[True,False,True,True,True,False,False,False,False,False,True,True,True],[False,False,False,True,False,True,False,True,True,False,False,True,True],[True,True,False,False,True,True,False,False,True,True,False,True,True]]], dtype = "bool")#candidate|280|(9, 15, 13)|const|bool
bop_281 = relay.multiply(bop_231.astype('int32'), relay.reshape(const_280.astype('int32'), relay.shape_of(bop_231))) # shape=(9, 15, 13)
var_284 = relay.var("var_284", dtype = "float64", shape = (9, 15, 13))#candidate|284|(9, 15, 13)|var|float64
bop_285 = relay.floor_divide(uop_259.astype('float32'), relay.reshape(var_284.astype('float32'), relay.shape_of(uop_259))) # shape=(9, 15, 13)
uop_288 = relay.log2(bop_277.astype('float64')) # shape=(9, 15, 13)
bop_290 = relay.not_equal(uop_288.astype('bool'), relay.reshape(bop_210.astype('bool'), relay.shape_of(uop_288))) # shape=(9, 15, 13)
uop_293 = relay.erf(bop_290.astype('float64')) # shape=(9, 15, 13)
var_295 = relay.var("var_295", dtype = "float64", shape = (9, 15, 13))#candidate|295|(9, 15, 13)|var|float64
bop_296 = relay.add(bop_269.astype('int8'), relay.reshape(var_295.astype('int8'), relay.shape_of(bop_269))) # shape=(9, 15, 13)
output = relay.Tuple([uop_208,bop_213,call_224,const_225,bop_234,uop_240,bop_242,uop_245,uop_249,bop_251,bop_254,call_257,call_265,const_266,bop_273,bop_281,bop_285,uop_293,bop_296,])
output2 = relay.Tuple([uop_208,bop_213,call_226,const_225,bop_234,uop_240,bop_242,uop_245,uop_249,bop_251,bop_254,call_258,call_267,const_266,bop_273,bop_281,bop_285,uop_293,bop_296,])
func_299 = relay.Function([var_186,var_216,var_268,var_276,var_284,var_295,], output)
mod['func_299'] = func_299
mod = relay.transform.InferType()(mod)
var_300 = relay.var("var_300", dtype = "float32", shape = (9, 15, 13))#candidate|300|(9, 15, 13)|var|float32
var_301 = relay.var("var_301", dtype = "bool", shape = (9, 15, 13))#candidate|301|(9, 15, 13)|var|bool
var_302 = relay.var("var_302", dtype = "bool", shape = (9, 15, 13))#candidate|302|(9, 15, 13)|var|bool
var_303 = relay.var("var_303", dtype = "bool", shape = (9, 15, 13))#candidate|303|(9, 15, 13)|var|bool
var_304 = relay.var("var_304", dtype = "float64", shape = (9, 15, 13))#candidate|304|(9, 15, 13)|var|float64
var_305 = relay.var("var_305", dtype = "float64", shape = (9, 15, 13))#candidate|305|(9, 15, 13)|var|float64
output = func_299(var_300,var_301,var_302,var_303,var_304,var_305,)
func_306 = relay.Function([var_300,var_301,var_302,var_303,var_304,var_305,], output)
mutated_mod['func_306'] = func_306
mutated_mod = relay.transform.InferType()(mutated_mod)
const_308 = relay.const([-8.216618,-6.948219,6.957812,-1.484451], dtype = "float64")#candidate|308|(4,)|const|float64
uop_309 = relay.sin(const_308.astype('float64')) # shape=(4,)
bop_311 = relay.equal(uop_309.astype('bool'), relay.reshape(const_308.astype('bool'), relay.shape_of(uop_309))) # shape=(4,)
bop_314 = relay.bitwise_and(uop_309.astype('int8'), relay.reshape(bop_311.astype('int8'), relay.shape_of(uop_309))) # shape=(4,)
bop_317 = relay.minimum(const_308.astype('uint64'), relay.reshape(uop_309.astype('uint64'), relay.shape_of(const_308))) # shape=(4,)
uop_320 = relay.cos(const_308.astype('float32')) # shape=(4,)
uop_322 = relay.sinh(uop_320.astype('float32')) # shape=(4,)
output = relay.Tuple([bop_314,bop_317,uop_322,])
output2 = relay.Tuple([bop_314,bop_317,uop_322,])
F = relay.Function([], output)
mod['main'] = F
mod = relay.transform.InferType()(mod)
print('==========mod==========')
print(mod.astext(show_meta_data=False))
print('===================================')
F = relay.Function([], output2)
mutated_mod['main'] = F
mutated_mod = relay.transform.InferType()(mutated_mod)
print('==========mutated_mod==========')
print(mutated_mod.astext(show_meta_data=False))
print('===================================')
graph, lib, params = relay.build(mod, target='llvm')
module1 = graph_runtime.create(graph, lib, tvm.device('llvm',0))
intrp2 = relay.build_module.create_executor('graph', mod, tvm.device('llvm',0),'llvm')
intrp3 = relay.build_module.create_executor('debug', mod, tvm.device('llvm',0),'llvm')
intrp4 = relay.build_module.create_executor('vm', mod, tvm.device('llvm',0),'llvm')
graph, lib, params = relay.build(mod, target='cuda')
module5 = graph_runtime.create(graph, lib, tvm.device('cuda',0))
intrp6 = relay.build_module.create_executor('graph', mod, tvm.device('cuda',0),'cuda')
intrp7 = relay.build_module.create_executor('debug', mod, tvm.device('cuda',0),'cuda')
intrp8 = relay.build_module.create_executor('vm', mod, tvm.device('cuda',0),'cuda')
seq = Sequential([
	relay.transform.AlterOpLayout(),
	relay.transform.AnnotateSpans(),
	relay.transform.BatchingOps(),
	relay.transform.CanonicalizeCast(),
	relay.transform.CanonicalizeOps(),
	relay.transform.DeadCodeElimination(),
	relay.transform.DynamicToStatic(),
	relay.transform.FastMath(),
	relay.transform.FirstOrderGradient(),
	relay.transform.EliminateCommonSubexpr(),
	relay.transform.MergeCompilerRegions(),
	relay.transform.Inline(),
	relay.transform.LambdaLift(),
	relay.transform.LazyGradientInit(),
	relay.transform.PartialEvaluate(),
	relay.transform.Legalize(),
	relay.transform.FoldConstant(),
	relay.transform.ToANormalForm(),
	relay.transform.ToGraphNormalForm(),
	relay.transform.SimplifyInference(),
	relay.transform.ToBasicBlockNormalForm(),
	relay.transform.FuseOps(3),
	relay.transform.DefuseOps(),
	relay.transform.SimplifyExpr(),
])
mod = seq(mod)
print(mod.astext(show_meta_data=False))
graph, lib, params = relay.build(mod, target='llvm')
module9 = graph_runtime.create(graph, lib, tvm.device('llvm',0))
intrp10 = relay.build_module.create_executor('graph', mod, tvm.device('llvm',0),'llvm')
intrp11 = relay.build_module.create_executor('debug', mod, tvm.device('llvm',0),'llvm')
intrp12 = relay.build_module.create_executor('vm', mod, tvm.device('llvm',0),'llvm')
graph, lib, params = relay.build(mod, target='cuda')
module13 = graph_runtime.create(graph, lib, tvm.device('cuda',0))
intrp14 = relay.build_module.create_executor('graph', mod, tvm.device('cuda',0),'cuda')
intrp15 = relay.build_module.create_executor('debug', mod, tvm.device('cuda',0),'cuda')
intrp16 = relay.build_module.create_executor('vm', mod, tvm.device('cuda',0),'cuda')
graph, lib, params = relay.build(mutated_mod, target='llvm')
module17 = graph_runtime.create(graph, lib, tvm.device('llvm',0))
intrp18 = relay.build_module.create_executor('graph', mutated_mod, tvm.device('llvm',0),'llvm')
intrp19 = relay.build_module.create_executor('debug', mutated_mod, tvm.device('llvm',0),'llvm')
intrp20 = relay.build_module.create_executor('vm', mutated_mod, tvm.device('llvm',0),'llvm')
graph, lib, params = relay.build(mutated_mod, target='cuda')
module21 = graph_runtime.create(graph, lib, tvm.device('cuda',0))
intrp22 = relay.build_module.create_executor('graph', mutated_mod, tvm.device('cuda',0),'cuda')
intrp23 = relay.build_module.create_executor('debug', mutated_mod, tvm.device('cuda',0),'cuda')
intrp24 = relay.build_module.create_executor('vm', mutated_mod, tvm.device('cuda',0),'cuda')
module1.set_input(**params)
module1.run()
res2 = intrp2.evaluate()()
res3 = intrp3.evaluate()()
res4 = intrp4.evaluate()()
res2 = vmobj_to_list(res2)
res3 = vmobj_to_list(res3)
res4 = vmobj_to_list(res4)
res1_0 = module1.get_output(0).asnumpy()
res2_0 = res2[0].asnumpy()
res3_0 = res3[0].asnumpy()
res4_0 = res4[0].asnumpy()
np.testing.assert_allclose(res1_0 ,res2_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_0 ,res3_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_0 ,res4_0, atol=1e-3, rtol=1e-3)
(res1_0 == res2_0).all()
(res1_0 == res3_0).all()
(res1_0 == res4_0).all()
res1_1 = module1.get_output(1).asnumpy()
res2_1 = res2[1].asnumpy()
res3_1 = res3[1].asnumpy()
res4_1 = res4[1].asnumpy()
np.testing.assert_allclose(res1_1 ,res2_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_1 ,res3_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_1 ,res4_1, atol=1e-3, rtol=1e-3)
(res1_1 == res2_1).all()
(res1_1 == res3_1).all()
(res1_1 == res4_1).all()
res1_2 = module1.get_output(2).asnumpy()
res2_2 = res2[2].asnumpy()
res3_2 = res3[2].asnumpy()
res4_2 = res4[2].asnumpy()
np.testing.assert_allclose(res1_2 ,res2_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_2 ,res3_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_2 ,res4_2, atol=1e-3, rtol=1e-3)
(res1_2 == res2_2).all()
(res1_2 == res3_2).all()
(res1_2 == res4_2).all()
module5.set_input(**params)
module5.run()
res6 = intrp6.evaluate()()
res7 = intrp7.evaluate()()
res8 = intrp8.evaluate()()
res6 = vmobj_to_list(res6)
res7 = vmobj_to_list(res7)
res8 = vmobj_to_list(res8)
res5_0 = module5.get_output(0).asnumpy()
res6_0 = res6[0].asnumpy()
res7_0 = res7[0].asnumpy()
res8_0 = res8[0].asnumpy()
np.testing.assert_allclose(res5_0 ,res6_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_0 ,res7_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_0 ,res8_0, atol=1e-3, rtol=1e-3)
(res5_0 == res6_0).all()
(res5_0 == res7_0).all()
(res5_0 == res8_0).all()
res5_1 = module5.get_output(1).asnumpy()
res6_1 = res6[1].asnumpy()
res7_1 = res7[1].asnumpy()
res8_1 = res8[1].asnumpy()
np.testing.assert_allclose(res5_1 ,res6_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_1 ,res7_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_1 ,res8_1, atol=1e-3, rtol=1e-3)
(res5_1 == res6_1).all()
(res5_1 == res7_1).all()
(res5_1 == res8_1).all()
res5_2 = module5.get_output(2).asnumpy()
res6_2 = res6[2].asnumpy()
res7_2 = res7[2].asnumpy()
res8_2 = res8[2].asnumpy()
np.testing.assert_allclose(res5_2 ,res6_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_2 ,res7_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_2 ,res8_2, atol=1e-3, rtol=1e-3)
(res5_2 == res6_2).all()
(res5_2 == res7_2).all()
(res5_2 == res8_2).all()
module9.set_input(**params)
module9.run()
res10 = intrp10.evaluate()()
res11 = intrp11.evaluate()()
res12 = intrp12.evaluate()()
res10 = vmobj_to_list(res10)
res11 = vmobj_to_list(res11)
res12 = vmobj_to_list(res12)
res9_0 = module9.get_output(0).asnumpy()
res10_0 = res10[0].asnumpy()
res11_0 = res11[0].asnumpy()
res12_0 = res12[0].asnumpy()
np.testing.assert_allclose(res9_0 ,res10_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_0 ,res11_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_0 ,res12_0, atol=1e-3, rtol=1e-3)
(res9_0 == res10_0).all()
(res9_0 == res11_0).all()
(res9_0 == res12_0).all()
res9_1 = module9.get_output(1).asnumpy()
res10_1 = res10[1].asnumpy()
res11_1 = res11[1].asnumpy()
res12_1 = res12[1].asnumpy()
np.testing.assert_allclose(res9_1 ,res10_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_1 ,res11_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_1 ,res12_1, atol=1e-3, rtol=1e-3)
(res9_1 == res10_1).all()
(res9_1 == res11_1).all()
(res9_1 == res12_1).all()
res9_2 = module9.get_output(2).asnumpy()
res10_2 = res10[2].asnumpy()
res11_2 = res11[2].asnumpy()
res12_2 = res12[2].asnumpy()
np.testing.assert_allclose(res9_2 ,res10_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_2 ,res11_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_2 ,res12_2, atol=1e-3, rtol=1e-3)
(res9_2 == res10_2).all()
(res9_2 == res11_2).all()
(res9_2 == res12_2).all()
module13.set_input(**params)
module13.run()
res14 = intrp14.evaluate()()
res15 = intrp15.evaluate()()
res16 = intrp16.evaluate()()
res14 = vmobj_to_list(res14)
res15 = vmobj_to_list(res15)
res16 = vmobj_to_list(res16)
res13_0 = module13.get_output(0).asnumpy()
res14_0 = res14[0].asnumpy()
res15_0 = res15[0].asnumpy()
res16_0 = res16[0].asnumpy()
np.testing.assert_allclose(res13_0 ,res14_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_0 ,res15_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_0 ,res16_0, atol=1e-3, rtol=1e-3)
(res13_0 == res14_0).all()
(res13_0 == res15_0).all()
(res13_0 == res16_0).all()
res13_1 = module13.get_output(1).asnumpy()
res14_1 = res14[1].asnumpy()
res15_1 = res15[1].asnumpy()
res16_1 = res16[1].asnumpy()
np.testing.assert_allclose(res13_1 ,res14_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_1 ,res15_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_1 ,res16_1, atol=1e-3, rtol=1e-3)
(res13_1 == res14_1).all()
(res13_1 == res15_1).all()
(res13_1 == res16_1).all()
res13_2 = module13.get_output(2).asnumpy()
res14_2 = res14[2].asnumpy()
res15_2 = res15[2].asnumpy()
res16_2 = res16[2].asnumpy()
np.testing.assert_allclose(res13_2 ,res14_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_2 ,res15_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_2 ,res16_2, atol=1e-3, rtol=1e-3)
(res13_2 == res14_2).all()
(res13_2 == res15_2).all()
(res13_2 == res16_2).all()
module17.set_input(**params)
module17.run()
res18 = intrp18.evaluate()()
res19 = intrp19.evaluate()()
res20 = intrp20.evaluate()()
res18 = vmobj_to_list(res18)
res19 = vmobj_to_list(res19)
res20 = vmobj_to_list(res20)
res17_0 = module17.get_output(0).asnumpy()
res18_0 = res18[0].asnumpy()
res19_0 = res19[0].asnumpy()
res20_0 = res20[0].asnumpy()
np.testing.assert_allclose(res17_0 ,res18_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_0 ,res19_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_0 ,res20_0, atol=1e-3, rtol=1e-3)
(res17_0 == res18_0).all()
(res17_0 == res19_0).all()
(res17_0 == res20_0).all()
res17_1 = module17.get_output(1).asnumpy()
res18_1 = res18[1].asnumpy()
res19_1 = res19[1].asnumpy()
res20_1 = res20[1].asnumpy()
np.testing.assert_allclose(res17_1 ,res18_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_1 ,res19_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_1 ,res20_1, atol=1e-3, rtol=1e-3)
(res17_1 == res18_1).all()
(res17_1 == res19_1).all()
(res17_1 == res20_1).all()
res17_2 = module17.get_output(2).asnumpy()
res18_2 = res18[2].asnumpy()
res19_2 = res19[2].asnumpy()
res20_2 = res20[2].asnumpy()
np.testing.assert_allclose(res17_2 ,res18_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_2 ,res19_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_2 ,res20_2, atol=1e-3, rtol=1e-3)
(res17_2 == res18_2).all()
(res17_2 == res19_2).all()
(res17_2 == res20_2).all()
module21.set_input(**params)
module21.run()
res22 = intrp22.evaluate()()
res23 = intrp23.evaluate()()
res24 = intrp24.evaluate()()
res22 = vmobj_to_list(res22)
res23 = vmobj_to_list(res23)
res24 = vmobj_to_list(res24)
res21_0 = module21.get_output(0).asnumpy()
res22_0 = res22[0].asnumpy()
res23_0 = res23[0].asnumpy()
res24_0 = res24[0].asnumpy()
np.testing.assert_allclose(res21_0 ,res22_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_0 ,res23_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_0 ,res24_0, atol=1e-3, rtol=1e-3)
(res21_0 == res22_0).all()
(res21_0 == res23_0).all()
(res21_0 == res24_0).all()
res21_1 = module21.get_output(1).asnumpy()
res22_1 = res22[1].asnumpy()
res23_1 = res23[1].asnumpy()
res24_1 = res24[1].asnumpy()
np.testing.assert_allclose(res21_1 ,res22_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_1 ,res23_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_1 ,res24_1, atol=1e-3, rtol=1e-3)
(res21_1 == res22_1).all()
(res21_1 == res23_1).all()
(res21_1 == res24_1).all()
res21_2 = module21.get_output(2).asnumpy()
res22_2 = res22[2].asnumpy()
res23_2 = res23[2].asnumpy()
res24_2 = res24[2].asnumpy()
np.testing.assert_allclose(res21_2 ,res22_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_2 ,res23_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_2 ,res24_2, atol=1e-3, rtol=1e-3)
(res21_2 == res22_2).all()
(res21_2 == res23_2).all()
(res21_2 == res24_2).all()

'''9: TVMFuncCall
8: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)
7: tvm::transform::Pass::operator()(tvm::IRModule) const
6: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
5: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
4: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
3: tvm::relay::transform::FunctionPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
2: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::relay::Function (tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::LazyGradientInit()::{lambda(tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)#1}>(tvm::relay::transform::LazyGradientInit()::{lambda(tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)
1: tvm::relay::LazyGradientInit(tvm::RelayExpr const&, tvm::IRModule)
0: tvm::relay::CheckFeature(tvm::RelayExpr const&, tvm::relay::FeatureSet const&)

'''