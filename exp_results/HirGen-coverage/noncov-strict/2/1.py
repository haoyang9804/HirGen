import tvm
from tvm import relay
from tvm.ir.transform import Sequential
from tvm.contrib import graph_runtime
import numpy as np
def vmobj_to_list(o, dtype="float32"):
    if isinstance(o, tvm.nd.NDArray):
        return [o]
    elif isinstance(o, tvm.runtime.container.ADT):
        result = []
        for f in o:
            result.extend(vmobj_to_list(f, dtype))
        return result
    else:
        return o


mod = tvm.IRModule()
mutated_mod = tvm.IRModule()
var_0 = relay.var("var_0", dtype = "float64", shape = (2,))#candidate|0|(2,)|var|float64
var_1 = relay.var("var_1", dtype = "float64", shape = (2,))#candidate|1|(2,)|var|float64
bop_2 = relay.floor_divide(var_0.astype('float64'), relay.reshape(var_1.astype('float64'), relay.shape_of(var_0))) # shape=(2,)
var_5 = relay.var("var_5", dtype = "float64", shape = (2,))#candidate|5|(2,)|var|float64
bop_6 = relay.greater_equal(bop_2.astype('bool'), relay.reshape(var_5.astype('bool'), relay.shape_of(bop_2))) # shape=(2,)
bop_9 = relay.bitwise_xor(bop_6.astype('int16'), relay.reshape(var_0.astype('int16'), relay.shape_of(bop_6))) # shape=(2,)
bop_12 = relay.less_equal(var_5.astype('bool'), relay.reshape(var_1.astype('bool'), relay.shape_of(var_5))) # shape=(2,)
uop_15 = relay.log10(bop_9.astype('float64')) # shape=(2,)
bop_17 = relay.bitwise_or(var_1.astype('uint32'), relay.reshape(bop_2.astype('uint32'), relay.shape_of(var_1))) # shape=(2,)
const_20 = relay.const([1.521646,-8.864602], dtype = "float64")#candidate|20|(2,)|const|float64
bop_21 = relay.maximum(uop_15.astype('int64'), relay.reshape(const_20.astype('int64'), relay.shape_of(uop_15))) # shape=(2,)
bop_24 = relay.subtract(uop_15.astype('uint32'), relay.reshape(bop_17.astype('uint32'), relay.shape_of(uop_15))) # shape=(2,)
const_27 = relay.const([5.573240,-9.012714], dtype = "float64")#candidate|27|(2,)|const|float64
bop_28 = relay.greater(var_1.astype('bool'), relay.reshape(const_27.astype('bool'), relay.shape_of(var_1))) # shape=(2,)
const_31 = relay.const([-10,-7], dtype = "int64")#candidate|31|(2,)|const|int64
bop_32 = relay.logical_xor(bop_21.astype('int8'), relay.reshape(const_31.astype('int8'), relay.shape_of(bop_21))) # shape=(2,)
const_35 = relay.const([7,-8], dtype = "uint32")#candidate|35|(2,)|const|uint32
bop_36 = relay.maximum(bop_24.astype('int16'), relay.reshape(const_35.astype('int16'), relay.shape_of(bop_24))) # shape=(2,)
bop_39 = relay.minimum(bop_36.astype('uint8'), relay.reshape(bop_6.astype('uint8'), relay.shape_of(bop_36))) # shape=(2,)
uop_42 = relay.sinh(const_20.astype('float64')) # shape=(2,)
uop_44 = relay.log2(const_20.astype('float32')) # shape=(2,)
output = relay.Tuple([bop_12,bop_28,bop_32,bop_39,uop_42,uop_44,])
output2 = relay.Tuple([bop_12,bop_28,bop_32,bop_39,uop_42,uop_44,])
func_46 = relay.Function([var_0,var_1,var_5,], output)
mod['func_46'] = func_46
mod = relay.transform.InferType()(mod)
var_47 = relay.var("var_47", dtype = "float64", shape = (2,))#candidate|47|(2,)|var|float64
var_48 = relay.var("var_48", dtype = "float64", shape = (2,))#candidate|48|(2,)|var|float64
var_49 = relay.var("var_49", dtype = "float64", shape = (2,))#candidate|49|(2,)|var|float64
output = func_46(var_47,var_48,var_49,)
func_50 = relay.Function([var_47,var_48,var_49,], output)
mutated_mod['func_50'] = func_50
mutated_mod = relay.transform.InferType()(mutated_mod)
var_52 = relay.var("var_52", dtype = "float64", shape = (7,))#candidate|52|(7,)|var|float64
const_53 = relay.const([-2.344905,0.336561,7.354313,-2.744549,-3.187633,-3.996032,0.437187], dtype = "float64")#candidate|53|(7,)|const|float64
bop_54 = relay.divide(var_52.astype('float64'), relay.reshape(const_53.astype('float64'), relay.shape_of(var_52))) # shape=(7,)
uop_57 = relay.atanh(const_53.astype('float64')) # shape=(7,)
output = relay.Tuple([bop_54,uop_57,])
output2 = relay.Tuple([bop_54,uop_57,])
func_59 = relay.Function([var_52,], output)
mod['func_59'] = func_59
mod = relay.transform.InferType()(mod)
var_60 = relay.var("var_60", dtype = "float64", shape = (7,))#candidate|60|(7,)|var|float64
output = func_59(var_60)
func_61 = relay.Function([var_60], output)
mutated_mod['func_61'] = func_61
mutated_mod = relay.transform.InferType()(mutated_mod)
var_63 = relay.var("var_63", dtype = "float32", shape = (14, 15, 14))#candidate|63|(14, 15, 14)|var|float32
uop_64 = relay.tan(var_63.astype('float32')) # shape=(14, 15, 14)
bop_66 = relay.add(uop_64.astype('int16'), relay.reshape(var_63.astype('int16'), relay.shape_of(uop_64))) # shape=(14, 15, 14)
uop_69 = relay.atan(bop_66.astype('float32')) # shape=(14, 15, 14)
var_71 = relay.var("var_71", dtype = "float32", shape = (14, 15, 14))#candidate|71|(14, 15, 14)|var|float32
bop_72 = relay.mod(var_63.astype('float64'), relay.reshape(var_71.astype('float64'), relay.shape_of(var_63))) # shape=(14, 15, 14)
const_75 = relay.const([[[-10,8,10,4,-7,1,4,5,-6,-5,9,-1,3,-4],[-8,8,-1,-4,10,5,1,-1,9,-4,1,1,3,3],[-2,6,6,-10,8,-8,-1,6,-10,-6,-3,3,10,-7],[8,8,7,-1,-7,9,-2,4,1,-5,8,-9,2,8],[6,4,3,3,3,2,5,-7,-8,10,2,-10,7,-1],[1,-10,5,2,-3,10,1,7,-5,2,-5,3,-8,-8],[-4,5,-10,-4,-6,-3,-3,6,-4,7,7,-3,2,4],[10,-8,-2,-2,7,-5,2,1,-8,-9,-1,-2,-6,5],[-10,1,-10,4,1,2,4,10,-5,1,-1,8,7,-2],[-2,4,-5,-1,5,7,-3,-5,-8,3,7,1,-6,-9],[8,9,-8,3,9,8,-3,-3,8,3,4,-1,2,8],[2,3,1,-1,7,4,-10,-2,-1,-9,-3,-5,8,8],[10,10,-7,2,-4,-9,-9,-7,-7,-1,-5,7,5,-7],[-8,5,-4,9,-7,-1,4,-2,-5,1,1,2,6,-6],[-9,-4,-1,-4,5,6,4,2,7,10,-6,-6,5,-5]],[[-7,-10,5,5,4,-10,-5,-10,4,-7,-10,5,-8,-5],[10,3,-10,-6,-8,10,2,-2,6,8,-8,5,3,-3],[2,5,-7,-1,-1,1,-10,3,3,-3,-9,-3,5,2],[7,-9,5,-2,2,7,-4,3,1,8,-3,-5,9,7],[5,1,9,2,6,4,9,3,2,-7,-4,-9,7,9],[-3,1,-10,-9,-6,2,-6,2,-10,1,3,-6,-5,5],[-10,-8,-3,-10,-3,1,-1,1,-9,-3,10,-2,-1,1],[3,8,2,-6,-6,5,7,-1,9,6,-7,-9,-2,-1],[9,-3,-9,8,8,6,2,5,7,8,10,-4,-2,3],[5,-8,-7,7,-1,-9,10,-7,5,2,10,10,3,-4],[-8,-8,2,-7,9,6,10,-3,1,3,-1,-9,-4,-10],[4,1,-2,5,6,-2,-6,9,4,-6,-1,10,-3,-5],[-8,3,9,-4,-2,-5,-10,7,5,-2,7,3,-7,2],[-2,9,1,1,-6,3,1,10,4,7,-3,-8,7,8],[4,5,6,5,-6,9,9,-1,9,4,-9,5,-2,-4]],[[-4,-2,-2,-4,9,-8,-6,-6,-1,7,-10,-5,4,3],[-3,-4,9,7,4,-4,1,-7,-10,-3,-2,1,5,-3],[6,-6,2,5,-7,5,-6,-4,10,5,6,3,10,10],[-1,-4,-8,5,-10,3,5,-7,-4,7,2,-6,-9,6],[4,-3,-10,2,-7,2,-7,5,1,-10,-4,-3,-10,7],[-9,-9,1,-7,-10,3,-6,-5,7,3,-3,-5,4,5],[6,-3,5,9,5,10,-5,-5,9,-1,1,6,-1,-10],[10,6,7,2,-3,-9,5,6,-4,10,-2,-2,9,6],[1,-2,1,-7,-9,-10,8,-3,-3,-6,9,-2,8,-3],[-2,-4,2,1,8,-2,7,-1,5,9,-4,-5,-10,3],[9,-5,-4,-3,9,-2,2,-3,-7,-3,8,-8,-8,5],[-10,-7,6,-1,3,7,-7,-8,-2,-5,5,9,1,-8],[-2,6,5,2,-3,2,-6,9,-7,-2,6,-7,-7,-6],[8,5,9,10,3,5,-5,-6,-7,4,-10,4,6,-8],[-10,1,-10,-7,-8,-5,1,10,7,8,-1,-8,1,-6]],[[3,-9,-10,-2,5,-9,8,-7,-4,-4,-3,4,5,4],[4,-2,-5,4,9,6,-7,10,-1,-2,-2,-5,-1,10],[3,-1,-3,7,-3,-3,-7,8,-4,-9,3,-9,10,-3],[-4,-6,-4,-5,-1,5,1,6,-7,-4,-5,5,4,7],[9,-4,1,-2,-8,-6,-7,-5,-10,-10,7,7,5,-10],[-7,3,-6,-1,-9,-4,9,-8,-10,9,-3,-7,1,2],[8,-6,-8,-5,10,-3,-10,-7,-6,7,7,-8,-3,1],[-8,3,-7,-3,10,1,-3,-10,-1,1,-2,-5,-4,-9],[9,2,-5,5,6,8,5,7,-6,-10,3,-6,2,4],[-6,3,-3,3,2,1,-6,-3,10,9,-6,-3,-2,2],[10,-10,-6,-2,-7,-8,-4,6,-10,3,8,6,-2,-1],[-7,10,8,4,2,5,-2,8,-6,6,-3,5,-10,5],[1,-8,-8,6,8,-2,-7,-10,1,-4,4,2,10,1],[2,6,2,2,4,-8,7,3,-6,-4,2,-6,10,6],[-9,4,2,5,-3,6,4,-10,-1,-8,7,-5,-9,-5]],[[-1,1,-7,1,4,-3,-2,4,2,-10,10,-9,-7,-6],[-7,5,4,-6,-10,2,3,-1,-6,-3,-3,-9,-9,10],[5,4,8,10,5,5,-2,-1,4,-10,-1,7,5,8],[8,-2,5,5,-5,-7,10,10,-9,-9,-5,1,3,9],[-6,2,5,7,9,-3,-8,7,-2,-1,7,4,-10,-5],[5,-1,-1,4,-8,-3,-4,3,7,-9,-6,8,10,-3],[-6,-3,4,-3,8,8,10,-5,8,-8,10,3,-8,9],[-4,-8,3,-3,-7,10,4,3,1,-10,-8,5,-6,1],[-9,1,5,4,-3,4,3,-7,-6,-1,-10,6,-9,-5],[-9,-10,9,2,3,1,-4,9,-1,-6,-9,-3,-10,-7],[2,-8,8,-1,-9,10,-2,-1,-8,-6,7,7,9,-6],[-1,-1,-7,-5,-5,2,9,8,-5,-8,1,1,5,5],[5,4,6,-8,4,-8,10,-3,-3,2,3,-8,-5,-2],[6,6,-1,-9,8,2,3,-1,9,3,6,-10,7,-3],[9,-5,-5,8,3,-4,5,3,5,2,-9,-10,2,5]],[[-9,2,-6,-5,-7,-8,10,-3,10,-4,1,3,-1,-4],[2,-2,10,1,10,8,8,-8,-1,-3,7,8,-3,8],[3,-7,-3,-7,3,-10,5,10,3,-4,-1,7,-6,5],[-7,5,7,4,3,5,-1,-8,-1,2,8,-10,4,-6],[4,10,-6,-1,9,5,9,7,-2,-6,3,9,-3,8],[-8,-6,8,4,-4,-9,10,-4,-1,-7,-6,-8,-1,10],[-7,9,-5,-10,4,-8,-8,-1,8,-7,6,2,9,1],[-6,-3,-9,2,9,6,-5,10,-9,2,-6,-8,3,4],[-9,-1,4,-2,6,7,-4,-9,-7,-2,9,6,5,8],[4,-1,9,-10,7,7,3,-9,9,8,8,-4,6,-4],[6,8,-6,-4,2,-7,5,-2,-8,-7,-10,2,-7,-5],[-8,3,-1,-5,1,-1,3,-1,1,-7,6,-5,1,4],[-6,8,-8,-10,-3,7,4,6,-5,6,-10,-5,10,-3],[-5,-6,6,7,-6,-4,-3,4,8,-5,-7,-8,-7,-3],[1,6,3,-9,10,4,4,-7,-8,4,-1,10,3,4]],[[1,5,-5,9,4,10,7,-2,-1,-8,9,8,5,5],[6,-6,-1,10,-1,-6,9,1,-10,-9,-1,2,10,-8],[-8,1,-6,-2,7,3,-10,-6,-6,7,9,9,-2,10],[10,7,4,-3,-4,-5,4,-10,10,-5,3,4,-7,-4],[3,1,3,-3,-5,-7,-1,3,-2,-10,-10,-9,-7,7],[-6,-3,6,-2,1,7,-4,-8,-7,-10,5,-1,7,10],[-5,-7,9,-7,5,7,7,-3,-8,-7,3,4,-9,3],[-7,9,-9,2,-8,4,-10,-1,-4,-9,-7,-9,-4,-10],[-10,-9,7,10,8,-5,-10,-2,-1,7,-7,-2,-5,-7],[-4,1,4,-4,10,9,7,-6,5,7,-9,5,-3,2],[-8,6,-8,9,-9,-2,-8,-8,-5,1,-10,-7,-5,7],[-9,-5,-8,10,-7,9,-1,-6,-4,-3,-7,-10,-5,8],[-1,-7,3,-9,4,-10,-6,9,-2,6,9,6,6,-5],[-4,2,-9,8,-4,5,-4,-8,-6,10,2,-3,-7,-9],[6,7,-8,-5,-9,-10,-8,10,-2,4,5,-5,2,-10]],[[-8,6,-2,1,-2,-6,7,-6,3,-9,-2,4,-9,-8],[6,1,-6,5,10,5,-2,6,9,6,-6,10,2,-7],[10,1,5,9,1,-7,-9,6,7,3,-2,9,-6,5],[-2,8,-2,-9,2,-6,9,-5,-8,-10,-3,-1,1,-2],[-1,-6,3,-7,4,-10,2,-3,-9,-1,-9,2,-5,-6],[4,-5,7,10,-7,3,-4,2,-8,9,3,-4,3,6],[-8,-4,10,-9,-3,5,7,3,-10,7,10,-3,6,-5],[3,6,-4,6,-4,-9,4,-8,1,-2,6,8,5,-9],[9,1,5,-5,-2,1,4,2,5,10,-1,8,4,-3],[7,2,-6,-10,-4,10,-6,9,-2,-9,-1,4,3,-9],[-5,-6,6,8,4,-5,-3,-4,5,-10,-6,-5,-9,-7],[8,-9,-10,-5,4,-8,-1,5,-9,4,2,-2,-2,5],[3,-2,-8,4,-6,4,-4,8,-7,-1,2,10,-9,4],[7,-1,-1,-1,-5,-9,-6,3,-7,-5,-4,3,-4,-3],[5,-2,-7,5,7,-9,3,-5,2,6,7,-6,-10,10]],[[-3,-6,-2,-3,3,-9,5,5,5,-6,-6,-6,6,7],[-2,1,-1,4,-5,-2,-8,-1,8,-3,-5,-10,3,-5],[10,6,-8,7,-4,-3,-9,-7,4,10,-3,-5,-1,-9],[-2,5,6,-4,-10,6,-2,-5,1,-6,10,-9,10,-9],[-10,7,-3,-4,6,5,-6,2,-9,-9,-8,9,2,1],[1,-2,10,-3,-2,2,-4,5,-10,-10,-5,1,-3,-3],[6,8,6,2,-9,-9,-3,-8,9,-7,-2,8,-5,1],[9,4,8,7,-1,-9,4,-9,10,2,-3,-10,7,10],[-1,9,-5,-5,4,-6,-1,-5,-5,-1,-4,-8,-5,9],[10,-3,2,-9,6,9,-8,-5,2,-5,4,5,1,4],[4,8,-7,-3,3,-4,-9,-1,10,5,7,10,-8,-1],[8,4,1,4,-3,6,2,-6,-5,-6,-4,6,5,-3],[8,-9,-9,8,7,7,10,7,-3,1,-2,2,1,5],[1,6,-2,-8,2,-3,8,8,-5,-10,-9,-8,-1,7],[6,8,2,1,-3,-6,-4,3,-9,2,9,2,-4,-9]],[[1,-6,9,-6,-10,-4,-3,9,9,1,-4,-2,4,10],[-4,-2,-6,2,4,4,-5,8,-9,7,-8,6,9,4],[-1,1,3,10,2,5,-2,-10,7,6,3,-4,2,-3],[-7,4,1,-5,9,-6,-9,-6,9,-7,4,-2,7,-9],[7,9,7,6,-9,6,8,10,2,10,4,6,1,6],[-8,-6,-5,1,-10,-3,7,8,9,5,-6,3,-2,-7],[-8,10,7,1,3,-7,-10,-2,10,-4,-8,2,-4,3],[3,1,-4,-9,9,7,3,-4,6,2,6,5,-5,-9],[10,-6,-3,-6,8,-1,5,-8,4,3,-8,4,-1,1],[5,-6,3,2,7,-4,-3,-1,-5,-9,2,6,9,7],[10,9,-7,4,6,-5,-4,-9,6,-7,2,-9,-10,-8],[7,-2,-3,-6,-5,-10,8,6,-6,9,7,-2,-4,5],[6,-4,7,3,8,-10,-2,3,-8,10,-4,-6,6,1],[-9,-3,-8,-1,4,6,-3,-4,9,-5,-6,2,7,-2],[6,-1,2,1,3,-6,5,-9,-2,-5,8,-9,8,-6]],[[-9,-8,-4,9,4,-5,-3,-4,-6,-9,3,9,-6,8],[2,-9,-6,6,-5,-5,7,4,4,-6,-10,-9,9,-8],[8,10,-2,1,-3,8,-1,7,-7,-8,10,1,9,4],[-10,6,10,10,-5,10,7,8,-2,-6,7,-10,-7,10],[3,-7,-8,-10,9,8,10,-1,-7,5,-5,10,4,-10],[3,9,4,8,9,8,-10,3,8,7,5,9,-4,2],[1,8,-2,1,-5,9,8,3,8,10,-9,3,10,2],[1,1,-7,-7,10,-6,8,10,-5,-6,10,-6,6,3],[-1,9,10,-3,2,8,9,-6,9,3,-10,6,-6,7],[2,-7,6,5,9,-4,2,-3,-6,-6,-5,-9,-9,-3],[7,-8,-1,-6,-4,-2,10,3,8,3,-5,8,-1,4],[-4,-6,8,-4,10,5,-10,6,-5,-4,-3,6,7,7],[-3,-7,-10,9,-8,5,2,1,-9,2,5,6,2,-5],[5,6,-5,-6,5,-10,-8,-2,-9,2,1,3,-9,-4],[-10,-1,-5,5,-9,4,6,-8,3,5,-2,-9,1,9]],[[-10,3,5,6,-3,9,-4,8,1,6,-8,5,8,-5],[7,-8,-8,-8,7,5,7,-3,-9,2,-9,-3,9,-8],[-3,3,6,6,4,-9,9,2,7,8,-8,-5,1,5],[5,7,6,-7,-3,8,-8,2,-10,3,2,5,-4,-1],[10,4,-1,5,-3,2,7,5,7,-3,4,6,7,-5],[2,7,4,-9,-2,-2,9,3,4,-1,7,-9,10,-4],[7,-10,-7,-2,10,-6,6,-9,2,10,10,-6,-7,-6],[10,-6,1,-5,4,-1,-1,-7,7,-3,-8,4,6,6],[4,-8,4,-9,-9,7,-4,-10,-7,1,4,10,6,-1],[3,6,1,-10,-8,-4,-5,-4,9,-3,10,-8,-9,6],[4,8,7,3,-7,-7,-3,-6,9,-7,-2,7,-6,4],[-7,1,-10,-7,2,-6,-6,-6,3,-7,-9,-5,9,-3],[-8,10,-1,-5,1,-7,3,-4,8,7,-1,6,-3,3],[2,6,-6,3,9,-6,1,3,-1,-4,6,-4,8,-7],[10,2,7,-2,-4,10,-3,6,-4,-8,8,5,3,-1]],[[9,3,-9,3,-1,-10,-8,-10,7,-6,7,-5,6,-6],[-1,-4,-6,-2,-10,-10,-10,7,9,10,3,8,-10,2],[-6,8,7,10,7,-6,-6,7,7,5,-9,-5,-3,-4],[-7,-10,7,10,8,-7,3,9,4,-7,-9,-8,-9,3],[-7,4,3,6,-10,6,-8,10,-8,3,6,-4,2,5],[4,-3,5,4,-9,-10,1,-4,8,-10,-6,10,-3,-9],[6,-8,2,-5,7,6,2,-3,-1,1,5,-8,6,-5],[4,-6,5,-5,5,3,9,-6,-5,-3,-9,4,10,7],[1,7,-3,8,-8,5,2,5,-7,-2,3,-7,-2,8],[-6,-9,4,-4,2,-7,4,-4,-9,-8,2,-1,5,-7],[10,8,2,-2,-5,5,8,-8,3,-1,-2,1,8,9],[9,-10,-5,6,10,-4,-6,-2,1,9,3,6,-10,1],[10,-1,8,-9,-4,10,5,-8,-3,5,2,7,5,-1],[4,-5,4,3,-9,-6,-9,6,-10,-3,7,-8,4,-4],[-1,-6,-7,-9,-6,4,7,10,-6,-8,-3,1,10,8]],[[-5,3,-7,10,9,-6,2,-2,-10,2,1,4,2,-5],[-5,4,-5,-5,-7,8,-4,3,-4,2,-7,4,6,-3],[3,9,-9,9,4,-6,-9,-7,9,-9,-4,1,-7,1],[-10,2,-2,-5,-7,-7,-6,-2,-9,8,-8,3,7,-7],[-6,10,5,-3,-4,-8,-1,-2,9,-4,2,6,-8,-3],[-2,3,-1,6,-4,10,7,9,-4,7,-4,2,2,5],[9,-8,8,-7,-4,-4,-1,-6,-4,-6,-5,-4,5,-2],[-5,8,-7,-5,10,6,6,-2,-4,-7,3,-9,-8,7],[10,-10,-8,-1,7,-10,7,-10,-5,1,-1,8,-2,4],[9,-1,5,-5,2,-8,1,5,-5,2,7,7,-4,4],[3,5,-1,2,10,9,-3,-10,-6,-4,-9,-10,2,4],[4,1,6,-9,6,5,9,7,-2,6,-1,-8,9,-5],[-5,6,-7,-7,6,-3,7,8,1,-8,2,8,4,-2],[-4,-3,-7,10,-9,8,3,6,9,-8,9,1,1,3],[-7,-8,1,2,4,4,9,7,-3,-1,-8,3,6,9]]], dtype = "int16")#candidate|75|(14, 15, 14)|const|int16
bop_76 = relay.not_equal(bop_66.astype('bool'), relay.reshape(const_75.astype('bool'), relay.shape_of(bop_66))) # shape=(14, 15, 14)
uop_79 = relay.rsqrt(uop_69.astype('float64')) # shape=(14, 15, 14)
bop_81 = relay.logical_xor(uop_69.astype('uint8'), relay.reshape(const_75.astype('uint8'), relay.shape_of(uop_69))) # shape=(14, 15, 14)
output = relay.Tuple([bop_72,bop_76,uop_79,bop_81,])
output2 = relay.Tuple([bop_72,bop_76,uop_79,bop_81,])
func_84 = relay.Function([var_63,var_71,], output)
mod['func_84'] = func_84
mod = relay.transform.InferType()(mod)
var_85 = relay.var("var_85", dtype = "float32", shape = (14, 15, 14))#candidate|85|(14, 15, 14)|var|float32
var_86 = relay.var("var_86", dtype = "float32", shape = (14, 15, 14))#candidate|86|(14, 15, 14)|var|float32
output = func_84(var_85,var_86,)
func_87 = relay.Function([var_85,var_86,], output)
mutated_mod['func_87'] = func_87
mutated_mod = relay.transform.InferType()(mutated_mod)
const_89 = relay.const([[[8,3,10,-5,-10,-6,-6,8],[-7,-8,5,-4,-9,5,-7,9]],[[-8,-5,-8,7,1,-5,-2,9],[-3,-6,4,5,-5,1,-7,7]],[[-5,-4,-5,10,-4,-4,-10,-8],[1,3,-2,-9,9,8,2,-1]],[[-8,-1,4,10,10,4,9,1],[6,7,2,-4,10,9,7,-1]],[[5,-9,-7,8,-1,5,6,1],[-2,9,-8,9,7,10,-9,1]],[[4,4,-7,9,5,-9,10,1],[10,-9,3,6,7,-5,6,-10]],[[-4,-2,-7,10,-2,4,-2,-5],[-5,3,-2,9,5,-6,10,9]],[[-2,-6,1,2,-6,7,-1,2],[-7,-7,2,-8,2,7,-10,5]],[[-7,-3,-8,2,-3,-3,1,2],[10,9,-5,-8,1,-6,-2,-4]],[[-5,-9,-4,-8,2,-9,9,-5],[1,1,-2,-3,-6,5,2,-1]],[[6,2,5,-5,3,1,7,9],[1,6,-2,-6,7,-8,-3,-8]],[[9,1,9,-2,-1,-2,-9,10],[4,-3,2,5,-3,10,2,-6]],[[-9,-4,2,1,-8,-6,6,9],[10,6,-3,1,4,3,3,-6]]], dtype = "int16")#candidate|89|(13, 2, 8)|const|int16
var_90 = relay.var("var_90", dtype = "int16", shape = (13, 2, 8))#candidate|90|(13, 2, 8)|var|int16
bop_91 = relay.bitwise_xor(const_89.astype('int16'), relay.reshape(var_90.astype('int16'), relay.shape_of(const_89))) # shape=(13, 2, 8)
func_84_call = mod.get_global_var('func_84')
func_87_call = mutated_mod.get_global_var('func_87')
const_95 = relay.const([-0.318214,-6.375442,2.656975,-7.446132,4.023708,3.548769,-1.566471,-5.700464,-1.768897,-8.335561,7.566658,6.616289,4.352310,7.605248,9.275061,1.953716,-2.799201,1.412124,-0.995508,-5.764606,-9.507477,-6.860086,9.874365,7.894158,4.272827,4.834258,0.455872,-4.213060,4.381067,3.719468,3.772638,-6.661173,-8.967107,9.883240,6.513349,5.793517,-8.751964,-1.981978,-2.296440,6.093949,-7.386540,-3.720538,8.557156,-8.818712,-5.675414,-1.992617,-1.196029,8.388265,-5.067654,9.259678,-3.054505,4.325045,-1.205602,-6.841248,7.870342,5.173959,-0.643373,0.056590,-5.291780,-9.521310,9.289694,9.053562,-4.425018,3.569692,8.916323,-3.074490,6.316094,-6.570058,-4.293360,-9.557101,9.727415,2.715107,1.376701,3.231394,-3.106793,3.994903,-4.974801,6.838491,6.766574,-6.564460,-3.957711,3.722555,-0.115864,6.114906,-7.011285,0.293031,1.461747,-0.388391,7.391983,7.546797,4.330620,-6.738129,3.448827,-6.141460,-6.473951,8.548933,-9.988723,-7.302127,4.115388,0.998708,8.363562,9.482727,9.505097,9.683865,8.070047,-0.100041,6.999145,5.417704,-4.587511,-4.211348,-5.246213,6.675870,-4.970891,8.050208,-6.125566,2.503065,3.779983,-8.667783,-9.060613,-8.025421,-2.084540,9.718681,2.901972,-3.096544,-9.335586,-7.546243,5.183200,7.193934,8.870535,0.069799,1.831732,3.695033,8.615133,1.988883,7.097833,2.673454,-5.856787,-1.234151,0.603803,-4.940119,0.195674,-5.564374,-4.405984,-0.143731,2.871617,6.021601,-8.981353,3.381508,1.462830,-0.787525,-1.397974,-6.287246,-5.127978,-5.994636,-1.725979,4.788539,8.075271,-6.272925,-3.486819,5.560636,-5.756683,-2.889329,8.706729,-3.835648,5.368369,-6.840874,-0.315411,-8.456233,0.868868,2.851565,8.184253,9.803901,-8.857587,6.256641,-2.300375,-2.228699,3.732654,3.387402,7.552334,0.889146,-7.580602,-6.660089,8.830400,3.386293,-8.308166,-4.282478,-0.663884,-8.915879,5.304094,0.535753,4.917435,-6.135849,-2.267408,8.777489,7.591715,-1.372713,-0.140180,-9.558117,-6.203574,-9.396041,-6.384458,-6.514587,-5.342571,-5.285165,-9.036042,2.016324,6.696507,7.419268,-2.512810,2.966083,3.462353,4.323578,3.053457,9.596642,-1.597829,-1.591261,-4.037369,6.342248,6.426371,-3.641214,6.226071,2.539788,1.477943,-2.731727,-7.481445,0.426502,-7.896766,1.518590,4.889087,5.760024,7.278017,-3.547874,-6.225200,-2.153762,5.999237,-1.432690,8.749445,-9.795097,-7.437799,-5.971742,-5.802147,-2.460799,-9.367098,-4.150531,0.726472,4.375394,6.667069,-5.778037,5.669068,-2.308066,-6.117974,3.644271,-1.393344,-8.529540,9.030403,9.023362,1.452329,-5.651275,-9.805122,5.480869,-0.856867,-8.906330,-9.981457,2.044544,6.709641,9.244390,-8.284578,0.737916,-8.024549,9.192444,-0.908678,9.223282,1.335140,-3.595134,9.827337,7.092160,-3.761855,7.585744,-6.017810,6.716209,-7.799257,5.973833,2.297280,-6.483135,4.119431,2.568737,-8.919905,8.367332,-2.495014,0.174625,8.385598,3.725835,-0.723475,-3.249495,-9.942116,7.676146,-0.140494,8.926279,1.769229,1.479166,-6.840570,7.875944,-0.818806,-0.433413,-0.915029,-0.606574,-2.681099,4.352045,-8.256784,7.263245,0.534764,-3.795292,-2.488245,-4.872092,3.883329,-6.898280,-4.158404,-6.428073,-7.776224,-1.210630,5.204141,-1.475832,-9.288589,-2.436987,3.610183,9.176807,-8.339694,1.895102,-3.672462,7.776671,2.849826,6.723069,4.169879,-9.334548,-1.691736,-3.341376,5.193237,0.440308,-3.602830,6.003707,6.446853,5.737703,-9.288979,-6.723131,-3.318499,-7.258157,5.405497,6.022964,6.246860,-7.231563,-8.117687,4.280728,3.644172,-3.620279,4.064482,-7.828907,-3.519953,-9.140863,-9.200453,7.699855,-9.360718,-2.419537,9.192463,-1.085754,-4.501177,-2.272095,9.099779,-8.199388,-6.554623,6.529317,-2.606829,8.629672,6.834330,3.253620,-6.150426,-8.568820,-9.093776,0.051888,-9.284001,4.037448,-5.139654,-9.654579,0.484691,6.751824,7.750450,2.400280,-5.597263,-2.716340,4.060046,1.025091,8.432742,-8.112465,-6.674761,7.359310,-5.952227,4.855578,3.074249,-3.287930,2.409304,-8.470818,-3.773177,-3.197810,-9.686008,-1.356325,9.560756,-3.811011,1.506168,-3.485236,-1.510073,7.769268,-7.463487,6.638699,-9.901179,2.445955,8.964889,-2.328136,9.329544,-6.171217,0.431271,3.489322,-5.085356,9.761973,9.135228,-5.314341,-8.403333,-2.966101,-5.527689,-8.528446,4.208009,-0.016701,1.873098,5.347410,-8.745608,5.257583,-1.187844,-9.935531,-3.704212,6.300791,8.752225,0.658876,3.271159,3.058548,7.921035,-5.783897,8.661491,-3.270947,5.769128,3.393341,7.709192,9.408433,-0.292531,2.876564,-6.197744,-2.710385,-0.271380,5.127806,6.025072,0.021925,-0.197457,6.716240,6.079625,-7.639229,0.617423,-5.919700,-9.749290,1.388137,6.274296,3.176441,4.815408,3.543947,3.488013,0.300808,4.638821,-2.545469,-4.020786,8.353435,9.836649,-2.363157,-5.522515,5.647186,-4.358387,0.595764,3.883660,3.297773,-7.826247,-6.814391,5.053529,-7.872371,2.610263,-5.646075,-9.264632,1.227483,-0.211540,6.513684,-5.416519,0.882734,0.951860,-2.316126,-5.986487,4.719412,-8.505334,-6.088057,5.319830,9.486052,4.629882,-3.828323,9.108224,1.393781,8.689819,-5.394637,-5.952171,-7.090082,-0.823361,-1.533072,0.309254,6.250630,-5.207316,1.892959,-9.292086,-3.617408,5.719813,-8.409252,-3.978701,-9.138604,-1.806058,0.464063,-6.637628,-6.366340,-9.653167,6.998925,-0.911005,9.323908,4.378890,-2.949816,1.665665,2.797136,7.065166,-6.377904,-6.289510,1.123311,6.754987,1.528469,-3.365353,2.757677,-7.340537,-0.034074,6.007532,1.054810,6.608790,0.502636,-7.035538,9.798832,-0.595018,5.195732,-4.750532,5.057572,0.478638,0.408862,-4.420657,-7.115911,-0.955357,4.704854,3.391293,-2.432304,-8.537778,6.231549,-9.304460,-9.718989,-2.247723,2.349162,-3.173040,0.749790,1.793364,8.861807,0.459455,8.327423,4.939047,5.228961,1.229818,2.571324,2.897598,9.169039,5.347695,-7.561018,8.216142,-0.623891,-9.693882,-6.365617,-4.627099,6.126910,3.197476,1.615742,5.033069,1.648929,-8.261572,-9.234729,-9.226986,-0.296486,0.788778,6.941179,-2.269220,-7.021064,2.337814,0.308693,4.666090,4.714789,5.817937,8.377353,-7.570260,7.471374,8.025934,-8.822857,9.311704,8.411315,-6.907107,-1.559461,-2.565347,4.452632,3.167024,3.902492,-1.441678,0.314387,-9.257589,-4.334692,-3.464129,9.585864,-0.471046,5.687127,-2.450959,-1.991289,8.666982,-9.697725,-1.604446,-0.727852,-5.834255,-8.792123,-5.749694,-6.635285,-3.229975,5.683203,-1.040925,-3.051211,4.657859,1.440241,-4.352046,-8.827454,-6.813016,4.877646,-1.778671,-7.307723,7.552900,7.889966,-0.157596,-5.246972,8.059512,7.185692,1.166792,-7.029115,7.038576,-9.166534,8.510847,-2.004520,8.940343,-2.785216,0.650950,-3.657470,9.014529,-2.054223,2.104224,-4.041052,7.461421,0.970091,3.009540,7.878309,2.977858,-7.023527,-4.386139,-2.086350,-5.526391,5.210833,0.727770,7.278812,-6.217568,-4.014227,-9.183876,-5.182969,8.999869,-5.933972,7.290229,3.685365,-0.655848,4.778488,-8.836504,-0.555393,2.773342,-1.292522,-5.142330,5.550480,-2.779151,-0.680469,6.225579,-4.981619,-4.296732,9.915844,-9.840517,-2.410526,3.556219,5.376854,1.709425,-5.388934,6.584406,2.770771,-4.778221,-5.095561,2.385506,-4.596495,4.199324,5.958727,6.147784,8.990114,1.784894,-0.332128,-0.266778,0.242261,-0.998421,-3.196005,-5.097325,0.072903,-4.747529,8.612361,-5.396430,-7.294209,-5.229505,-4.337281,9.645954,9.432191,9.505220,9.299414,7.594743,-1.836577,-3.414465,-2.093365,-4.961331,-6.996637,8.985628,-0.697325,3.031677,-0.960571,-9.850554,5.639463,-5.341892,5.034499,8.703643,7.098207,1.795579,-5.635477,-5.048729,-2.311856,-5.982132,-4.905535,9.399792,0.560347,6.542280,-1.128272,-0.402759,7.639236,7.196487,9.079125,8.705074,6.755300,-9.317534,2.929942,-9.596539,7.684058,-6.380304,9.575416,9.658280,-5.978002,-3.561543,-3.368168,-4.105918,0.391382,-9.074509,-9.703202,-4.067391,-0.275833,9.253527,5.379329,-3.561327,-4.913276,-5.165452,-7.346518,9.295080,1.003705,0.445644,-2.908226,3.990979,4.579108,-2.406222,-9.686864,-7.042921,9.103165,-8.310000,6.897177,-4.602739,8.117689,5.421507,-7.952733,-2.784854,-4.634517,2.258862,9.769781,8.665586,9.741680,5.576450,-0.021756,-7.624861,5.316369,-6.082063,2.691963,0.968453,-0.469924,-6.487742,7.024806,-7.041918,0.227148,-2.385533,-0.090985,3.496390,-2.778429,6.972005,-3.516871,-0.828412,-0.405284,1.220922,9.306145,-0.912786,9.715332,-6.323445,1.099308,1.393421,6.587717,-1.064264,5.462847,6.423196,-3.849487,-1.006718,-7.570838,-5.651483,2.202547,8.156602,-4.466570,-8.948690,-2.620105,-7.108384,9.583670,-8.022993,-6.762014,8.537323,7.329290,7.882479,1.164782,-6.882651,-3.613392,0.367498,-1.429349,6.598640,-9.787620,0.626664,-8.012476,2.999063,6.949551,-3.196206,-0.885069,8.057685,-0.167240,1.955285,-0.588854,-2.104868,-2.607945,-8.554621,-9.417350,-7.998282,-7.285235,0.529659,9.985917,-7.852309,2.010471,-4.341943,-2.467761,3.024774,-9.397547,0.489166,-5.097246,-3.028227,9.032252,-4.205020,-2.194265,-5.486471,-9.780915,1.293416,-9.923757,-3.135000,6.200570,8.534100,-9.914041,-5.312135,2.605762,2.578100,6.288017,8.096586,-5.611801,-2.481377,-9.162849,9.190203,4.313947,-4.245044,8.100614,8.588433,-4.463415,-7.731246,9.801873,1.663383,-1.229540,-7.768847,-3.785948,-1.509072,3.517964,9.596151,-9.122391,-0.266766,-1.840742,3.168074,5.853346,-2.299911,-4.241192,-7.382418,3.142298,-1.285693,-9.095201,-8.715715,-7.855145,-5.588416,8.673140,4.495450,-8.179534,7.680066,9.051221,-3.852679,2.083605,-8.519889,-3.770921,4.591067,-5.624560,1.576308,0.632876,-0.704548,5.191033,2.079825,-4.445879,-9.041955,7.484254,7.625565,-0.866360,0.367251,-4.347177,5.223834,8.316919,5.084736,7.115109,-2.531339,-9.388892,-3.542485,8.761269,-7.231601,1.841542,3.302415,4.894526,5.860490,-9.375595,7.668145,-6.265155,9.418493,-0.160225,3.238866,-3.100727,-6.162738,-7.464096,-9.324327,-3.874957,-8.716846,7.652114,-5.068099,-1.086182,-3.788652,8.524069,-0.202905,1.907347,6.418740,-4.554568,3.696893,-6.739086,6.621770,-5.046541,5.473539,-3.025090,-4.629132,2.426710,-2.768577,-7.495474,-0.368791,2.087563,4.714109,9.204966,-1.894504,-0.971254,-9.521845,7.373562,9.471514,5.518882,-7.651377,-1.881199,3.611280,-9.132615,-5.094789,-9.711293,-5.883960,8.588681,-0.104007,-1.887225,-1.788519,-4.298483,3.813360,-2.473572,-8.041956,6.060285,6.390355,8.791640,1.337915,2.370661,3.066027,6.505626,7.619594,5.355979,5.521675,-4.951829,-2.354598,-6.316038,-1.451296,0.034641,-7.057664,1.311747,-1.339052,-5.941579,-7.855285,4.809705,0.798759,9.416456,2.267685,9.557890,-6.243660,-1.295891,-9.289379,3.895352,2.266228,0.554235,7.407225,-6.383198,-9.866798,-3.378239,-4.146080,-5.424673,-9.017406,-8.485272,-1.472548,-1.160273,8.190675,-4.856932,1.870615,-6.409097,-4.726676,-6.070363,-3.856644,0.657602,9.346178,-0.703152,-0.318779,3.912611,-3.565872,-7.318742,8.990353,-3.388883,-4.432517,5.844261,-6.543119,-9.454389,7.597378,-7.079548,8.522197,-1.963817,9.381594,-2.972007,0.265538,-6.452941,5.264849,9.745269,0.408747,2.399496,-4.093763,6.028272,-1.250933,4.539095,-1.787040,-0.767237,7.980809,-7.025973,1.955732,-2.456130,9.993353,-8.213688,-9.303199,1.608244,1.807063,3.480750,2.364234,-4.228662,-3.007383,-6.252537,-4.905131,2.291631,6.301240,-6.726151,-8.592864,-6.290587,-6.337585,8.574891,-7.628138,-4.281324,9.760163,6.798579,3.152149,3.786944,6.993047,-0.930967,-8.820617,0.563656,-5.030443,-9.361698,4.050283,-0.765991,3.803665,-5.611583,-7.905984,-2.406047,-0.729478,0.375818,3.993681,8.413985,-4.407482,-1.991741,3.223177,-2.793125,-8.937697,0.743499,4.149629,2.561031,9.803221,-8.570940,-8.238384,7.885812,-8.823427,-5.512777,8.698435,-1.290577,-8.051606,-5.747970,1.275335,1.738903,4.454380,2.818166,-8.904514,-6.304920,-2.253184,5.856857,0.011787,4.458051,6.208324,7.132823,1.384523,-0.646003,8.870810,-1.244649,-5.668059,-2.333533,-4.333019,-1.835121,-7.708069,-1.338131,-0.653040,5.391955,-2.247880,2.230415,6.227609,1.141943,9.262963,-2.536082,-4.993382,5.287529,-0.604785,3.458300,7.944714,7.854682,-0.988176,-9.927005,5.899463,-5.197388,-3.224234,-5.938810,-6.409561,-6.242270,2.482605,-4.884994,7.122441,-8.863150,2.299927,-9.476797,-8.651860,-9.822443,6.222027,9.700813,0.330755,6.108645,6.006723,7.731117,2.001857,8.982348,-8.312080,-1.388468,2.246096,2.450421,-5.401544,3.406236,4.473945,3.379562,-9.278994,6.157522,-4.307041,4.366583,-1.824109,-6.995011,1.718510,0.967914,3.849345,6.622831,-0.840588,-3.482899,3.259608,4.438319,7.407526,4.843329,0.742224,0.790478,0.444138,-1.411577,3.141765,4.851946,-8.300087,-4.042190,5.631591,8.974706,-9.687934,-4.959812,9.975104,-3.480216,4.649133,0.066935,6.015694,-3.786387,7.542098,-7.082474,4.587548,4.260979,-9.389378,-5.322446,-7.613224,-5.306335,1.060907,-1.949243,-7.177654,0.182038,-4.558390,6.792131,-4.208786,2.999211,-6.826823,-2.700403,5.891218,6.830131,-3.859210,8.264041,1.838403,6.927445,7.797421,-2.451958,0.831130,6.821824,-6.040536,4.329400,-5.640877,-5.544852,-5.940841,2.789688,3.946008,-3.905701,-1.237218,-8.062900,0.377818,-5.785729,2.533997,-2.655026,-8.290475,-8.287299,-4.139437,5.789317,-5.087192,5.708126,7.027299,9.190436,-3.854554,-9.982820,9.165307,-6.744578,-9.518370,2.560983,8.266099,-4.269046,5.347421,-7.608029,-1.734956,5.834598,-1.539483,-2.831297,1.875133,-8.288396,1.561926,-5.301859,9.802275,9.205467,3.765765,2.092572,-4.700620,-4.504368,-7.102268,-4.898587,7.351962,-7.535446,-2.423340,7.640505,-9.527955,6.543012,-7.893617,-0.267624,2.567563,0.855784,4.620478,8.047652,8.584493,7.806134,1.687605,-3.686286,6.046953,-4.944480,1.404756,8.581135,2.014342,8.740066,-9.498845,3.822785,8.696248,-5.975741,7.480036,9.738406,-0.244599,-8.406252,-8.466512,-3.701679,2.393351,1.976219,-7.162376,-0.089934,-7.308348,7.154814,-9.431579,-4.342685,9.204559,-7.728268,-1.454897,8.821183,-8.076825,-2.193105,1.799173,1.452633,1.602482,9.366947,4.809907,5.908972,-5.297983,6.264972,0.689095,-5.927715,-2.677524,0.858022,-3.391564,4.370871,8.181444,9.118359,-9.478189,6.717340,-9.762862,7.597552,2.811009,4.332877,7.248688,-5.498928,-8.730850,-7.066888,5.119289,7.710879,-4.053082,-6.012953,5.881978,-1.137928,-7.609376,2.628174,2.952669,9.462434,-2.296040,-8.233277,3.401605,-5.751894,8.973831,-0.795148,8.592033,1.238309,5.412723,6.658327,9.002641,-6.569467,7.544955,-4.340864,1.468875,7.448654,-6.959682,7.413893,-1.791580,4.283398,-4.334090,-5.862306,-6.647665,-5.928046,-3.126892,-8.330786,3.938104,3.320927,-0.089330,8.261067,8.099592,3.924647,-9.595167,4.881633,9.065208,1.029181,2.912155,1.026616,7.020081,0.940257,3.735583,4.179136,-4.847555,3.949076,9.200567,-7.077901,-3.957883,-1.112396,3.219708,7.417454,9.608745,-2.531572,5.312210,-1.908560,4.885939,-4.615379,4.507020,-0.310893,-4.162328,-3.128997,-1.514300,1.455567,9.749020,-2.347797,0.698135,9.631977,-5.732136,4.487279,0.450363,-3.994828,8.231076,8.092521,-9.451123,2.270004,2.414777,-0.252731,-5.145196,-2.083777,-0.668629,-6.716779,9.821624,-5.933716,-7.909986,7.901282,0.748463,-5.788033,-5.470711,0.058245,7.394961,8.065227,-0.611051,9.884190,0.086637,-4.837549,-3.930007,-2.991004,-3.204442,4.685069,-4.908366,-0.564149,-6.690736,0.098072,-0.144799,4.552255,5.925315,1.479944,2.775238,-5.815604,-0.102135,-4.923466,-5.216582,-9.431771,8.423001,3.617534,-4.653216,6.504796,-0.013311,8.556812,8.251058,2.682574,-1.787157,-6.781748,8.279308,-3.025223,-9.504373,-9.337358,0.315072,0.972727,-1.571221,1.861176,9.616357,0.983634,5.275273,-8.573374,6.328938,4.180651,-0.509561,5.075849,-2.307577,-3.254292,-9.024237,1.971484,5.773128,-3.825230,9.916517,5.482795,-4.390771,9.200051,9.526056,-3.652669,0.462051,-4.963379,-1.677539,5.622059,-5.129156,0.167950,-4.936009,-3.657025,2.090475,1.136269,-7.285881,6.372307,5.464318,-7.600228,9.708985,3.108041,-7.004758,-8.124152,-4.370133,-2.125320,5.370509,4.661198,-6.252632,-4.471647,1.388720,4.657254,-3.839276,-9.474733,6.961219,-3.002387,-4.185328,0.844171,-5.553442,7.443192,4.328143,5.506368,9.979098,-7.717398,-1.985429,8.585964,-8.624707,-8.205556,-0.875921,-7.570461,7.068030,-9.573522,-1.477432,7.798887,5.164167,5.871940,-8.870521,-3.525036,-6.275189,9.128830,9.093528,-3.149262,1.527498,-2.174373,1.353344,6.808648,2.582340,-5.808114,4.238419,-0.607238,-7.003279,3.810740,-8.774106,-5.042197,-6.757942,-7.331658,1.806313,2.288156,0.141550,-2.465046,-1.120425,5.347829,2.732255,-7.271301,1.214686,5.750244,-5.788675,-3.817989,-9.435244,2.018188,4.421372,-5.307190,-0.635258,1.188905,2.597583,2.538919,-6.610104,-2.652714,-7.137003,-2.809992,2.901823,-7.788282,0.388766,6.043014,1.607938,-3.301306,-7.974418,2.809455,2.086223,-7.888821,-5.882062,-9.679181,-1.132963,-3.510296,2.534116,1.200126,8.321477,4.775959,-8.877890,-2.031546,1.880242,-0.319455,-7.750114,6.716201,6.398352,-7.883288,8.304007,-4.901612,3.501495,-1.616956,1.097689,-2.472394,5.121205,9.469210,-9.546359,-8.004737,7.923024,5.830604,-7.938979,9.655512,-6.200156,-2.381534,-1.061505,9.078934,7.817886,7.099184,1.175883,8.185387,4.079459,7.258940,8.453015,5.066801,-0.130542,-2.117545,6.822046,-4.523015,6.226315,3.523163,2.632577,-5.471049,8.127742,-9.297178,0.821459,9.871022,-0.229497,-6.087011,-9.023435,-5.920161,-7.121840,-1.949575,-5.466060,4.681174,2.680117,-3.561960,5.156501,8.044643,-8.668806,-4.383541,-2.994657,-2.189606,-1.731890,-8.124165,-2.750392,1.262512,2.992178,0.167224,0.447407,2.202968,5.819234,9.269827,-9.490179,0.940969,-9.180088,-6.665850,-3.819734,-9.097042,9.013186,2.668358,0.438888,-5.562791,-9.765110,5.034911,-0.988854,-7.270021,-4.152404,0.373924,8.942236,4.682571,-5.823420,-2.216061,-6.108940,7.738567,7.179688,3.896551,9.180516,2.986076,6.546027,0.384330,8.834554,-6.528770,-9.440082,5.249715,-0.591607,1.871144,-4.203938,8.763702,-1.125127,8.309145,-3.038313,4.092271,-1.625827,1.697596,3.157325,-8.064866,4.147890,-9.821695,-6.952135,9.346691,-7.377443,8.725916,-2.895169,2.288367,1.274675,-3.312999,7.600623,9.213360,-4.405576,-8.945125,-7.598504,-4.505264,7.192441,9.200075,-9.334839,-6.938162,7.578832,-2.234390,8.374104,6.659299,-6.143164,-6.699241,9.756275,9.269788,-0.688424,1.928271,-9.188004,-5.116824,-3.060613,8.466764,-3.621034,2.367445,7.351295,3.600037,3.174560,8.760150,-0.929191,2.522068,-9.252903,5.317248,-9.998411,9.005376,9.957719,-2.077372,8.704905,-3.048469,-8.625239,2.325857,7.650108,-9.144256,0.544146,-2.531262,4.226751,8.565306,6.823873,-4.570011,2.376634,-3.613633,-2.933927,-2.972041,1.897698,2.248224,-4.086625,7.723295,-8.735510,-6.071316,-9.500956,5.947479,3.096051,7.053893,-3.141543,-9.132127,0.273497,-1.373898,-6.110183,8.860914,8.664709,0.140200,7.199440,-5.709804,-2.765979,-4.173777,2.588268,-6.124423,-6.796296,0.353959,0.047669,8.277751,5.169670,-4.057639,-1.453977,1.347623,7.038826,-9.606370,1.600537,-3.629696,8.576160,-4.435875,-9.123011,1.326363,-6.150564,1.217393,2.394608,-3.417858,-5.213050,-9.373558,-0.685913,4.036959,-2.147941,1.162065,-8.987552,1.738967,-4.207746,-3.514534,-1.401843,2.616766,5.125782,-0.387271,1.934282,3.496903,-4.521122,5.191283,9.922896,-9.138734,-0.052313,6.014947,6.534707,-2.123985,8.501328,-6.608638,4.776716,-0.861945,6.226311,1.098833,-1.938414,-9.977224,-0.697227,0.950938,-8.551597,0.669582,5.601003,4.704359,5.538118,-0.320146,2.798093,-3.404623,4.719399,4.973912,3.348929,2.592719,2.129101,-9.015793,3.441887,1.663693,6.570958,-6.170939,0.448880,7.880070,-4.159332,6.591195,8.910402,-1.908245,3.884801,1.809530,-7.111173,-7.546003,-6.978628,1.556263,-2.974581,-9.028920,2.692965,7.813501,-6.440095,9.085510,-6.950472,-4.512689,-7.610639,-0.383356,-6.662333,-2.372951,7.152693,-7.117119,-9.701296,1.958147,-0.613931,-4.679422,3.956457,8.312424,6.631920,-8.851993,0.949861,9.160943,2.392767,8.616930,0.692682,-8.982500,-3.504364,-8.186533,-3.794413,-2.139873,1.529222,-2.470473,-4.629775,0.934972,-4.361583,2.061862,-8.650846,1.582891,1.602595,-9.636719,-5.694050,3.289978,6.457709,6.493333,7.399192,8.563316,6.861985,4.826325,7.446155,1.045779,-7.929101,3.265744,7.688826,-8.292301,-1.020411,4.051255,8.412624,2.331612,-7.928436,-6.116714,-6.741897,6.334669,2.033395,0.825555,0.661628,-2.301568,-0.889244,-4.578920,-0.939646,-0.306670,1.256083,-8.576900,-2.561816,-0.856929,-0.176321,-7.549982,-3.348498,-4.073225,9.431562,-5.393589,-6.118345,-0.816392,-2.847303,-7.667514,-6.249520,6.179786,-0.314703,-1.494869,-7.494537,-6.293039,-1.295898,5.389913,-6.006589,-1.295697,-5.267311,-0.742361,-0.206123,4.839901,9.344746,4.941059,-1.115587,-9.565751,-9.018158,5.865228,4.059148,-3.040748,-5.528697,-2.479874,9.647156,-7.428346,4.979441,8.194866,-6.334618,-6.790582,-7.878930,5.490447,9.813520,-3.207932,-3.714836,-3.359541,0.660395,9.682978,-0.357481,-7.323793,7.505191,6.951110,0.680205,-5.649604,2.546602,4.159796,-6.970650,-0.624909,-9.371909,-8.580393,-1.105191,-5.745919,8.150610,-3.490618,5.921311,5.632855,2.497592,9.311688,0.110892,-7.744535,5.844523,4.391565,-0.537255,1.083705,-8.087035,-1.404672,-3.950883,-7.017152,-9.452920,6.671665,7.656798,-6.368898,-9.916416,1.054542,8.822835,-8.467049,4.345445,2.489173,-7.617032,3.451837,-6.355030,5.732022,-0.963110,-6.906956,-6.921861,2.992918,-6.289206,4.087759,4.831729,9.962673,-7.865211,7.742796,3.263874,-8.284387,6.017423,-9.175737,9.876377,-9.824716,1.005083,-1.347655,5.815174,5.850518,-3.878680,-6.089583,6.997091,-1.242710,1.681011,6.791536,-4.679546,-3.334816,6.962404,4.435939,1.755917,6.683013,-5.553939,-0.201791,4.690172,-0.784521,-2.129113,0.515901,-3.870468,-0.680930,-9.202250,-8.427544,5.174347,-4.594316,2.019083,1.466573,-4.950694,4.016269,-3.214891,-1.512698,7.063251,5.917348,9.094925,2.068567,2.861675,4.310977,7.040587,-4.927048,6.682716,-5.158003,5.750450,8.474200,-0.479383,-2.618368,-5.855432,-8.749118,0.376576,-3.764128,-3.797761,-3.011234,6.286093,2.542284,2.411392,4.190059,5.302933,2.960345,4.540281,-1.372120,4.490674,-5.606286,5.720263,2.702988,5.735462,5.345280,0.006387,6.892063,5.296132,-2.586447,-9.913743,4.762254,2.418801,-6.076889,5.801847,-2.690391,-3.831183,6.702128,0.721609,-4.212681,-8.794710,-0.100410,-9.373053,-5.678803,9.243563,-7.793280,-9.696203,5.592970,0.421986,-7.548772,-6.588666,1.162477,7.757719,-8.285869,-1.229795,8.995827,-7.311129,-3.827191,1.988359,-6.347262,6.698283,9.888519,3.341971,2.582618,-5.543527,3.691074,-2.880340,9.098589,8.872191,-7.051821,4.248963,-6.369420,-4.132674,-0.174630,5.554990,-9.429668,0.234166,-1.604202,-7.145659,4.192654,1.392582,3.626416,-7.956441,-2.485350,-8.481374,7.896150,-8.755071,6.574805,-7.503381,4.696547,-5.306807,9.197951,9.753025,-0.642597,9.306882,-2.120855,0.108747,6.709697,7.586731,7.316304,-5.257490,7.897628,4.520228,9.199754,-4.005068,4.852629,-4.027524,-0.613550,8.625445,3.358227,1.272882,9.107928,0.088926,-0.947808,-1.117068,-3.601816,-8.244967,-3.454597,-6.920876,1.799027,-4.888237,-3.719932,1.764314,-8.241994,7.105135,-9.916537,1.982713,4.225110,-7.851690,4.864384,-1.474812,0.801709,4.313609,-0.669254,-3.182387,-5.447825,-4.711514,7.439186,-1.583889,-6.674710,-2.629538,-1.390887,8.608718,-9.200737,0.691111,-2.431606,-4.066294,-2.607475,1.015524,3.177518,-4.924506,-3.135076,-7.045628,9.030704,7.730507,3.534690,-0.130405,-6.117300,1.701398,3.702551,-3.191372,-1.066692,5.941841,3.209229,0.317403,-5.097970,-6.329985,3.254707,7.329297,1.336448,-7.107859,-6.174993,-5.508174,-7.268666,8.874690,-0.967583,-2.258514,-7.102627,3.728058,-9.547862,9.329222,4.556021,-5.353998,-2.390049,2.262932,-7.815560,-7.631659,-8.374805,0.970757,1.593163,-2.722942,6.266792,-3.165390,-8.767481,2.615367,5.228001,-1.857317,-2.350029,4.547131,-1.507752,4.359503,-6.925770,8.196325,-0.759952,-5.989231,8.000927,-8.156045,8.578291,0.168623,-0.420893,-1.699063,7.808614,-7.458966,4.420257,-1.689021,-5.454790,3.966403,-0.203279,5.103801,7.277131,-0.332475,-6.804062,8.297132,9.871436,-5.220121,9.620770,9.443844,0.104325,5.001849,3.953737,-0.950722,8.049649,9.109961,-5.212705,-3.101873,-3.205479,-3.433549,6.655077,-6.254416,-5.058248,1.971132,4.331504,-5.578927,-1.237740,-1.229920,-3.227936,-9.193876,-9.214115,1.948344,-8.046809,-9.462211,-9.304257,-0.940324,4.047899,-8.750951,8.332182,2.600323,4.108410,7.785441,6.398888,7.766777,-6.520202,6.258087,7.830340,9.432015,9.824433,-5.971320,-2.475373,5.535071,1.187439,-5.134288,0.277956,-8.861957,9.272462,8.793012,9.386479,-1.443978,-8.054455,-4.132149,-1.880719,9.508868,7.733264,7.089879,-5.846946,1.562471,6.322507,-8.837401,-4.019345,6.236382,-9.305947,-1.182419,5.223283,0.349118,2.718927,-1.908638,2.178843,5.027360,6.909482,4.941832,3.834866,-0.213112,-2.215237,-2.341930,4.360479,-9.528356,-2.827895,3.558510,-4.666485,9.283702,-8.916340,2.924115,1.608080,-1.765189,-4.906934,9.281170,4.335354,-4.115668,-9.585496,-9.291183,-9.362533,-4.024786,5.608130,-7.028674,-8.223942,3.483196,7.333448,6.679591,9.955610,-1.459732,1.703720,-8.886222,5.641593,-0.027880,2.117599,8.533585,6.268109,-7.047915,2.737387,-0.981967,-1.768106,-0.418774,8.315219,-1.604680,7.422422,-2.178490,-1.828869,5.109625,4.466239,-3.973254,-1.781158,-0.516575,5.218532,8.953224,0.205847,-1.291555,0.018539,-9.992227,-9.942962,-0.581377,6.970315,-8.497801,9.276785,8.957627,8.876888,0.456100,5.886996,-2.836741,-3.714427,0.880576,2.604856,6.558936,-5.669486,7.230100,-1.375621,-2.393024,-0.135906,-4.971527,5.646153,-2.248821,5.138783,-8.164923,5.090001,7.456123,-6.055982,-2.767192,-1.057661,8.069079,0.231482,-9.825788,-4.864717,3.801828,1.989158,-3.216881,5.321947,-9.002788,-3.851378,6.156164,0.240354,2.249348,2.445494,9.415897,8.706691,-6.057317,-6.499282,-3.872972,0.862365,0.690815,2.897076,1.844380,0.168690,6.238515,2.125634,2.723882,5.220000,-0.120150,-8.421447,8.983783,-0.732588,-5.036833,-7.031778,9.389436,-7.236916,-3.761112,-3.361385,-4.857462,3.695016,6.669861,-3.696249,6.599494,0.959234,-5.359934,-9.562230,1.323513,2.522198,3.882932,2.785471,-8.224943,3.054854,8.206059,-7.174143,2.039746,-7.978790,-2.916111,-7.312679,-3.056958,-5.659529,7.415986,-3.579802,8.421455,8.012496,5.788877,-7.902260,-7.113463,5.197138,9.352084,-3.316517,8.172358,-0.519477,0.539044,-5.141987,-6.482541,6.157839,0.611276,7.661198,5.477624,7.165193,6.649620,-4.331629,7.029733,5.203992,-1.111008,-4.335582,-9.849687,4.875410,8.523262,-6.529381,-0.325488,6.743928,4.017452,6.907180,3.871794,-1.250293,-2.642341,5.604338,-7.883826,-8.617812,-2.180950,-5.409945,9.895832,-0.557866,0.179875,0.458444,-2.158701,3.282086,0.578617,8.316487,1.123845,2.479823,-0.289007,-3.845670,5.991380,6.088040,1.510674,8.512079,-2.152721,0.398608,-9.390776,1.206921,3.208013,-5.347402,4.505796,-9.826886,6.928212,-6.963757,-9.746122,-3.344151,-3.449275,7.531011,-0.118518,-6.202192,-7.312929,-7.181431,-2.508264,-9.430184,9.810532,-9.873747,-1.857641,7.155040,-4.155406,3.369854,-0.368792,4.120506,-7.117159,-6.423090,1.370732,7.466223,-8.753876,-4.422666,8.974387,6.029438,3.752848,-2.128945,-0.884657,-2.795091,6.506262,8.051255,1.701345,-7.819235,8.973220,-9.172351,-4.582381,-9.624593,-6.838354,7.992429,5.673872,-1.898171,2.172957,-3.847013,-0.764232,-7.756101,1.079189,-3.463901,-7.865794,-5.215363,1.595537,-7.276464,-6.707097,2.797835,2.490705,-2.218680,9.580502,-5.453784,9.601406,-5.275346,8.598949,-8.038450,-4.236685,4.311279,8.545897,-9.058555,5.974741,-0.614514,1.943262,-8.859262,5.600328,-2.201007,2.955894,8.674158,7.448678,-2.759926,-0.967977,1.065545,7.878400,-6.193703,-0.024312,-8.664019,3.496364,8.562165,-6.045586,-1.031598,6.587687,-4.970808,1.696074,4.921295,1.035916,7.059381,-7.112290,-8.163677,4.848038,4.450766,0.830450,1.498244,-7.389991,7.397887,-7.667219,-6.837081,-8.235784,-5.126752,-6.013708,1.513803,-2.106571,-0.339429,0.598515,-0.134457,0.817974,6.080214,5.266062,6.963250,1.478936,-4.546058,-8.302076,8.930370,6.508459,-3.483119,-6.133621,5.738382,-3.360397,7.110070,-9.047362,2.772120,2.026313,-9.438052,5.277378,0.139656,7.138981,4.481853,-5.254413,-7.947119,-5.238409,-0.454666,-2.361099,3.268360,9.277801,5.897361,7.222605,8.022491,8.984056,2.489824,7.246018,7.008229,0.052714,5.434070,-9.949674,7.211969,-6.734434,4.526043,-3.208808,-8.957564,5.052095,9.499206,-0.523718,-6.283779,8.897131,-9.506920,-1.889534,2.210938,-6.312188,8.496272,-0.472331,-3.552950,-7.800519,-0.194946,-3.376134,-6.619058,-9.344135,-6.551945,-4.044577,-3.288989,6.802629,5.326534,-8.398139,7.578916,1.929372,0.904317,4.765443,-8.613285,3.763520,-7.406426,5.429919,-3.077519,0.209239,-9.990156,9.500639,7.789766,-9.111697,-2.492050,2.537249,2.652520,-1.373722,-8.258204,-2.819992,-3.729730,2.579255,-4.064938,0.684182,-7.725864,4.877186,2.885489,1.699007,4.103918,3.552608,3.929988,3.272335,8.642877,7.393201,-7.523469,-3.903814,-2.004894], dtype = "float32")#candidate|95|(2940,)|const|float32
call_94 = relay.TupleGetItem(func_84_call(relay.reshape(const_95.astype('float32'), [14, 15, 14]), relay.reshape(const_95.astype('float32'), [14, 15, 14]), ), 2)
call_96 = relay.TupleGetItem(func_87_call(relay.reshape(const_95.astype('float32'), [14, 15, 14]), relay.reshape(const_95.astype('float32'), [14, 15, 14]), ), 2)
output = relay.Tuple([bop_91,call_94,const_95,])
output2 = relay.Tuple([bop_91,call_96,const_95,])
func_97 = relay.Function([var_90,], output)
mod['func_97'] = func_97
mod = relay.transform.InferType()(mod)
mutated_mod['func_97'] = func_97
mutated_mod = relay.transform.InferType()(mutated_mod)
var_98 = relay.var("var_98", dtype = "int16", shape = (13, 2, 8))#candidate|98|(13, 2, 8)|var|int16
func_97_call = mutated_mod.get_global_var('func_97')
call_99 = func_97_call(var_98)
output = call_99
func_100 = relay.Function([var_98], output)
mutated_mod['func_100'] = func_100
mutated_mod = relay.transform.InferType()(mutated_mod)
var_102 = relay.var("var_102", dtype = "uint8", shape = (7, 7))#candidate|102|(7, 7)|var|uint8
var_103 = relay.var("var_103", dtype = "uint8", shape = (7, 7))#candidate|103|(7, 7)|var|uint8
bop_104 = relay.greater(var_102.astype('bool'), relay.reshape(var_103.astype('bool'), relay.shape_of(var_102))) # shape=(7, 7)
bop_107 = relay.bitwise_and(var_102.astype('int32'), relay.reshape(bop_104.astype('int32'), relay.shape_of(var_102))) # shape=(7, 7)
uop_110 = relay.exp(bop_104.astype('float64')) # shape=(7, 7)
uop_112 = relay.sigmoid(uop_110.astype('float64')) # shape=(7, 7)
uop_114 = relay.acos(uop_112.astype('float64')) # shape=(7, 7)
uop_116 = relay.log10(uop_114.astype('float64')) # shape=(7, 7)
uop_118 = relay.cosh(uop_116.astype('float32')) # shape=(7, 7)
uop_120 = relay.log2(uop_116.astype('float32')) # shape=(7, 7)
bop_122 = relay.right_shift(uop_120.astype('int8'), relay.reshape(bop_107.astype('int8'), relay.shape_of(uop_120))) # shape=(7, 7)
uop_125 = relay.log10(uop_112.astype('float64')) # shape=(7, 7)
uop_127 = relay.sin(uop_120.astype('float32')) # shape=(7, 7)
output = relay.Tuple([uop_118,bop_122,uop_125,uop_127,])
output2 = relay.Tuple([uop_118,bop_122,uop_125,uop_127,])
func_129 = relay.Function([var_102,var_103,], output)
mod['func_129'] = func_129
mod = relay.transform.InferType()(mod)
mutated_mod['func_129'] = func_129
mutated_mod = relay.transform.InferType()(mutated_mod)
func_129_call = mutated_mod.get_global_var('func_129')
var_131 = relay.var("var_131", dtype = "uint8", shape = (7, 7))#candidate|131|(7, 7)|var|uint8
var_132 = relay.var("var_132", dtype = "uint8", shape = (7, 7))#candidate|132|(7, 7)|var|uint8
call_130 = func_129_call(var_131,var_132,)
output = call_130
func_133 = relay.Function([var_131,var_132,], output)
mutated_mod['func_133'] = func_133
mutated_mod = relay.transform.InferType()(mutated_mod)
var_135 = relay.var("var_135", dtype = "int64", shape = (11, 15))#candidate|135|(11, 15)|var|int64
var_136 = relay.var("var_136", dtype = "int64", shape = (11, 15))#candidate|136|(11, 15)|var|int64
bop_137 = relay.bitwise_or(var_135.astype('int64'), relay.reshape(var_136.astype('int64'), relay.shape_of(var_135))) # shape=(11, 15)
bop_140 = relay.less_equal(var_136.astype('bool'), relay.reshape(bop_137.astype('bool'), relay.shape_of(var_136))) # shape=(11, 15)
output = relay.Tuple([bop_140,])
output2 = relay.Tuple([bop_140,])
func_143 = relay.Function([var_135,var_136,], output)
mod['func_143'] = func_143
mod = relay.transform.InferType()(mod)
mutated_mod['func_143'] = func_143
mutated_mod = relay.transform.InferType()(mutated_mod)
func_143_call = mutated_mod.get_global_var('func_143')
var_145 = relay.var("var_145", dtype = "int64", shape = (11, 15))#candidate|145|(11, 15)|var|int64
var_146 = relay.var("var_146", dtype = "int64", shape = (11, 15))#candidate|146|(11, 15)|var|int64
call_144 = func_143_call(var_145,var_146,)
output = call_144
func_147 = relay.Function([var_145,var_146,], output)
mutated_mod['func_147'] = func_147
mutated_mod = relay.transform.InferType()(mutated_mod)
var_149 = relay.var("var_149", dtype = "uint8", shape = (12, 9))#candidate|149|(12, 9)|var|uint8
const_150 = relay.const([[8,6,3,4,-5,1,9,2,2],[5,-8,-4,6,6,3,-3,-1,3],[-2,-9,-7,1,-6,4,-10,7,-1],[-6,-6,6,-6,2,-7,-3,-1,-7],[3,-4,1,-8,-6,-9,-9,-3,-9],[4,-7,3,3,-4,8,-5,-9,1],[-7,-1,5,2,-8,9,-4,-5,1],[-9,-3,9,6,4,4,-7,4,6],[9,5,2,7,1,9,9,6,-2],[-3,2,-6,-3,-5,-1,10,8,-9],[3,6,-7,6,4,-8,-1,-5,-10],[-7,-3,4,5,6,-1,-6,5,6]], dtype = "uint8")#candidate|150|(12, 9)|const|uint8
bop_151 = relay.equal(var_149.astype('bool'), relay.reshape(const_150.astype('bool'), relay.shape_of(var_149))) # shape=(12, 9)
const_154 = relay.const([[-8,5,-10,8,9,8,9,10,-1],[-8,2,-2,-9,-1,1,-3,7,-9],[-7,2,-10,-9,2,-5,-10,10,4],[-4,8,8,-5,8,-2,-10,-5,-4],[3,-8,-5,-9,-5,6,10,-4,7],[-8,6,-6,-5,7,1,9,-7,10],[-7,8,8,1,5,-8,1,7,-2],[-6,-9,8,-4,-5,-3,4,4,2],[-5,-1,10,5,5,-9,-4,5,5],[5,-2,2,-5,-5,-8,2,2,6],[-3,3,10,5,6,9,-7,3,-5],[7,1,1,-1,-5,-6,-4,1,-5]], dtype = "uint8")#candidate|154|(12, 9)|const|uint8
bop_155 = relay.floor_mod(var_149.astype('float32'), relay.reshape(const_154.astype('float32'), relay.shape_of(var_149))) # shape=(12, 9)
bop_158 = relay.logical_xor(bop_151.astype('uint8'), relay.reshape(var_149.astype('uint8'), relay.shape_of(bop_151))) # shape=(12, 9)
bop_161 = relay.greater(bop_158.astype('bool'), relay.reshape(bop_151.astype('bool'), relay.shape_of(bop_158))) # shape=(12, 9)
uop_164 = relay.cos(bop_155.astype('float64')) # shape=(12, 9)
const_166 = relay.const([[-5.052610,9.213163,8.332689,-3.187922,9.241255,9.686276,6.946891,4.007207,1.676416],[-0.770483,6.878142,4.941149,-2.055628,0.430100,-5.560186,2.529739,9.773802,9.309936],[-9.633101,7.888396,-7.384952,-8.230721,4.376626,-9.810624,5.870350,7.312529,9.716869],[-2.272307,4.810447,-9.677770,8.080529,-4.302613,-8.058188,9.669478,8.163769,-6.925741],[4.719846,1.168140,-1.337648,4.185274,-2.235439,2.192638,5.004024,-7.133487,9.640468],[8.750819,-8.079503,-9.524462,3.362151,-7.042527,-1.906837,3.173186,0.393666,-7.333082],[-8.624375,4.079882,-7.879778,-3.722652,8.519859,-9.089110,8.309727,3.179910,6.939050],[-9.968722,6.761962,8.705585,9.404158,5.091761,7.200621,4.528838,4.286328,-0.127023],[0.609723,7.396654,3.955056,3.579587,6.975259,1.458544,-0.211677,-7.668056,-6.892656],[2.444082,-5.049112,-1.955957,-1.238138,9.032481,-1.345344,9.939663,-7.006726,-8.812906],[-7.096805,8.537287,-5.867101,-6.233520,-2.418695,-9.589596,-6.245478,5.999657,-3.641164],[-8.749245,6.573818,-7.102305,-4.513228,1.203677,6.580802,-1.753738,5.942607,8.719885]], dtype = "float64")#candidate|166|(12, 9)|const|float64
bop_167 = relay.greater_equal(uop_164.astype('bool'), relay.reshape(const_166.astype('bool'), relay.shape_of(uop_164))) # shape=(12, 9)
output = relay.Tuple([bop_161,bop_167,])
output2 = relay.Tuple([bop_161,bop_167,])
func_170 = relay.Function([var_149,], output)
mod['func_170'] = func_170
mod = relay.transform.InferType()(mod)
mutated_mod['func_170'] = func_170
mutated_mod = relay.transform.InferType()(mutated_mod)
var_171 = relay.var("var_171", dtype = "uint8", shape = (12, 9))#candidate|171|(12, 9)|var|uint8
func_170_call = mutated_mod.get_global_var('func_170')
call_172 = func_170_call(var_171)
output = call_172
func_173 = relay.Function([var_171], output)
mutated_mod['func_173'] = func_173
mutated_mod = relay.transform.InferType()(mutated_mod)
const_175 = relay.const([[4.614523,-1.639851,4.786459,7.364891,4.045108,7.162758,3.400978,5.302835,-7.236704,-2.193663,-4.202069,-8.846816,-3.048875,-2.873333]], dtype = "float64")#candidate|175|(1, 14)|const|float64
uop_176 = relay.tan(const_175.astype('float64')) # shape=(1, 14)
uop_178 = relay.rsqrt(uop_176.astype('float64')) # shape=(1, 14)
bop_180 = relay.multiply(uop_176.astype('int8'), relay.reshape(const_175.astype('int8'), relay.shape_of(uop_176))) # shape=(1, 14)
bop_183 = relay.multiply(uop_178.astype('float64'), relay.reshape(uop_176.astype('float64'), relay.shape_of(uop_178))) # shape=(1, 14)
uop_186 = relay.sqrt(bop_183.astype('float32')) # shape=(1, 14)
bop_188 = relay.logical_xor(bop_180.astype('int32'), relay.reshape(const_175.astype('int32'), relay.shape_of(bop_180))) # shape=(1, 14)
var_191 = relay.var("var_191", dtype = "float64", shape = (6, 14))#candidate|191|(6, 14)|var|float64
bop_192 = relay.multiply(const_175.astype('int16'), var_191.astype('int16')) # shape=(6, 14)
bop_195 = relay.not_equal(uop_186.astype('bool'), bop_192.astype('bool')) # shape=(6, 14)
bop_198 = relay.equal(bop_188.astype('bool'), var_191.astype('bool')) # shape=(6, 14)
uop_201 = relay.atan(uop_178.astype('float32')) # shape=(1, 14)
bop_203 = relay.greater(uop_201.astype('bool'), relay.reshape(uop_176.astype('bool'), relay.shape_of(uop_201))) # shape=(1, 14)
uop_206 = relay.sin(const_175.astype('float64')) # shape=(1, 14)
func_129_call = mod.get_global_var('func_129')
func_133_call = mutated_mod.get_global_var('func_133')
const_209 = relay.const([-4,1,4,1,-2,9,3,-2,9,-1,7,-2,3,2,-8,8,-8,1,7,-5,4,4,5,6,-3,-7,-3,7,-3,-3,-9,-2,-10,-3,4,7,-10,-9,-7,9,2,-10,-4,-8,7,-9,-2,5,5], dtype = "uint8")#candidate|209|(49,)|const|uint8
call_208 = relay.TupleGetItem(func_129_call(relay.reshape(const_209.astype('uint8'), [7, 7]), relay.reshape(const_209.astype('uint8'), [7, 7]), ), 0)
call_210 = relay.TupleGetItem(func_133_call(relay.reshape(const_209.astype('uint8'), [7, 7]), relay.reshape(const_209.astype('uint8'), [7, 7]), ), 0)
bop_211 = relay.left_shift(uop_178.astype('uint32'), relay.reshape(const_175.astype('uint32'), relay.shape_of(uop_178))) # shape=(1, 14)
uop_214 = relay.sqrt(uop_201.astype('float32')) # shape=(1, 14)
bop_216 = relay.mod(uop_214.astype('float32'), relay.reshape(uop_178.astype('float32'), relay.shape_of(uop_214))) # shape=(1, 14)
bop_219 = relay.multiply(bop_211.astype('float32'), var_191.astype('float32')) # shape=(6, 14)
func_170_call = mod.get_global_var('func_170')
func_173_call = mutated_mod.get_global_var('func_173')
var_223 = relay.var("var_223", dtype = "uint8", shape = (108, 1))#candidate|223|(108, 1)|var|uint8
call_222 = relay.TupleGetItem(func_170_call(relay.reshape(var_223.astype('uint8'), [12, 9])), 0)
call_224 = relay.TupleGetItem(func_173_call(relay.reshape(var_223.astype('uint8'), [12, 9])), 0)
var_225 = relay.var("var_225", dtype = "float32", shape = (9, 14))#candidate|225|(9, 14)|var|float32
bop_226 = relay.divide(uop_214.astype('float64'), var_225.astype('float64')) # shape=(9, 14)
uop_229 = relay.log2(bop_216.astype('float64')) # shape=(1, 14)
bop_231 = relay.subtract(uop_229.astype('int16'), bop_192.astype('int16')) # shape=(6, 14)
uop_234 = relay.cos(uop_229.astype('float32')) # shape=(1, 14)
var_236 = relay.var("var_236", dtype = "float32", shape = (16, 14))#candidate|236|(16, 14)|var|float32
bop_237 = relay.equal(uop_234.astype('bool'), var_236.astype('bool')) # shape=(16, 14)
bop_240 = relay.power(bop_180.astype('float64'), bop_195.astype('float64')) # shape=(6, 14)
output = relay.Tuple([bop_198,bop_203,uop_206,call_208,const_209,bop_219,call_222,var_223,bop_226,bop_231,bop_237,bop_240,])
output2 = relay.Tuple([bop_198,bop_203,uop_206,call_210,const_209,bop_219,call_224,var_223,bop_226,bop_231,bop_237,bop_240,])
func_243 = relay.Function([var_191,var_223,var_225,var_236,], output)
mod['func_243'] = func_243
mod = relay.transform.InferType()(mod)
mutated_mod['func_243'] = func_243
mutated_mod = relay.transform.InferType()(mutated_mod)
func_243_call = mutated_mod.get_global_var('func_243')
var_245 = relay.var("var_245", dtype = "float64", shape = (6, 14))#candidate|245|(6, 14)|var|float64
var_246 = relay.var("var_246", dtype = "uint8", shape = (108, 1))#candidate|246|(108, 1)|var|uint8
var_247 = relay.var("var_247", dtype = "float32", shape = (9, 14))#candidate|247|(9, 14)|var|float32
var_248 = relay.var("var_248", dtype = "float32", shape = (16, 14))#candidate|248|(16, 14)|var|float32
call_244 = func_243_call(var_245,var_246,var_247,var_248,)
output = call_244
func_249 = relay.Function([var_245,var_246,var_247,var_248,], output)
mutated_mod['func_249'] = func_249
mutated_mod = relay.transform.InferType()(mutated_mod)
var_251 = relay.var("var_251", dtype = "bool", shape = ())#candidate|251|()|var|bool
var_252 = relay.var("var_252", dtype = "bool", shape = (2, 7, 8))#candidate|252|(2, 7, 8)|var|bool
bop_253 = relay.logical_and(var_251.astype('bool'), var_252.astype('bool')) # shape=(2, 7, 8)
bop_256 = relay.less_equal(bop_253.astype('bool'), var_251.astype('bool')) # shape=(2, 7, 8)
bop_259 = relay.logical_xor(var_251.astype('uint16'), var_252.astype('uint16')) # shape=(2, 7, 8)
var_262 = relay.var("var_262", dtype = "bool", shape = (2, 7, 8))#candidate|262|(2, 7, 8)|var|bool
bop_263 = relay.logical_or(var_252.astype('bool'), relay.reshape(var_262.astype('bool'), relay.shape_of(var_252))) # shape=(2, 7, 8)
uop_266 = relay.sqrt(var_262.astype('float32')) # shape=(2, 7, 8)
uop_268 = relay.acosh(uop_266.astype('float64')) # shape=(2, 7, 8)
uop_270 = relay.sin(uop_268.astype('float64')) # shape=(2, 7, 8)
uop_272 = relay.log10(uop_268.astype('float64')) # shape=(2, 7, 8)
bop_274 = relay.minimum(uop_270.astype('float32'), relay.reshape(uop_272.astype('float32'), relay.shape_of(uop_270))) # shape=(2, 7, 8)
var_277 = relay.var("var_277", dtype = "float32", shape = (2, 7, 8))#candidate|277|(2, 7, 8)|var|float32
bop_278 = relay.not_equal(uop_266.astype('bool'), relay.reshape(var_277.astype('bool'), relay.shape_of(uop_266))) # shape=(2, 7, 8)
uop_281 = relay.asinh(uop_272.astype('float64')) # shape=(2, 7, 8)
bop_283 = relay.equal(uop_281.astype('bool'), relay.reshape(bop_263.astype('bool'), relay.shape_of(uop_281))) # shape=(2, 7, 8)
uop_286 = relay.atanh(uop_281.astype('float32')) # shape=(2, 7, 8)
uop_288 = relay.atan(uop_286.astype('float32')) # shape=(2, 7, 8)
var_290 = relay.var("var_290", dtype = "float32", shape = (2, 7, 8))#candidate|290|(2, 7, 8)|var|float32
bop_291 = relay.multiply(uop_288.astype('uint64'), relay.reshape(var_290.astype('uint64'), relay.shape_of(uop_288))) # shape=(2, 7, 8)
bop_294 = relay.right_shift(uop_288.astype('int16'), relay.reshape(var_290.astype('int16'), relay.shape_of(uop_288))) # shape=(2, 7, 8)
bop_297 = relay.less_equal(uop_281.astype('bool'), relay.reshape(uop_272.astype('bool'), relay.shape_of(uop_281))) # shape=(2, 7, 8)
uop_300 = relay.erf(uop_286.astype('float64')) # shape=(2, 7, 8)
bop_302 = relay.left_shift(uop_288.astype('int16'), var_251.astype('int16')) # shape=(2, 7, 8)
uop_305 = relay.asin(uop_286.astype('float32')) # shape=(2, 7, 8)
uop_307 = relay.erf(uop_286.astype('float32')) # shape=(2, 7, 8)
var_309 = relay.var("var_309", dtype = "float32", shape = (2, 7, 8))#candidate|309|(2, 7, 8)|var|float32
bop_310 = relay.mod(uop_286.astype('float64'), relay.reshape(var_309.astype('float64'), relay.shape_of(uop_286))) # shape=(2, 7, 8)
uop_313 = relay.tan(uop_300.astype('float32')) # shape=(2, 7, 8)
uop_315 = relay.sin(uop_313.astype('float64')) # shape=(2, 7, 8)
uop_317 = relay.sinh(uop_315.astype('float32')) # shape=(2, 7, 8)
output = relay.Tuple([bop_256,bop_259,bop_274,bop_278,bop_283,bop_291,bop_294,bop_297,bop_302,uop_305,uop_307,bop_310,uop_317,])
output2 = relay.Tuple([bop_256,bop_259,bop_274,bop_278,bop_283,bop_291,bop_294,bop_297,bop_302,uop_305,uop_307,bop_310,uop_317,])
func_319 = relay.Function([var_251,var_252,var_262,var_277,var_290,var_309,], output)
mod['func_319'] = func_319
mod = relay.transform.InferType()(mod)
mutated_mod['func_319'] = func_319
mutated_mod = relay.transform.InferType()(mutated_mod)
func_319_call = mutated_mod.get_global_var('func_319')
var_321 = relay.var("var_321", dtype = "bool", shape = ())#candidate|321|()|var|bool
var_322 = relay.var("var_322", dtype = "bool", shape = (2, 7, 8))#candidate|322|(2, 7, 8)|var|bool
var_323 = relay.var("var_323", dtype = "bool", shape = (2, 7, 8))#candidate|323|(2, 7, 8)|var|bool
var_324 = relay.var("var_324", dtype = "float32", shape = (2, 7, 8))#candidate|324|(2, 7, 8)|var|float32
var_325 = relay.var("var_325", dtype = "float32", shape = (2, 7, 8))#candidate|325|(2, 7, 8)|var|float32
var_326 = relay.var("var_326", dtype = "float32", shape = (2, 7, 8))#candidate|326|(2, 7, 8)|var|float32
call_320 = func_319_call(var_321,var_322,var_323,var_324,var_325,var_326,)
output = call_320
func_327 = relay.Function([var_321,var_322,var_323,var_324,var_325,var_326,], output)
mutated_mod['func_327'] = func_327
mutated_mod = relay.transform.InferType()(mutated_mod)
var_329 = relay.var("var_329", dtype = "bool", shape = ())#candidate|329|()|var|bool
var_330 = relay.var("var_330", dtype = "bool", shape = (2,))#candidate|330|(2,)|var|bool
bop_331 = relay.logical_or(var_329.astype('bool'), var_330.astype('bool')) # shape=(2,)
output = relay.Tuple([bop_331,])
output2 = relay.Tuple([bop_331,])
func_334 = relay.Function([var_329,var_330,], output)
mod['func_334'] = func_334
mod = relay.transform.InferType()(mod)
var_335 = relay.var("var_335", dtype = "bool", shape = ())#candidate|335|()|var|bool
var_336 = relay.var("var_336", dtype = "bool", shape = (2,))#candidate|336|(2,)|var|bool
output = func_334(var_335,var_336,)
func_337 = relay.Function([var_335,var_336,], output)
mutated_mod['func_337'] = func_337
mutated_mod = relay.transform.InferType()(mutated_mod)
var_339 = relay.var("var_339", dtype = "uint16", shape = (10, 9))#candidate|339|(10, 9)|var|uint16
var_340 = relay.var("var_340", dtype = "uint16", shape = (10, 9))#candidate|340|(10, 9)|var|uint16
bop_341 = relay.bitwise_xor(var_339.astype('uint16'), relay.reshape(var_340.astype('uint16'), relay.shape_of(var_339))) # shape=(10, 9)
uop_344 = relay.exp(var_339.astype('float32')) # shape=(10, 9)
bop_346 = relay.floor_mod(var_340.astype('float64'), relay.reshape(uop_344.astype('float64'), relay.shape_of(var_340))) # shape=(10, 9)
bop_349 = relay.minimum(uop_344.astype('float32'), relay.reshape(bop_346.astype('float32'), relay.shape_of(uop_344))) # shape=(10, 9)
output = relay.Tuple([bop_341,bop_349,])
output2 = relay.Tuple([bop_341,bop_349,])
func_352 = relay.Function([var_339,var_340,], output)
mod['func_352'] = func_352
mod = relay.transform.InferType()(mod)
mutated_mod['func_352'] = func_352
mutated_mod = relay.transform.InferType()(mutated_mod)
func_352_call = mutated_mod.get_global_var('func_352')
var_354 = relay.var("var_354", dtype = "uint16", shape = (10, 9))#candidate|354|(10, 9)|var|uint16
var_355 = relay.var("var_355", dtype = "uint16", shape = (10, 9))#candidate|355|(10, 9)|var|uint16
call_353 = func_352_call(var_354,var_355,)
output = call_353
func_356 = relay.Function([var_354,var_355,], output)
mutated_mod['func_356'] = func_356
mutated_mod = relay.transform.InferType()(mutated_mod)
var_358 = relay.var("var_358", dtype = "int16", shape = (3, 12, 9))#candidate|358|(3, 12, 9)|var|int16
var_359 = relay.var("var_359", dtype = "int16", shape = (3, 12, 9))#candidate|359|(3, 12, 9)|var|int16
bop_360 = relay.logical_xor(var_358.astype('int16'), relay.reshape(var_359.astype('int16'), relay.shape_of(var_358))) # shape=(3, 12, 9)
func_46_call = mod.get_global_var('func_46')
func_50_call = mutated_mod.get_global_var('func_50')
const_364 = relay.const([-5.085122,-4.920536], dtype = "float64")#candidate|364|(2,)|const|float64
call_363 = relay.TupleGetItem(func_46_call(relay.reshape(const_364.astype('float64'), [2,]), relay.reshape(const_364.astype('float64'), [2,]), relay.reshape(const_364.astype('float64'), [2,]), ), 5)
call_365 = relay.TupleGetItem(func_50_call(relay.reshape(const_364.astype('float64'), [2,]), relay.reshape(const_364.astype('float64'), [2,]), relay.reshape(const_364.astype('float64'), [2,]), ), 5)
uop_366 = relay.log2(var_358.astype('float64')) # shape=(3, 12, 9)
const_368 = relay.const([[[7,2,9,4,-9,3,-3,9,-7],[-6,-5,-6,1,-2,-10,-10,-9,8],[-2,-1,3,10,-6,7,-9,6,3],[-5,-6,1,-2,-4,7,-8,-4,-10],[5,-10,1,4,2,2,-4,8,-3],[-7,-3,-5,-2,-9,-4,-1,9,9],[3,-7,-5,-8,5,-10,-6,3,-7],[10,-1,-6,-8,-3,-2,-4,-6,-10],[10,-2,6,3,-7,1,-5,3,-10],[3,8,2,8,7,-4,7,-4,9],[8,-2,-8,-1,4,1,5,-1,-7],[4,-6,1,7,6,-8,-3,-8,-3]],[[8,1,8,-7,5,-9,-8,10,-6],[-7,-1,-6,9,5,-6,6,-2,9],[1,6,-1,-8,8,4,1,6,-4],[10,6,3,-4,8,-7,8,1,4],[7,-1,-2,-8,6,-4,8,4,-9],[-6,5,1,-10,-10,2,-5,7,-3],[-2,-3,-7,-7,-1,9,-7,3,10],[3,-2,3,8,5,5,-6,1,5],[6,-2,-2,-7,7,-10,5,-9,6],[-2,-1,2,7,4,7,5,-1,10],[-8,-4,-8,-4,-10,1,6,-2,10],[-6,2,-4,-7,-4,-6,4,3,2]],[[2,4,8,8,1,-2,4,8,6],[-6,-3,-5,-7,4,5,-1,2,1],[-3,6,8,4,4,9,6,-6,8],[-7,-8,-4,8,4,-3,10,3,-1],[-3,-5,7,-10,-1,-9,8,5,8],[3,-7,4,1,7,1,6,-2,-5],[-5,1,1,-5,7,-7,9,9,-6],[-5,10,-2,1,6,-7,2,6,-5],[3,-6,-10,-5,2,5,8,6,4],[-10,-3,8,-9,-1,-2,-2,10,7],[-2,9,6,-3,-5,-4,-8,-6,3],[3,4,9,-4,-3,10,2,-10,-7]]], dtype = "int16")#candidate|368|(3, 12, 9)|const|int16
bop_369 = relay.bitwise_and(var_359.astype('int16'), relay.reshape(const_368.astype('int16'), relay.shape_of(var_359))) # shape=(3, 12, 9)
uop_372 = relay.erf(uop_366.astype('float64')) # shape=(3, 12, 9)
uop_374 = relay.sin(uop_372.astype('float64')) # shape=(3, 12, 9)
output = relay.Tuple([bop_360,call_363,const_364,bop_369,uop_374,])
output2 = relay.Tuple([bop_360,call_365,const_364,bop_369,uop_374,])
F = relay.Function([var_358,var_359,], output)
mod['main'] = F
mod = relay.transform.InferType()(mod)
print('==========mod==========')
print(mod.astext(show_meta_data=False))
print('===================================')
F = relay.Function([var_358,var_359,], output2)
mutated_mod['main'] = F
mutated_mod = relay.transform.InferType()(mutated_mod)
print('==========mutated_mod==========')
print(mutated_mod.astext(show_meta_data=False))
print('===================================')
graph, lib, params = relay.build(mod, target='llvm')
module1 = graph_runtime.create(graph, lib, tvm.device('llvm',0))
intrp2 = relay.build_module.create_executor('graph', mod, tvm.device('llvm',0),'llvm')
intrp3 = relay.build_module.create_executor('debug', mod, tvm.device('llvm',0),'llvm')
intrp4 = relay.build_module.create_executor('vm', mod, tvm.device('llvm',0),'llvm')
graph, lib, params = relay.build(mod, target='cuda')
module5 = graph_runtime.create(graph, lib, tvm.device('cuda',0))
intrp6 = relay.build_module.create_executor('graph', mod, tvm.device('cuda',0),'cuda')
intrp7 = relay.build_module.create_executor('debug', mod, tvm.device('cuda',0),'cuda')
intrp8 = relay.build_module.create_executor('vm', mod, tvm.device('cuda',0),'cuda')
seq = Sequential([
	relay.transform.AlterOpLayout(),
	relay.transform.AnnotateSpans(),
	relay.transform.BatchingOps(),
	relay.transform.CanonicalizeCast(),
	relay.transform.CanonicalizeOps(),
	relay.transform.DeadCodeElimination(),
	relay.transform.DynamicToStatic(),
	relay.transform.FastMath(),
	relay.transform.FirstOrderGradient(),
	relay.transform.EliminateCommonSubexpr(),
	relay.transform.MergeCompilerRegions(),
	relay.transform.Inline(),
	relay.transform.LambdaLift(),
	relay.transform.LazyGradientInit(),
	relay.transform.PartialEvaluate(),
	relay.transform.Legalize(),
	relay.transform.FoldConstant(),
])
mod = seq(mod)
print(mod.astext(show_meta_data=False))
graph, lib, params = relay.build(mod, target='llvm')
module9 = graph_runtime.create(graph, lib, tvm.device('llvm',0))
intrp10 = relay.build_module.create_executor('graph', mod, tvm.device('llvm',0),'llvm')
intrp11 = relay.build_module.create_executor('debug', mod, tvm.device('llvm',0),'llvm')
intrp12 = relay.build_module.create_executor('vm', mod, tvm.device('llvm',0),'llvm')
graph, lib, params = relay.build(mod, target='cuda')
module13 = graph_runtime.create(graph, lib, tvm.device('cuda',0))
intrp14 = relay.build_module.create_executor('graph', mod, tvm.device('cuda',0),'cuda')
intrp15 = relay.build_module.create_executor('debug', mod, tvm.device('cuda',0),'cuda')
intrp16 = relay.build_module.create_executor('vm', mod, tvm.device('cuda',0),'cuda')
graph, lib, params = relay.build(mutated_mod, target='llvm')
module17 = graph_runtime.create(graph, lib, tvm.device('llvm',0))
intrp18 = relay.build_module.create_executor('graph', mutated_mod, tvm.device('llvm',0),'llvm')
intrp19 = relay.build_module.create_executor('debug', mutated_mod, tvm.device('llvm',0),'llvm')
intrp20 = relay.build_module.create_executor('vm', mutated_mod, tvm.device('llvm',0),'llvm')
graph, lib, params = relay.build(mutated_mod, target='cuda')
module21 = graph_runtime.create(graph, lib, tvm.device('cuda',0))
intrp22 = relay.build_module.create_executor('graph', mutated_mod, tvm.device('cuda',0),'cuda')
intrp23 = relay.build_module.create_executor('debug', mutated_mod, tvm.device('cuda',0),'cuda')
intrp24 = relay.build_module.create_executor('vm', mutated_mod, tvm.device('cuda',0),'cuda')
input_358= np.array([[[-6,10,-9,-6,-1,-7,8,-6,-2],[-7,4,2,8,5,-8,9,-10,-3],[-9,3,-7,4,10,6,-2,2,4],[3,2,5,-5,-5,5,-5,7,6],[-8,9,-10,-2,9,-10,10,5,1],[5,6,10,-5,8,5,-8,-4,-3],[-4,-9,-8,4,-2,3,10,-9,5],[-10,8,-4,1,8,-9,-2,-5,-3],[-9,3,7,5,4,-6,7,1,3],[8,5,9,-6,-6,1,-4,-8,2],[-4,5,-2,9,8,-7,-3,-6,1],[-4,-8,8,2,2,2,7,2,6]],[[-4,5,2,6,-7,6,10,6,10],[9,-7,-10,-6,7,-9,-4,-5,-7],[-3,4,5,-1,-8,5,3,8,7],[-9,6,-3,-8,-10,-9,1,1,-3],[5,-1,1,1,-2,-3,8,1,7],[-1,-4,9,-9,5,-6,-6,2,-4],[-5,-4,3,-5,-9,-4,-2,-3,-7],[8,-1,-6,1,7,-3,-4,-3,7],[-8,-6,-9,-5,-7,-7,-9,10,10],[-8,-2,-4,-6,-5,-1,-7,-5,7],[-3,-6,1,5,-2,3,-3,-5,-7],[-1,-1,4,-9,2,3,-9,-2,-9]],[[2,-4,-10,-8,-7,9,-4,-7,-7],[9,-3,9,10,4,-4,-4,10,-9],[-4,-5,-2,5,7,2,-6,-7,4],[4,-5,-6,5,3,8,6,-1,-3],[7,10,3,-5,5,-5,-1,2,1],[-3,8,10,2,-9,6,7,-1,7],[-10,-10,-6,5,8,-1,7,-5,-4],[2,2,-8,-3,-2,-1,-10,-1,8],[-7,-3,2,4,-2,4,-6,9,-8],[-6,3,7,9,6,10,-7,9,-4],[8,10,-8,5,3,-2,2,-3,-10],[-8,8,8,8,-6,7,-7,7,4]]], dtype='int16')
module1.set_input('var_358', input_358)
input_359= np.array([[[-6,-1,-2,9,3,-6,2,1,-8],[7,4,4,-3,-8,-10,8,-1,4],[-2,-7,3,-7,9,-7,4,-2,9],[-2,9,-3,-4,5,-9,-1,2,-7],[3,-1,1,9,2,-6,9,3,9],[7,8,9,10,8,7,-6,9,-3],[3,-6,5,-6,-1,2,-7,-3,10],[-10,-9,-4,-6,-5,8,-7,-1,-8],[8,-1,-4,-9,4,4,4,-6,-6],[7,1,-9,1,-9,-3,-9,2,-10],[-4,9,-2,2,9,-7,8,-7,8],[-7,-5,3,5,9,-3,8,-9,-5]],[[-10,-7,7,-3,7,-4,-7,-8,-9],[-2,-7,4,1,9,-8,1,3,6],[1,5,-1,-7,-1,-1,-7,5,-4],[-4,-2,7,9,-8,5,10,-5,-7],[5,-5,8,7,10,1,-2,1,10],[-3,-5,9,7,7,4,6,-8,6],[-8,-3,-4,2,-9,-9,10,-8,-3],[6,-6,-1,9,-2,8,-4,8,5],[-2,-9,10,10,9,5,-4,-3,-6],[-3,-2,1,-2,6,-10,3,10,5],[-9,1,4,2,-7,-10,-9,-7,7],[-1,-10,-8,-10,4,-2,-9,5,-9]],[[-6,-9,-5,-7,10,-5,9,-6,5],[-1,7,-6,-6,10,-4,2,-7,4],[-8,6,2,-6,7,2,-10,-8,8],[-5,-8,-8,3,2,-9,-2,7,6],[9,-10,6,10,-5,-2,-4,-9,-2],[-5,-7,7,-3,-2,8,10,9,-6],[4,-10,6,-3,-9,-3,1,7,6],[1,-2,-10,2,10,1,-6,-3,3],[-8,-2,-1,9,-4,8,-2,-7,-4],[7,-8,9,2,-4,4,6,4,-1],[4,6,8,-6,-5,-5,2,6,8],[9,1,-4,-1,-6,-10,-1,-9,-10]]], dtype='int16')
module1.set_input('var_359', input_359)
module1.set_input(**params)
module1.run()
res2 = intrp2.evaluate()(input_358, input_359, )
res3 = intrp3.evaluate()(input_358, input_359, )
res4 = intrp4.evaluate()(input_358, input_359, )
res2 = vmobj_to_list(res2)
res3 = vmobj_to_list(res3)
res4 = vmobj_to_list(res4)
res1_0 = module1.get_output(0).asnumpy()
res2_0 = res2[0].asnumpy()
res3_0 = res3[0].asnumpy()
res4_0 = res4[0].asnumpy()
np.testing.assert_allclose(res1_0 ,res2_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_0 ,res3_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_0 ,res4_0, atol=1e-3, rtol=1e-3)
(res1_0 == res2_0).all()
(res1_0 == res3_0).all()
(res1_0 == res4_0).all()
res1_1 = module1.get_output(1).asnumpy()
res2_1 = res2[1].asnumpy()
res3_1 = res3[1].asnumpy()
res4_1 = res4[1].asnumpy()
np.testing.assert_allclose(res1_1 ,res2_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_1 ,res3_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_1 ,res4_1, atol=1e-3, rtol=1e-3)
(res1_1 == res2_1).all()
(res1_1 == res3_1).all()
(res1_1 == res4_1).all()
res1_2 = module1.get_output(2).asnumpy()
res2_2 = res2[2].asnumpy()
res3_2 = res3[2].asnumpy()
res4_2 = res4[2].asnumpy()
np.testing.assert_allclose(res1_2 ,res2_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_2 ,res3_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_2 ,res4_2, atol=1e-3, rtol=1e-3)
(res1_2 == res2_2).all()
(res1_2 == res3_2).all()
(res1_2 == res4_2).all()
res1_3 = module1.get_output(3).asnumpy()
res2_3 = res2[3].asnumpy()
res3_3 = res3[3].asnumpy()
res4_3 = res4[3].asnumpy()
np.testing.assert_allclose(res1_3 ,res2_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_3 ,res3_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_3 ,res4_3, atol=1e-3, rtol=1e-3)
(res1_3 == res2_3).all()
(res1_3 == res3_3).all()
(res1_3 == res4_3).all()
res1_4 = module1.get_output(4).asnumpy()
res2_4 = res2[4].asnumpy()
res3_4 = res3[4].asnumpy()
res4_4 = res4[4].asnumpy()
np.testing.assert_allclose(res1_4 ,res2_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_4 ,res3_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res1_4 ,res4_4, atol=1e-3, rtol=1e-3)
(res1_4 == res2_4).all()
(res1_4 == res3_4).all()
(res1_4 == res4_4).all()
module5.set_input('var_358', input_358)
module5.set_input('var_359', input_359)
module5.set_input(**params)
module5.run()
res6 = intrp6.evaluate()(input_358, input_359, )
res7 = intrp7.evaluate()(input_358, input_359, )
res8 = intrp8.evaluate()(input_358, input_359, )
res6 = vmobj_to_list(res6)
res7 = vmobj_to_list(res7)
res8 = vmobj_to_list(res8)
res5_0 = module5.get_output(0).asnumpy()
res6_0 = res6[0].asnumpy()
res7_0 = res7[0].asnumpy()
res8_0 = res8[0].asnumpy()
np.testing.assert_allclose(res5_0 ,res6_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_0 ,res7_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_0 ,res8_0, atol=1e-3, rtol=1e-3)
(res5_0 == res6_0).all()
(res5_0 == res7_0).all()
(res5_0 == res8_0).all()
res5_1 = module5.get_output(1).asnumpy()
res6_1 = res6[1].asnumpy()
res7_1 = res7[1].asnumpy()
res8_1 = res8[1].asnumpy()
np.testing.assert_allclose(res5_1 ,res6_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_1 ,res7_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_1 ,res8_1, atol=1e-3, rtol=1e-3)
(res5_1 == res6_1).all()
(res5_1 == res7_1).all()
(res5_1 == res8_1).all()
res5_2 = module5.get_output(2).asnumpy()
res6_2 = res6[2].asnumpy()
res7_2 = res7[2].asnumpy()
res8_2 = res8[2].asnumpy()
np.testing.assert_allclose(res5_2 ,res6_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_2 ,res7_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_2 ,res8_2, atol=1e-3, rtol=1e-3)
(res5_2 == res6_2).all()
(res5_2 == res7_2).all()
(res5_2 == res8_2).all()
res5_3 = module5.get_output(3).asnumpy()
res6_3 = res6[3].asnumpy()
res7_3 = res7[3].asnumpy()
res8_3 = res8[3].asnumpy()
np.testing.assert_allclose(res5_3 ,res6_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_3 ,res7_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_3 ,res8_3, atol=1e-3, rtol=1e-3)
(res5_3 == res6_3).all()
(res5_3 == res7_3).all()
(res5_3 == res8_3).all()
res5_4 = module5.get_output(4).asnumpy()
res6_4 = res6[4].asnumpy()
res7_4 = res7[4].asnumpy()
res8_4 = res8[4].asnumpy()
np.testing.assert_allclose(res5_4 ,res6_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_4 ,res7_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res5_4 ,res8_4, atol=1e-3, rtol=1e-3)
(res5_4 == res6_4).all()
(res5_4 == res7_4).all()
(res5_4 == res8_4).all()
module9.set_input('var_358', input_358)
module9.set_input('var_359', input_359)
module9.set_input(**params)
module9.run()
res10 = intrp10.evaluate()(input_358, input_359, )
res11 = intrp11.evaluate()(input_358, input_359, )
res12 = intrp12.evaluate()(input_358, input_359, )
res10 = vmobj_to_list(res10)
res11 = vmobj_to_list(res11)
res12 = vmobj_to_list(res12)
res9_0 = module9.get_output(0).asnumpy()
res10_0 = res10[0].asnumpy()
res11_0 = res11[0].asnumpy()
res12_0 = res12[0].asnumpy()
np.testing.assert_allclose(res9_0 ,res10_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_0 ,res11_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_0 ,res12_0, atol=1e-3, rtol=1e-3)
(res9_0 == res10_0).all()
(res9_0 == res11_0).all()
(res9_0 == res12_0).all()
res9_1 = module9.get_output(1).asnumpy()
res10_1 = res10[1].asnumpy()
res11_1 = res11[1].asnumpy()
res12_1 = res12[1].asnumpy()
np.testing.assert_allclose(res9_1 ,res10_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_1 ,res11_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_1 ,res12_1, atol=1e-3, rtol=1e-3)
(res9_1 == res10_1).all()
(res9_1 == res11_1).all()
(res9_1 == res12_1).all()
res9_2 = module9.get_output(2).asnumpy()
res10_2 = res10[2].asnumpy()
res11_2 = res11[2].asnumpy()
res12_2 = res12[2].asnumpy()
np.testing.assert_allclose(res9_2 ,res10_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_2 ,res11_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_2 ,res12_2, atol=1e-3, rtol=1e-3)
(res9_2 == res10_2).all()
(res9_2 == res11_2).all()
(res9_2 == res12_2).all()
res9_3 = module9.get_output(3).asnumpy()
res10_3 = res10[3].asnumpy()
res11_3 = res11[3].asnumpy()
res12_3 = res12[3].asnumpy()
np.testing.assert_allclose(res9_3 ,res10_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_3 ,res11_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_3 ,res12_3, atol=1e-3, rtol=1e-3)
(res9_3 == res10_3).all()
(res9_3 == res11_3).all()
(res9_3 == res12_3).all()
res9_4 = module9.get_output(4).asnumpy()
res10_4 = res10[4].asnumpy()
res11_4 = res11[4].asnumpy()
res12_4 = res12[4].asnumpy()
np.testing.assert_allclose(res9_4 ,res10_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_4 ,res11_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res9_4 ,res12_4, atol=1e-3, rtol=1e-3)
(res9_4 == res10_4).all()
(res9_4 == res11_4).all()
(res9_4 == res12_4).all()
module13.set_input('var_358', input_358)
module13.set_input('var_359', input_359)
module13.set_input(**params)
module13.run()
res14 = intrp14.evaluate()(input_358, input_359, )
res15 = intrp15.evaluate()(input_358, input_359, )
res16 = intrp16.evaluate()(input_358, input_359, )
res14 = vmobj_to_list(res14)
res15 = vmobj_to_list(res15)
res16 = vmobj_to_list(res16)
res13_0 = module13.get_output(0).asnumpy()
res14_0 = res14[0].asnumpy()
res15_0 = res15[0].asnumpy()
res16_0 = res16[0].asnumpy()
np.testing.assert_allclose(res13_0 ,res14_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_0 ,res15_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_0 ,res16_0, atol=1e-3, rtol=1e-3)
(res13_0 == res14_0).all()
(res13_0 == res15_0).all()
(res13_0 == res16_0).all()
res13_1 = module13.get_output(1).asnumpy()
res14_1 = res14[1].asnumpy()
res15_1 = res15[1].asnumpy()
res16_1 = res16[1].asnumpy()
np.testing.assert_allclose(res13_1 ,res14_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_1 ,res15_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_1 ,res16_1, atol=1e-3, rtol=1e-3)
(res13_1 == res14_1).all()
(res13_1 == res15_1).all()
(res13_1 == res16_1).all()
res13_2 = module13.get_output(2).asnumpy()
res14_2 = res14[2].asnumpy()
res15_2 = res15[2].asnumpy()
res16_2 = res16[2].asnumpy()
np.testing.assert_allclose(res13_2 ,res14_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_2 ,res15_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_2 ,res16_2, atol=1e-3, rtol=1e-3)
(res13_2 == res14_2).all()
(res13_2 == res15_2).all()
(res13_2 == res16_2).all()
res13_3 = module13.get_output(3).asnumpy()
res14_3 = res14[3].asnumpy()
res15_3 = res15[3].asnumpy()
res16_3 = res16[3].asnumpy()
np.testing.assert_allclose(res13_3 ,res14_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_3 ,res15_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_3 ,res16_3, atol=1e-3, rtol=1e-3)
(res13_3 == res14_3).all()
(res13_3 == res15_3).all()
(res13_3 == res16_3).all()
res13_4 = module13.get_output(4).asnumpy()
res14_4 = res14[4].asnumpy()
res15_4 = res15[4].asnumpy()
res16_4 = res16[4].asnumpy()
np.testing.assert_allclose(res13_4 ,res14_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_4 ,res15_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res13_4 ,res16_4, atol=1e-3, rtol=1e-3)
(res13_4 == res14_4).all()
(res13_4 == res15_4).all()
(res13_4 == res16_4).all()
module17.set_input('var_358', input_358)
module17.set_input('var_359', input_359)
module17.set_input(**params)
module17.run()
res18 = intrp18.evaluate()(input_358, input_359, )
res19 = intrp19.evaluate()(input_358, input_359, )
res20 = intrp20.evaluate()(input_358, input_359, )
res18 = vmobj_to_list(res18)
res19 = vmobj_to_list(res19)
res20 = vmobj_to_list(res20)
res17_0 = module17.get_output(0).asnumpy()
res18_0 = res18[0].asnumpy()
res19_0 = res19[0].asnumpy()
res20_0 = res20[0].asnumpy()
np.testing.assert_allclose(res17_0 ,res18_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_0 ,res19_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_0 ,res20_0, atol=1e-3, rtol=1e-3)
(res17_0 == res18_0).all()
(res17_0 == res19_0).all()
(res17_0 == res20_0).all()
res17_1 = module17.get_output(1).asnumpy()
res18_1 = res18[1].asnumpy()
res19_1 = res19[1].asnumpy()
res20_1 = res20[1].asnumpy()
np.testing.assert_allclose(res17_1 ,res18_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_1 ,res19_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_1 ,res20_1, atol=1e-3, rtol=1e-3)
(res17_1 == res18_1).all()
(res17_1 == res19_1).all()
(res17_1 == res20_1).all()
res17_2 = module17.get_output(2).asnumpy()
res18_2 = res18[2].asnumpy()
res19_2 = res19[2].asnumpy()
res20_2 = res20[2].asnumpy()
np.testing.assert_allclose(res17_2 ,res18_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_2 ,res19_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_2 ,res20_2, atol=1e-3, rtol=1e-3)
(res17_2 == res18_2).all()
(res17_2 == res19_2).all()
(res17_2 == res20_2).all()
res17_3 = module17.get_output(3).asnumpy()
res18_3 = res18[3].asnumpy()
res19_3 = res19[3].asnumpy()
res20_3 = res20[3].asnumpy()
np.testing.assert_allclose(res17_3 ,res18_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_3 ,res19_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_3 ,res20_3, atol=1e-3, rtol=1e-3)
(res17_3 == res18_3).all()
(res17_3 == res19_3).all()
(res17_3 == res20_3).all()
res17_4 = module17.get_output(4).asnumpy()
res18_4 = res18[4].asnumpy()
res19_4 = res19[4].asnumpy()
res20_4 = res20[4].asnumpy()
np.testing.assert_allclose(res17_4 ,res18_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_4 ,res19_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res17_4 ,res20_4, atol=1e-3, rtol=1e-3)
(res17_4 == res18_4).all()
(res17_4 == res19_4).all()
(res17_4 == res20_4).all()
module21.set_input('var_358', input_358)
module21.set_input('var_359', input_359)
module21.set_input(**params)
module21.run()
res22 = intrp22.evaluate()(input_358, input_359, )
res23 = intrp23.evaluate()(input_358, input_359, )
res24 = intrp24.evaluate()(input_358, input_359, )
res22 = vmobj_to_list(res22)
res23 = vmobj_to_list(res23)
res24 = vmobj_to_list(res24)
res21_0 = module21.get_output(0).asnumpy()
res22_0 = res22[0].asnumpy()
res23_0 = res23[0].asnumpy()
res24_0 = res24[0].asnumpy()
np.testing.assert_allclose(res21_0 ,res22_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_0 ,res23_0, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_0 ,res24_0, atol=1e-3, rtol=1e-3)
(res21_0 == res22_0).all()
(res21_0 == res23_0).all()
(res21_0 == res24_0).all()
res21_1 = module21.get_output(1).asnumpy()
res22_1 = res22[1].asnumpy()
res23_1 = res23[1].asnumpy()
res24_1 = res24[1].asnumpy()
np.testing.assert_allclose(res21_1 ,res22_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_1 ,res23_1, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_1 ,res24_1, atol=1e-3, rtol=1e-3)
(res21_1 == res22_1).all()
(res21_1 == res23_1).all()
(res21_1 == res24_1).all()
res21_2 = module21.get_output(2).asnumpy()
res22_2 = res22[2].asnumpy()
res23_2 = res23[2].asnumpy()
res24_2 = res24[2].asnumpy()
np.testing.assert_allclose(res21_2 ,res22_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_2 ,res23_2, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_2 ,res24_2, atol=1e-3, rtol=1e-3)
(res21_2 == res22_2).all()
(res21_2 == res23_2).all()
(res21_2 == res24_2).all()
res21_3 = module21.get_output(3).asnumpy()
res22_3 = res22[3].asnumpy()
res23_3 = res23[3].asnumpy()
res24_3 = res24[3].asnumpy()
np.testing.assert_allclose(res21_3 ,res22_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_3 ,res23_3, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_3 ,res24_3, atol=1e-3, rtol=1e-3)
(res21_3 == res22_3).all()
(res21_3 == res23_3).all()
(res21_3 == res24_3).all()
res21_4 = module21.get_output(4).asnumpy()
res22_4 = res22[4].asnumpy()
res23_4 = res23[4].asnumpy()
res24_4 = res24[4].asnumpy()
np.testing.assert_allclose(res21_4 ,res22_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_4 ,res23_4, atol=1e-3, rtol=1e-3)
np.testing.assert_allclose(res21_4 ,res24_4, atol=1e-3, rtol=1e-3)
(res21_4 == res22_4).all()
(res21_4 == res23_4).all()
(res21_4 == res24_4).all()

'''104: TVMFuncCall
103: _ZNSt17_Function_handlerIFvN3tvm7runtime7TVM
102: tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
101: tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, tvm::runtime::String const&)
100: tvm::relay::backend::RelayBuildModule::OptimizeImpl(tvm::IRModule)
99: tvm::transform::Pass::operator()(tvm::IRModule) const
98: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
97: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
96: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
95: tvm::relay::transform::FunctionPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
94: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::relay::Function (tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::DynamicToStatic()::{lambda(tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)#1}>(tvm::relay::transform::DynamicToStatic()::{lambda(tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)
93: tvm::relay::DynamicToStatic(tvm::relay::Function, tvm::IRModule)
92: tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)
91: void tvm::relay::ExpandDataflow<tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#2}, tvm::relay::ExpandDataflow<{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, {lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1})::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#2}, tvm::relay::ExpandDataflow, tvm::relay::ExpandDataflow<{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, {lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1})::{lambda(tvm::RelayExpr const&)#1}) [clone .isra.535]
90: tvm::relay::MixedModeMutator::VisitLeaf(tvm::RelayExpr const&)
89: tvm::relay::DynamicToStaticMutator::DispatchVisitExpr(tvm::RelayExpr const&)
88: _ZN3tvm5relay16MixedModeMutato
87: tvm::relay::ExprMutator::VisitExpr(tvm::RelayExpr const&)
86: tvm::relay::ExprFunctor<tvm::RelayExpr (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)
85: _ZZN3tvm5relay11ExprFunctorIFNS_9RelayEx
84: tvm::relay::ExprMutator::VisitExpr_(tvm::relay::FunctionNode const*)
83: tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)
82: void tvm::relay::ExpandDataflow<tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#2}, tvm::relay::ExpandDataflow<{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, {lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1})::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#2}, tvm::relay::ExpandDataflow, tvm::relay::ExpandDataflow<{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, {lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1})::{lambda(tvm::RelayExpr const&)#1}) [clone .isra.535]
81: tvm::relay::MixedModeMutator::VisitLeaf(tvm::RelayExpr const&)
80: tvm::relay::DynamicToStaticMutator::DispatchVisitExpr(tvm::RelayExpr const&)
79: _ZN3tvm5relay16MixedModeMutato
78: tvm::relay::ExprMutator::VisitExpr(tvm::RelayExpr const&)
77: tvm::relay::ExprFunctor<tvm::RelayExpr (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)
76: _ZZN3tvm5relay11ExprFunctorIFNS_9RelayEx
75: tvm::relay::MixedModeMutator::VisitExpr_(tvm::relay::CallNode const*)
74: tvm::relay::DynamicToStaticMutator::Rewrite_(tvm::relay::CallNode const*, tvm::RelayExpr const&)
73: std::_Function_handler<tvm::RelayExpr (tvm::relay::CallNode const*), tvm::relay::DynamicToStaticMutator::DynamicToStaticMutator(tvm::IRModule, tvm::relay::Function)::{lambda(tvm::relay::CallNode const*)#1}>::_M_invoke(std::_Any_data const&, tvm::relay::CallNode const*&&)
72: tvm::relay::DynamicToStaticMutator::PrepareArgs(tvm::relay::CallNode const*)
71: tvm::relay::DynamicToStaticMutator::PrepareInput(tvm::RelayExpr const&)
70: tvm::transform::Pass::operator()(tvm::IRModule) const
69: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
68: tvm::relay::transform::FunctionPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
67: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::relay::Function (tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::FoldConstant()::{lambda(tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)#1}>(tvm::relay::transform::FoldConstant()::{lambda(tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)
66: tvm::relay::transform::FoldConstantExpr(tvm::RelayExpr const&, tvm::IRModule const&)
65: tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)
64: void tvm::relay::ExpandDataflow<tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#2}, tvm::relay::ExpandDataflow<{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, {lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1})::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#2}, tvm::relay::ExpandDataflow, tvm::relay::ExpandDataflow<{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, {lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1})::{lambda(tvm::RelayExpr const&)#1}) [clone .isra.535]
63: tvm::relay::MixedModeMutator::VisitLeaf(tvm::RelayExpr const&)
62: _ZN3tvm5relay16MixedModeMutato
61: tvm::relay::ExprMutator::VisitExpr(tvm::RelayExpr const&)
60: tvm::relay::ExprFunctor<tvm::RelayExpr (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)
59: _ZZN3tvm5relay11ExprFunctorIFNS_9RelayEx
58: tvm::relay::transform::(anonymous namespace)::ConstantFolder::VisitExpr_(tvm::relay::FunctionNode const*)
57: tvm::relay::ExprMutator::VisitExpr_(tvm::relay::FunctionNode const*)
56: tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)
55: void tvm::relay::ExpandDataflow<tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#2}, tvm::relay::ExpandDataflow<{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, {lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1})::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#2}, tvm::relay::ExpandDataflow, tvm::relay::ExpandDataflow<{lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1}>(tvm::RelayExpr, {lambda(tvm::RelayExpr const&)#1}, tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&)::{lambda(tvm::RelayExpr const&)#1})::{lambda(tvm::RelayExpr const&)#1}) [clone .isra.535]
54: tvm::relay::MixedModeMutator::VisitLeaf(tvm::RelayExpr const&)
53: _ZN3tvm5relay16MixedModeMutato
52: tvm::relay::ExprMutator::VisitExpr(tvm::RelayExpr const&)
51: tvm::relay::ExprFunctor<tvm::RelayExpr (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)
50: _ZZN3tvm5relay11ExprFunctorIFNS_9RelayEx
49: tvm::relay::MixedModeMutator::VisitExpr_(tvm::relay::CallNode const*)
48: tvm::relay::transform::(anonymous namespace)::ConstantFolder::Rewrite_(tvm::relay::CallNode const*, tvm::RelayExpr const&)
47: tvm::relay::transform::(anonymous namespace)::ConstantFolder::ConstEvaluate(tvm::RelayExpr const&)
46: tvm::relay::Eval(tvm::RelayExpr, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>, std::unordered_set<tvm::runtime::String, std::hash<tvm::runtime::String>, std::equal_to<tvm::runtime::String>, std::allocator<tvm::runtime::String> >, DLDevice, tvm::Target)
45: tvm::relay::Prepare(tvm::IRModule, tvm::CompilationConfig)
44: tvm::transform::Pass::operator()(tvm::IRModule) const
43: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
42: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
41: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
40: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
39: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
38: tvm::transform::ModulePassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
37: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::tec::LowerTEPass(tvm::runtime::String const&, std::function<void (tvm::BaseFunc)>, tvm::VirtualDevice)::{lambda(tvm::IRModule, tvm::transform::PassContext)#1}>(tvm::relay::tec::LowerTEPass(tvm::runtime::String const&, std::function<void (tvm::BaseFunc)>, tvm::VirtualDevice)::{lambda(tvm::IRModule, tvm::transform::PassContext)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)
36: tvm::relay::tec::LowerTE(tvm::IRModule const&, tvm::runtime::String const&, std::function<void (tvm::BaseFunc)>, tvm::VirtualDevice)
35: tvm::transform::Pass::operator()(tvm::IRModule) const
34: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
33: tvm::relay::transform::FunctionPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
32: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::relay::Function (tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::tec::LowerTensorExpr(tvm::runtime::String const&, tvm::relay::tec::TECompiler, std::function<void (tvm::BaseFunc)>, tvm::VirtualDevice)::{lambda(tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)#1}>(tvm::relay::tec::LowerTensorExpr(tvm::runtime::String const&, tvm::relay::tec::TECompiler, std::function<void (tvm::BaseFunc)>, tvm::VirtualDevice)::{lambda(tvm::relay::Function, tvm::IRModule, tvm::transform::PassContext)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)
31: tvm::relay::ExprMutator::VisitExpr(tvm::RelayExpr const&)
30: tvm::relay::ExprFunctor<tvm::RelayExpr (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)
29: _ZZN3tvm5relay11ExprFunctorIFNS_9RelayEx
28: tvm::relay::transform::DeviceAwareExprMutator::VisitExpr_(tvm::relay::FunctionNode const*)
27: tvm::relay::tec::LowerTensorExprMutator::DeviceAwareVisitExpr_(tvm::relay::FunctionNode const*)
26: _ZN3tvm5relay9transform22Devic
25: tvm::relay::ExprMutator::VisitExpr_(tvm::relay::FunctionNode const*)
24: tvm::relay::ExprMutator::VisitExpr(tvm::RelayExpr const&)
23: tvm::relay::ExprFunctor<tvm::RelayExpr (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)
22: _ZZN3tvm5relay11ExprFunctorIFNS_9RelayEx
21: tvm::relay::transform::DeviceAwareExprMutator::VisitExpr_(tvm::relay::LetNode const*)
20: tvm::relay::tec::LowerTensorExprMutator::PreVisitLetBinding_(tvm::relay::Var const&, tvm::RelayExpr const&)
19: tvm::relay::ExprMutator::VisitExpr(tvm::RelayExpr const&)
18: tvm::relay::ExprFunctor<tvm::RelayExpr (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)
17: _ZZN3tvm5relay11ExprFunctorIFNS_9RelayEx
16: tvm::relay::transform::DeviceAwareExprMutator::VisitExpr_(tvm::relay::CallNode const*)
15: tvm::relay::ExprMutator::VisitExpr(tvm::RelayExpr const&)
14: tvm::relay::ExprFunctor<tvm::RelayExpr (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)
13: _ZZN3tvm5relay11ExprFunctorIFNS_9RelayEx
12: tvm::relay::transform::DeviceAwareExprMutator::VisitExpr_(tvm::relay::CallNode const*)
11: tvm::relay::tec::LowerTensorExprMutator::DeviceAwareVisitExpr_(tvm::relay::CallNode const*)
10: tvm::relay::tec::LowerTensorExprMutator::MakeLoweredCall(tvm::relay::Function, tvm::runtime::Array<tvm::RelayExpr, void>, tvm::Span, tvm::Target)
9: tvm::relay::tec::TECompilerImpl::LowerShapeFunc(tvm::relay::tec::CCacheKey const&)
8: tvm::relay::tec::TECompilerImpl::LowerShapeFuncInternal(tvm::relay::tec::CCacheKey const&)
7: tvm::relay::tec::ShapeFuncFor(tvm::relay::Function const&, tvm::Target const&, std::function<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)>)
6: tvm::relay::tec::MakeShapeFunc::Create(tvm::relay::Function const&, tvm::Target const&, std::function<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)>)
5: tvm::relay::tec::MakeShapeFunc::VisitExpr(tvm::RelayExpr const&)
4: tvm::relay::backend::MemoizedExprTranslator<tvm::runtime::Array<tvm::te::Tensor, void> >::VisitExpr(tvm::RelayExpr const&)
3: tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)
2: _ZZN3tvm5relay11ExprFunctorIFNS_7runtime
1: tvm::relay::tec::MakeShapeFunc::VisitExpr_(tvm::relay::CallNode const*)
0: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), TVMFuncCreateFromCFunc::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#2}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)
3: TVMFuncCall
2: _ZNSt17_Function_handlerIFvN3tvm7run
1: tvm::runtime::TypedPackedFunc<tvm::tir::ProducerLoad (tvm::tir::DataProducer, tvm::runtime::Array<tvm::PrimExpr, void>, tvm::Span)>::AssignTypedLambda<tvm::tir::{lambda(tvm::tir::DataProducer, tvm::runtime::Array<tvm::PrimExpr, void>, tvm::Span)#103}>(tvm::tir::{lambda(tvm::tir::DataProducer, tvm::runtime::Array<tvm::PrimExpr, void>, tvm::Span)#103}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Array<tvm::PrimExpr, void><tvm::runtime::Array<tvm::PrimExpr, void> >() const
4: TVMFuncCall
3: _ZNSt17_Function_handlerIFvN3tvm7run
2: tvm::runtime::TypedPackedFunc<tvm::tir::ProducerLoad (tvm::tir::DataProducer, tvm::runtime::Array<tvm::PrimExpr, void>, tvm::Span)>::AssignTypedLambda<tvm::tir::{lambda(tvm::tir::DataProducer, tvm::runtime::Array<tvm::PrimExpr, void>, tvm::Span)#103}>(tvm::tir::{lambda(tvm::tir::DataProducer, tvm::runtime::Array<tvm::PrimExpr, void>, tvm::Span)#103}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Array<tvm::PrimExpr, void><tvm::runtime::Array<tvm::PrimExpr, void> >() const
0: tvm::runtime::Array<tvm::PrimExpr, void> tvm::runtime::TVMPODValue_::AsObjectRef<tvm::runtime::Array<tvm::PrimExpr, void> >() const

'''